{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:10\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "from einops import rearrange\n",
    "import collections\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  8798 (13, 38)\n",
      " Shape of y =  (8798,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_classification(\"SpokenArabicDigits\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", len(X), X[0].shape)\n",
    "print(\" Shape of y = \", y.shape)\n",
    "y = y.astype(int)\n",
    "np.unique(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 93\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for i, x in enumerate(X):\n",
    "    lengths.append(x.shape[1])\n",
    "lengths.sort()\n",
    "\n",
    "MIN_TS_SIZE = min(lengths)\n",
    "MAX_TS_SIZE = max(lengths)\n",
    "\n",
    "print(MIN_TS_SIZE, MAX_TS_SIZE)\n",
    "\n",
    "# counter = collections.Counter(lengths)\n",
    "# counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_time, _y, batch_size = 512, random_state = 1):\n",
    "    # X\n",
    "    equi_length_X = []\n",
    "    for x in X_time:\n",
    "        pad_width = ((0, 0), (0, MAX_TS_SIZE - x.shape[1]))\n",
    "        padded = np.pad(x, pad_width, mode='constant', constant_values=np.nan)\n",
    "        equi_length_X.append(padded)\n",
    "\n",
    "    X_time = np.array(equi_length_X)\n",
    "    X_time = rearrange(X_time, \"b v t -> b t v\")\n",
    "    \n",
    "    X_ind = ~np.isnan(X_time)\n",
    "    X_time = np.nan_to_num(X_time, nan=0.0)\n",
    "    \n",
    "    # Target\n",
    "    _y = _y - 1\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    \n",
    "    # Class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    \n",
    "    # Split\n",
    "    X_time_train, X_time_test, X_ind_train, X_ind_test, y_train, y_test = train_test_split(X_time, X_ind, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_time_test, X_time_val, X_ind_test, X_ind_val, y_test, y_val = train_test_split(X_time_test, X_ind_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "\n",
    "    # Normalize\n",
    "    # X_time_train, X_time_val, X_time_test = normalize_across_time(X_time_train, X_time_val, X_time_test, X_time.shape[2])\n",
    "    \n",
    "    \n",
    "    # Datasets\n",
    "    X_time_train = torch.tensor(X_time_train, dtype=torch.float32)\n",
    "    X_ind_train = torch.tensor(X_ind_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train)\n",
    "\n",
    "    X_time_val = torch.tensor(X_time_val, dtype=torch.float32)\n",
    "    X_ind_val = torch.tensor(X_ind_val, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val)\n",
    "\n",
    "    X_time_test = torch.tensor(X_time_test, dtype=torch.float32)\n",
    "    X_ind_test = torch.tensor(X_ind_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "    # Dataloaders\n",
    "    train_dataset = TensorDataset(X_time_train, X_ind_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataset = TensorDataset(X_time_val, X_ind_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    test_dataset = TensorDataset(X_time_test, X_ind_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test, n_variables):\n",
    "    # scalerX=StandardScaler(with_std=False)\n",
    "    scalerX=RobustScaler()\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9998,\n",
      "        1.0021], device='cuda:10') 10\n",
      "torch.Size([512, 93, 13])\n",
      "torch.Size([512, 93, 13])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for batch in train_loader:\n",
    "    [print(t.shape) for t in batch]\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                    use_indicators, use_fixes, use_only_last_timestep, top_k=''):\n",
    "    model = original_models.CBM(static_dim = static_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = use_indicators,\n",
    "                                use_fixes = use_fixes,\n",
    "                                use_only_last_timestep = use_only_last_timestep,\n",
    "                                use_grad_norm= False,\n",
    "                                noise_std = None,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=1e-3,\n",
    "                                cos_sim_lambda=1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                                 use_summaries_for_atomics, use_indicators, use_fixes, top_k=''):\n",
    "    model = new_models.CBM(static_dim = static_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            use_fixes = use_fixes,\n",
    "                            use_grad_norm= False,\n",
    "                            noise_std = None,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=1e-3,\n",
    "                            cos_sim_lambda=1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0 93\n"
     ]
    }
   ],
   "source": [
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "seq_len = MAX_TS_SIZE\n",
    "changing_dim = X[0].shape[0]\n",
    "static_dim = 0\n",
    "\n",
    "print(changing_dim, static_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "config_original = {\n",
    "    \"n_concepts\": [4, 20],\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_only_last_timestep\": [False]\n",
    "}\n",
    "\n",
    "all_config_permutations_og = list(product(*config_original.values()))\n",
    "all_config_permutations_og = [dict(zip(config_original.keys(), permutation)) for permutation in all_config_permutations_og]\n",
    "print(len(all_config_permutations_og))\n",
    "# all_config_permutations_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/arabic_spoken_digits/original/\"\n",
    "model_path = experiment_folder + \"asd_c{n_concepts}_ind{use_indicators}_fixes{use_fixes}_onlylasttimestep{use_only_last_timestep}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 22%|██▏       | 2249/10000 [24:17<1:23:43,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.37882310152053833, 0.9952751994132996, 0.9102272987365723, 0.9102272987365723, 0.0013421890325844288]\n",
      "1 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 11%|█▏        | 1139/10000 [13:10<1:42:29,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.31455931067466736, 0.9961640238761902, 0.9375, 0.9375, 0.0004659700207412243]\n",
      "2 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 19%|█▉        | 1919/10000 [23:09<1:55:53,  1.16it/s]"
     ]
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_og):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "    \n",
    "    model = initializeModel(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    cos_sim = (model.cos_sim(model.bottleneck) / model.bottleneck.out_features).item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            X_time, X_ind, X_static, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(X_time, X_ind, X_static)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [\"original\", i, model.val_losses[-1], auc, acc, f1, cos_sim]\n",
    "    print(history)\n",
    "    histories_original.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "config_atomics = {\n",
    "    \"n_atomics\": [10, 30],\n",
    "    \"n_concepts\": [4, 20],\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    # \"use_only_last_timestep\": [True, False],\n",
    "    \"use_summaries_for_atomics\": [True, False],\n",
    "}\n",
    "\n",
    "all_config_permutations_atomics = list(product(*config_atomics.values()))\n",
    "all_config_permutations_atomics = [dict(zip(config_atomics.keys(), permutation)) for permutation in all_config_permutations_atomics]\n",
    "print(len(all_config_permutations_atomics))\n",
    "# all_config_permutations_atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/\"\n",
    "model_path = experiment_folder + \"asd_c{n_atomics}_c{n_concepts}_ind{use_indicators}_fixes{use_fixes}_summaries{use_summaries_for_atomics}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 0, 0.3353213369846344, 0.9977768063545227, 0.9420454502105713, 0.9420454502105713, 0.0025991180445998907]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 1, 1.5843349695205688, 0.7788463830947876, 0.4221591055393219, 0.4221591055393219, 0.006908874027431011]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 2, 0.3431147336959839, 0.9972932934761047, 0.9482954740524292, 0.9482954740524292, 0.01075510960072279]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 3, 2.028390645980835, 0.6792844533920288, 0.22499999403953552, 0.22499999403953552, 0.008288515731692314]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 4, 0.2734147012233734, 0.9916046261787415, 0.8482954502105713, 0.8482954502105713, 0.0024241164792329073]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 5, 0.3170201778411865, 0.9854267239570618, 0.8272727131843567, 0.8272727131843567, 0.005426987539976835]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 6, 0.2974870204925537, 0.9863454103469849, 0.7892045378684998, 0.7892045378684998, 0.0022586192935705185]\n",
      "7 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c4_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 7, 0.3041088283061981, 0.9081094861030579, 0.4698863625526428, 0.4698863625526428, 0.0066296132281422615]\n",
      "8 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 8, 0.2523161768913269, 0.9990429878234863, 0.9715909361839294, 0.9715909361839294, 0.008776410482823849]\n",
      "9 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 9, 1.8579308986663818, 0.7440115213394165, 0.3062500059604645, 0.3062500059604645, 0.011580284684896469]\n",
      "10 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 10, 0.25175949931144714, 0.9987093806266785, 0.9676136374473572, 0.9676136374473572, 0.008399609476327896]\n",
      "11 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 11, 1.3533354997634888, 0.8729915022850037, 0.5392045378684998, 0.5392045378684998, 0.008070406503975391]\n",
      "12 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 12, 0.22494447231292725, 0.9965783953666687, 0.9227272868156433, 0.9227272868156433, 0.006416226737201214]\n",
      "13 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 13, 0.21716810762882233, 0.9866262674331665, 0.7278409004211426, 0.7278409004211426, 0.004843917675316334]\n",
      "14 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 14, 0.2012123316526413, 0.9972347617149353, 0.9193181991577148, 0.9193181991577148, 0.0072888946160674095]\n",
      "15 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c10_c20_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 15, 0.20980466902256012, 0.9689082503318787, 0.5920454263687134, 0.5920454263687134, 0.006792254280298948]\n",
      "16 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 16, 0.30609115958213806, 0.9982663989067078, 0.949431836605072, 0.949431836605072, 0.012421539053320885]\n",
      "17 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 17, 1.846528172492981, 0.7635216116905212, 0.3642045557498932, 0.3642045557498932, 0.020465215668082237]\n",
      "18 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 18, 0.2991943061351776, 0.9966917037963867, 0.9488636255264282, 0.9488636255264282, 0.013697762973606586]\n",
      "19 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 19, 2.1338791847229004, 0.654559314250946, 0.1931818127632141, 0.1931818127632141, 0.020227482542395592]\n",
      "20 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 20, 0.2750416100025177, 0.9963129162788391, 0.9289772510528564, 0.9289772510528564, 0.012840209528803825]\n",
      "21 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 21, 0.3290204107761383, 0.9832014441490173, 0.769318163394928, 0.769318163394928, 0.014191851019859314]\n",
      "22 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 22, 0.2912112772464752, 0.9840733408927917, 0.7647727131843567, 0.7647727131843567, 0.010379546321928501]\n",
      "23 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c4_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 23, 0.28984835743904114, 0.9612234234809875, 0.7295454740524292, 0.7295454740524292, 0.015006204135715961]\n",
      "24 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 24, 0.2524090111255646, 0.999323844909668, 0.9721590876579285, 0.9721590876579285, 0.012338303029537201]\n",
      "25 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 25, 1.8569121360778809, 0.7559752464294434, 0.33181819319725037, 0.33181819319725037, 0.025285465642809868]\n",
      "26 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 26, 0.24170595407485962, 0.9991627931594849, 0.9721590876579285, 0.9721590876579285, 0.011992349289357662]\n",
      "27 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 27, 1.9525599479675293, 0.7112244963645935, 0.2801136374473572, 0.2801136374473572, 0.030275117605924606]\n",
      "28 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 28, 0.22191092371940613, 0.9979214072227478, 0.9221590757369995, 0.9221590757369995, 0.011342821642756462]\n",
      "29 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 29, 0.23474520444869995, 0.9678177833557129, 0.612500011920929, 0.612500011920929, 0.0121205048635602]\n",
      "30 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 30, 0.21175962686538696, 0.9957813620567322, 0.8801136612892151, 0.8801136612892151, 0.012896384112536907]\n",
      "31 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/arabic_spoken_digits/atomics/asd_c30_c20_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 31, 0.22437410056591034, 0.9808371663093567, 0.6517045497894287, 0.6517045497894287, 0.011230750009417534]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_atomics):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)#, batch_size=8)\n",
    "    \n",
    "    model = initializeModel_with_atomics(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim = num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    cos_sim = ((model.cos_sim(model.layer_to_concepts) + model.cos_sim(model.layer_time_to_atomics)) \n",
    "               / (model.layer_to_concepts.out_features + model.layer_time_to_atomics.out_features)).item()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            X_time, X_ind, X_static, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(X_time, X_ind, X_static)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "\n",
    "    history = [\"atomics\", i, model.val_losses[-1], auc, acc, f1, cos_sim]\n",
    "    print(history)\n",
    "    history_atomics.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\", \"cos_sim\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float, 'cos_sim': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = pd.concat([df_og, pd.DataFrame(all_config_permutations_og)], axis=1)\n",
    "\n",
    "df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "df_atomics = pd.concat([df_atomics, pd.DataFrame(all_config_permutations_atomics)], axis=1)\n",
    "\n",
    "result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.9952152371406555\n",
      "acc 0.9090909361839294\n",
      "f1 0.9090909361839294\n"
     ]
    }
   ],
   "source": [
    "for col in result_df.columns[3:6]:\n",
    "    baseline = result_df[(result_df['type'] == 'original') & (result_df['config'] == 0)][col].values[0]\n",
    "    print(col, baseline)\n",
    "    result_df[f'{col}_abs_imp'] = result_df[col] - baseline\n",
    "    # result_df[f'{col}_rel_imp'] = result_df[f'{col}_abs_imp'] / baseline\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>config</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th>auc_abs_imp</th>\n",
       "      <th>acc_abs_imp</th>\n",
       "      <th>f1_abs_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>original</td>\n",
       "      <td>11</td>\n",
       "      <td>0.129561</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>0.977841</td>\n",
       "      <td>0.977841</td>\n",
       "      <td>0.009065</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.068750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original</td>\n",
       "      <td>9</td>\n",
       "      <td>0.144528</td>\n",
       "      <td>0.999402</td>\n",
       "      <td>0.977841</td>\n",
       "      <td>0.977841</td>\n",
       "      <td>0.008317</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.068750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>atomics</td>\n",
       "      <td>26</td>\n",
       "      <td>0.241706</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.011992</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.063068</td>\n",
       "      <td>0.063068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>atomics</td>\n",
       "      <td>24</td>\n",
       "      <td>0.252409</td>\n",
       "      <td>0.999324</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.972159</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.063068</td>\n",
       "      <td>0.063068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>atomics</td>\n",
       "      <td>8</td>\n",
       "      <td>0.252316</td>\n",
       "      <td>0.999043</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.971591</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>atomics</td>\n",
       "      <td>10</td>\n",
       "      <td>0.251759</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>0.967614</td>\n",
       "      <td>0.967614</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.058523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original</td>\n",
       "      <td>13</td>\n",
       "      <td>0.141732</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.009212</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>0.051136</td>\n",
       "      <td>0.051136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>atomics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.306091</td>\n",
       "      <td>0.998266</td>\n",
       "      <td>0.949432</td>\n",
       "      <td>0.949432</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.040341</td>\n",
       "      <td>0.040341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>atomics</td>\n",
       "      <td>18</td>\n",
       "      <td>0.299194</td>\n",
       "      <td>0.996692</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.039773</td>\n",
       "      <td>0.039773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343115</td>\n",
       "      <td>0.997293</td>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.039205</td>\n",
       "      <td>0.039205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.311147</td>\n",
       "      <td>0.995961</td>\n",
       "      <td>0.942614</td>\n",
       "      <td>0.942614</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.033523</td>\n",
       "      <td>0.033523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.335321</td>\n",
       "      <td>0.997777</td>\n",
       "      <td>0.942045</td>\n",
       "      <td>0.942045</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.032955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "      <td>0.276146</td>\n",
       "      <td>0.997846</td>\n",
       "      <td>0.942045</td>\n",
       "      <td>0.942045</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.032955</td>\n",
       "      <td>0.032955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>original</td>\n",
       "      <td>10</td>\n",
       "      <td>0.264507</td>\n",
       "      <td>0.997894</td>\n",
       "      <td>0.941477</td>\n",
       "      <td>0.941477</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>0.032386</td>\n",
       "      <td>0.032386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>atomics</td>\n",
       "      <td>20</td>\n",
       "      <td>0.275042</td>\n",
       "      <td>0.996313</td>\n",
       "      <td>0.928977</td>\n",
       "      <td>0.928977</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.019886</td>\n",
       "      <td>0.019886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.281706</td>\n",
       "      <td>0.996879</td>\n",
       "      <td>0.928409</td>\n",
       "      <td>0.928409</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>0.019318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.325235</td>\n",
       "      <td>0.994469</td>\n",
       "      <td>0.924432</td>\n",
       "      <td>0.924432</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.015341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>atomics</td>\n",
       "      <td>12</td>\n",
       "      <td>0.224944</td>\n",
       "      <td>0.996578</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.922727</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>0.013636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>atomics</td>\n",
       "      <td>28</td>\n",
       "      <td>0.221911</td>\n",
       "      <td>0.997921</td>\n",
       "      <td>0.922159</td>\n",
       "      <td>0.922159</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.013068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>atomics</td>\n",
       "      <td>14</td>\n",
       "      <td>0.201212</td>\n",
       "      <td>0.997235</td>\n",
       "      <td>0.919318</td>\n",
       "      <td>0.919318</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.010227</td>\n",
       "      <td>0.010227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.335224</td>\n",
       "      <td>0.994828</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.917614</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000387</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.008523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375592</td>\n",
       "      <td>0.995215</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original</td>\n",
       "      <td>15</td>\n",
       "      <td>0.146892</td>\n",
       "      <td>0.996941</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>-0.005682</td>\n",
       "      <td>-0.005682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>atomics</td>\n",
       "      <td>30</td>\n",
       "      <td>0.211760</td>\n",
       "      <td>0.995781</td>\n",
       "      <td>0.880114</td>\n",
       "      <td>0.880114</td>\n",
       "      <td>0.012896</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>-0.028977</td>\n",
       "      <td>-0.028977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.273415</td>\n",
       "      <td>0.991605</td>\n",
       "      <td>0.848295</td>\n",
       "      <td>0.848295</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.003611</td>\n",
       "      <td>-0.060795</td>\n",
       "      <td>-0.060795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "      <td>0.336459</td>\n",
       "      <td>0.988646</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.846591</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006569</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.317020</td>\n",
       "      <td>0.985427</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.827273</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.009789</td>\n",
       "      <td>-0.081818</td>\n",
       "      <td>-0.081818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.297487</td>\n",
       "      <td>0.986345</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.789205</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.008870</td>\n",
       "      <td>-0.119886</td>\n",
       "      <td>-0.119886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>atomics</td>\n",
       "      <td>21</td>\n",
       "      <td>0.329020</td>\n",
       "      <td>0.983201</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.769318</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.012014</td>\n",
       "      <td>-0.139773</td>\n",
       "      <td>-0.139773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>atomics</td>\n",
       "      <td>22</td>\n",
       "      <td>0.291211</td>\n",
       "      <td>0.984073</td>\n",
       "      <td>0.764773</td>\n",
       "      <td>0.764773</td>\n",
       "      <td>0.010380</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.144318</td>\n",
       "      <td>-0.144318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>atomics</td>\n",
       "      <td>23</td>\n",
       "      <td>0.289848</td>\n",
       "      <td>0.961223</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.033992</td>\n",
       "      <td>-0.179545</td>\n",
       "      <td>-0.179545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>atomics</td>\n",
       "      <td>13</td>\n",
       "      <td>0.217168</td>\n",
       "      <td>0.986626</td>\n",
       "      <td>0.727841</td>\n",
       "      <td>0.727841</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.008589</td>\n",
       "      <td>-0.181250</td>\n",
       "      <td>-0.181250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>atomics</td>\n",
       "      <td>31</td>\n",
       "      <td>0.224374</td>\n",
       "      <td>0.980837</td>\n",
       "      <td>0.651705</td>\n",
       "      <td>0.651705</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014378</td>\n",
       "      <td>-0.257386</td>\n",
       "      <td>-0.257386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>atomics</td>\n",
       "      <td>29</td>\n",
       "      <td>0.234745</td>\n",
       "      <td>0.967818</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.027397</td>\n",
       "      <td>-0.296591</td>\n",
       "      <td>-0.296591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>atomics</td>\n",
       "      <td>15</td>\n",
       "      <td>0.209805</td>\n",
       "      <td>0.968908</td>\n",
       "      <td>0.592045</td>\n",
       "      <td>0.592045</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.026307</td>\n",
       "      <td>-0.317046</td>\n",
       "      <td>-0.317046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>atomics</td>\n",
       "      <td>11</td>\n",
       "      <td>1.353335</td>\n",
       "      <td>0.872992</td>\n",
       "      <td>0.539205</td>\n",
       "      <td>0.539205</td>\n",
       "      <td>0.008070</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.122224</td>\n",
       "      <td>-0.369886</td>\n",
       "      <td>-0.369886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.493369</td>\n",
       "      <td>0.930308</td>\n",
       "      <td>0.519318</td>\n",
       "      <td>0.519318</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064907</td>\n",
       "      <td>-0.389773</td>\n",
       "      <td>-0.389773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original</td>\n",
       "      <td>12</td>\n",
       "      <td>0.413643</td>\n",
       "      <td>0.950283</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044932</td>\n",
       "      <td>-0.406818</td>\n",
       "      <td>-0.406818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>atomics</td>\n",
       "      <td>7</td>\n",
       "      <td>0.304109</td>\n",
       "      <td>0.908109</td>\n",
       "      <td>0.469886</td>\n",
       "      <td>0.469886</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.087106</td>\n",
       "      <td>-0.439205</td>\n",
       "      <td>-0.439205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>1.584335</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.422159</td>\n",
       "      <td>0.422159</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.216369</td>\n",
       "      <td>-0.486932</td>\n",
       "      <td>-0.486932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>atomics</td>\n",
       "      <td>17</td>\n",
       "      <td>1.846528</td>\n",
       "      <td>0.763522</td>\n",
       "      <td>0.364205</td>\n",
       "      <td>0.364205</td>\n",
       "      <td>0.020465</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.231694</td>\n",
       "      <td>-0.544886</td>\n",
       "      <td>-0.544886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>atomics</td>\n",
       "      <td>25</td>\n",
       "      <td>1.856912</td>\n",
       "      <td>0.755975</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.025285</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.239240</td>\n",
       "      <td>-0.577273</td>\n",
       "      <td>-0.577273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>original</td>\n",
       "      <td>14</td>\n",
       "      <td>0.445643</td>\n",
       "      <td>0.862973</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.317614</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.132242</td>\n",
       "      <td>-0.591477</td>\n",
       "      <td>-0.591477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>atomics</td>\n",
       "      <td>9</td>\n",
       "      <td>1.857931</td>\n",
       "      <td>0.744012</td>\n",
       "      <td>0.306250</td>\n",
       "      <td>0.306250</td>\n",
       "      <td>0.011580</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.251204</td>\n",
       "      <td>-0.602841</td>\n",
       "      <td>-0.602841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>atomics</td>\n",
       "      <td>27</td>\n",
       "      <td>1.952560</td>\n",
       "      <td>0.711224</td>\n",
       "      <td>0.280114</td>\n",
       "      <td>0.280114</td>\n",
       "      <td>0.030275</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.283991</td>\n",
       "      <td>-0.628977</td>\n",
       "      <td>-0.628977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.482943</td>\n",
       "      <td>0.772965</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.222250</td>\n",
       "      <td>-0.672727</td>\n",
       "      <td>-0.672727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>2.028391</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.315931</td>\n",
       "      <td>-0.684091</td>\n",
       "      <td>-0.684091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>atomics</td>\n",
       "      <td>19</td>\n",
       "      <td>2.133879</td>\n",
       "      <td>0.654559</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.020227</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.340656</td>\n",
       "      <td>-0.715909</td>\n",
       "      <td>-0.715909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  config  val_loss       auc       acc        f1   cos_sim  \\\n",
       "11  original      11  0.129561  0.999613  0.977841  0.977841  0.009065   \n",
       "9   original       9  0.144528  0.999402  0.977841  0.977841  0.008317   \n",
       "42   atomics      26  0.241706  0.999163  0.972159  0.972159  0.011992   \n",
       "40   atomics      24  0.252409  0.999324  0.972159  0.972159  0.012338   \n",
       "24   atomics       8  0.252316  0.999043  0.971591  0.971591  0.008776   \n",
       "26   atomics      10  0.251759  0.998709  0.967614  0.967614  0.008400   \n",
       "13  original      13  0.141732  0.998759  0.960227  0.960227  0.009212   \n",
       "32   atomics      16  0.306091  0.998266  0.949432  0.949432  0.012422   \n",
       "34   atomics      18  0.299194  0.996692  0.948864  0.948864  0.013698   \n",
       "18   atomics       2  0.343115  0.997293  0.948295  0.948295  0.010755   \n",
       "1   original       1  0.311147  0.995961  0.942614  0.942614  0.000559   \n",
       "16   atomics       0  0.335321  0.997777  0.942045  0.942045  0.002599   \n",
       "8   original       8  0.276146  0.997846  0.942045  0.942045  0.007504   \n",
       "10  original      10  0.264507  0.997894  0.941477  0.941477  0.008972   \n",
       "36   atomics      20  0.275042  0.996313  0.928977  0.928977  0.012840   \n",
       "5   original       5  0.281706  0.996879  0.928409  0.928409  0.000898   \n",
       "3   original       3  0.325235  0.994469  0.924432  0.924432  0.000537   \n",
       "28   atomics      12  0.224944  0.996578  0.922727  0.922727  0.006416   \n",
       "44   atomics      28  0.221911  0.997921  0.922159  0.922159  0.011343   \n",
       "30   atomics      14  0.201212  0.997235  0.919318  0.919318  0.007289   \n",
       "2   original       2  0.335224  0.994828  0.917614  0.917614  0.000104   \n",
       "0   original       0  0.375592  0.995215  0.909091  0.909091  0.004382   \n",
       "15  original      15  0.146892  0.996941  0.903409  0.903409  0.007739   \n",
       "46   atomics      30  0.211760  0.995781  0.880114  0.880114  0.012896   \n",
       "20   atomics       4  0.273415  0.991605  0.848295  0.848295  0.002424   \n",
       "7   original       7  0.336459  0.988646  0.846591  0.846591  0.001156   \n",
       "21   atomics       5  0.317020  0.985427  0.827273  0.827273  0.005427   \n",
       "22   atomics       6  0.297487  0.986345  0.789205  0.789205  0.002259   \n",
       "37   atomics      21  0.329020  0.983201  0.769318  0.769318  0.014192   \n",
       "38   atomics      22  0.291211  0.984073  0.764773  0.764773  0.010380   \n",
       "39   atomics      23  0.289848  0.961223  0.729545  0.729545  0.015006   \n",
       "29   atomics      13  0.217168  0.986626  0.727841  0.727841  0.004844   \n",
       "47   atomics      31  0.224374  0.980837  0.651705  0.651705  0.011231   \n",
       "45   atomics      29  0.234745  0.967818  0.612500  0.612500  0.012121   \n",
       "31   atomics      15  0.209805  0.968908  0.592045  0.592045  0.006792   \n",
       "27   atomics      11  1.353335  0.872992  0.539205  0.539205  0.008070   \n",
       "4   original       4  0.493369  0.930308  0.519318  0.519318  0.026672   \n",
       "12  original      12  0.413643  0.950283  0.502273  0.502273  0.007853   \n",
       "23   atomics       7  0.304109  0.908109  0.469886  0.469886  0.006630   \n",
       "17   atomics       1  1.584335  0.778846  0.422159  0.422159  0.006909   \n",
       "33   atomics      17  1.846528  0.763522  0.364205  0.364205  0.020465   \n",
       "41   atomics      25  1.856912  0.755975  0.331818  0.331818  0.025285   \n",
       "14  original      14  0.445643  0.862973  0.317614  0.317614  0.008017   \n",
       "25   atomics       9  1.857931  0.744012  0.306250  0.306250  0.011580   \n",
       "43   atomics      27  1.952560  0.711224  0.280114  0.280114  0.030275   \n",
       "6   original       6  0.482943  0.772965  0.236364  0.236364  0.000144   \n",
       "19   atomics       3  2.028391  0.679284  0.225000  0.225000  0.008289   \n",
       "35   atomics      19  2.133879  0.654559  0.193182  0.193182  0.020227   \n",
       "\n",
       "    n_concepts  use_indicators  use_fixes use_only_last_timestep  n_atomics  \\\n",
       "11          20            True       True                  False        NaN   \n",
       "9           20            True      False                  False        NaN   \n",
       "42          20            True       True                    NaN       30.0   \n",
       "40          20            True      False                    NaN       30.0   \n",
       "24          20            True      False                    NaN       10.0   \n",
       "26          20            True       True                    NaN       10.0   \n",
       "13          20           False      False                  False        NaN   \n",
       "32           4            True      False                    NaN       30.0   \n",
       "34           4            True       True                    NaN       30.0   \n",
       "18           4            True       True                    NaN       10.0   \n",
       "1            4            True      False                  False        NaN   \n",
       "16           4            True      False                    NaN       10.0   \n",
       "8           20            True      False                   True        NaN   \n",
       "10          20            True       True                   True        NaN   \n",
       "36           4           False      False                    NaN       30.0   \n",
       "5            4           False      False                  False        NaN   \n",
       "3            4            True       True                  False        NaN   \n",
       "28          20           False      False                    NaN       10.0   \n",
       "44          20           False      False                    NaN       30.0   \n",
       "30          20           False       True                    NaN       10.0   \n",
       "2            4            True       True                   True        NaN   \n",
       "0            4            True      False                   True        NaN   \n",
       "15          20           False       True                  False        NaN   \n",
       "46          20           False       True                    NaN       30.0   \n",
       "20           4           False      False                    NaN       10.0   \n",
       "7            4           False       True                  False        NaN   \n",
       "21           4           False      False                    NaN       10.0   \n",
       "22           4           False       True                    NaN       10.0   \n",
       "37           4           False      False                    NaN       30.0   \n",
       "38           4           False       True                    NaN       30.0   \n",
       "39           4           False       True                    NaN       30.0   \n",
       "29          20           False      False                    NaN       10.0   \n",
       "47          20           False       True                    NaN       30.0   \n",
       "45          20           False      False                    NaN       30.0   \n",
       "31          20           False       True                    NaN       10.0   \n",
       "27          20            True       True                    NaN       10.0   \n",
       "4            4           False      False                   True        NaN   \n",
       "12          20           False      False                   True        NaN   \n",
       "23           4           False       True                    NaN       10.0   \n",
       "17           4            True      False                    NaN       10.0   \n",
       "33           4            True      False                    NaN       30.0   \n",
       "41          20            True      False                    NaN       30.0   \n",
       "14          20           False       True                   True        NaN   \n",
       "25          20            True      False                    NaN       10.0   \n",
       "43          20            True       True                    NaN       30.0   \n",
       "6            4           False       True                   True        NaN   \n",
       "19           4            True       True                    NaN       10.0   \n",
       "35           4            True       True                    NaN       30.0   \n",
       "\n",
       "   use_summaries_for_atomics  auc_abs_imp  acc_abs_imp  f1_abs_imp  \n",
       "11                       NaN     0.004398     0.068750    0.068750  \n",
       "9                        NaN     0.004187     0.068750    0.068750  \n",
       "42                      True     0.003948     0.063068    0.063068  \n",
       "40                      True     0.004109     0.063068    0.063068  \n",
       "24                      True     0.003828     0.062500    0.062500  \n",
       "26                      True     0.003494     0.058523    0.058523  \n",
       "13                       NaN     0.003544     0.051136    0.051136  \n",
       "32                      True     0.003051     0.040341    0.040341  \n",
       "34                      True     0.001476     0.039773    0.039773  \n",
       "18                      True     0.002078     0.039205    0.039205  \n",
       "1                        NaN     0.000746     0.033523    0.033523  \n",
       "16                      True     0.002562     0.032955    0.032955  \n",
       "8                        NaN     0.002631     0.032955    0.032955  \n",
       "10                       NaN     0.002678     0.032386    0.032386  \n",
       "36                      True     0.001098     0.019886    0.019886  \n",
       "5                        NaN     0.001664     0.019318    0.019318  \n",
       "3                        NaN    -0.000747     0.015341    0.015341  \n",
       "28                      True     0.001363     0.013636    0.013636  \n",
       "44                      True     0.002706     0.013068    0.013068  \n",
       "30                      True     0.002020     0.010227    0.010227  \n",
       "2                        NaN    -0.000387     0.008523    0.008523  \n",
       "0                        NaN     0.000000     0.000000    0.000000  \n",
       "15                       NaN     0.001726    -0.005682   -0.005682  \n",
       "46                      True     0.000566    -0.028977   -0.028977  \n",
       "20                      True    -0.003611    -0.060795   -0.060795  \n",
       "7                        NaN    -0.006569    -0.062500   -0.062500  \n",
       "21                     False    -0.009789    -0.081818   -0.081818  \n",
       "22                      True    -0.008870    -0.119886   -0.119886  \n",
       "37                     False    -0.012014    -0.139773   -0.139773  \n",
       "38                      True    -0.011142    -0.144318   -0.144318  \n",
       "39                     False    -0.033992    -0.179545   -0.179545  \n",
       "29                     False    -0.008589    -0.181250   -0.181250  \n",
       "47                     False    -0.014378    -0.257386   -0.257386  \n",
       "45                     False    -0.027397    -0.296591   -0.296591  \n",
       "31                     False    -0.026307    -0.317046   -0.317046  \n",
       "27                     False    -0.122224    -0.369886   -0.369886  \n",
       "4                        NaN    -0.064907    -0.389773   -0.389773  \n",
       "12                       NaN    -0.044932    -0.406818   -0.406818  \n",
       "23                     False    -0.087106    -0.439205   -0.439205  \n",
       "17                     False    -0.216369    -0.486932   -0.486932  \n",
       "33                     False    -0.231694    -0.544886   -0.544886  \n",
       "41                     False    -0.239240    -0.577273   -0.577273  \n",
       "14                       NaN    -0.132242    -0.591477   -0.591477  \n",
       "25                     False    -0.251204    -0.602841   -0.602841  \n",
       "43                     False    -0.283991    -0.628977   -0.628977  \n",
       "6                        NaN    -0.222250    -0.672727   -0.672727  \n",
       "19                     False    -0.315931    -0.684091   -0.684091  \n",
       "35                     False    -0.340656    -0.715909   -0.715909  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "result_df.sort_values(by='acc', ascending=False)\n",
    "# atomics: atomics, concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics\n",
    "# original: concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.930549</td>\n",
       "      <td>0.713672</td>\n",
       "      <td>0.713672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.921618</td>\n",
       "      <td>0.704439</td>\n",
       "      <td>0.704439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc       acc        f1\n",
       "type    n_atomics                              \n",
       "atomics 10.0       0.930549  0.713672  0.713672\n",
       "        30.0       0.921618  0.704439  0.704439"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>4</th>\n",
       "      <td>0.916409</td>\n",
       "      <td>0.695028</td>\n",
       "      <td>0.695028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.935759</td>\n",
       "      <td>0.723082</td>\n",
       "      <td>0.723082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>4</th>\n",
       "      <td>0.958659</td>\n",
       "      <td>0.778054</td>\n",
       "      <td>0.778054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.975464</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.815341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc       acc        f1\n",
       "type     n_concepts                              \n",
       "atomics  4           0.916409  0.695028  0.695028\n",
       "         20          0.935759  0.723082  0.723082\n",
       "original 4           0.958659  0.778054  0.778054\n",
       "         20          0.975464  0.815341  0.815341"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.933891</td>\n",
       "      <td>0.738672</td>\n",
       "      <td>0.738672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.918277</td>\n",
       "      <td>0.679439</td>\n",
       "      <td>0.679439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.983082</td>\n",
       "      <td>0.835227</td>\n",
       "      <td>0.835227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.951041</td>\n",
       "      <td>0.758168</td>\n",
       "      <td>0.758168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc       acc        f1\n",
       "type     use_fixes                              \n",
       "atomics  False      0.933891  0.738672  0.738672\n",
       "         True       0.918277  0.679439  0.679439\n",
       "original False      0.983082  0.835227  0.835227\n",
       "         True       0.951041  0.758168  0.758168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.980500</td>\n",
       "      <td>0.772230</td>\n",
       "      <td>0.772230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.871668</td>\n",
       "      <td>0.645881</td>\n",
       "      <td>0.645881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.937219</td>\n",
       "      <td>0.651776</td>\n",
       "      <td>0.651776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.996904</td>\n",
       "      <td>0.941619</td>\n",
       "      <td>0.941619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auc       acc        f1\n",
       "type     use_indicators                              \n",
       "atomics  False           0.980500  0.772230  0.772230\n",
       "         True            0.871668  0.645881  0.645881\n",
       "original False           0.937219  0.651776  0.651776\n",
       "         True            0.996904  0.941619  0.941619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.996334</td>\n",
       "      <td>0.932670</td>\n",
       "      <td>0.932670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.937789</td>\n",
       "      <td>0.660724</td>\n",
       "      <td>0.660724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      auc       acc        f1\n",
       "type     use_only_last_timestep                              \n",
       "original False                   0.996334  0.932670  0.932670\n",
       "         True                    0.937789  0.660724  0.660724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.856410</td>\n",
       "      <td>0.502628</td>\n",
       "      <td>0.502628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.995757</td>\n",
       "      <td>0.915483</td>\n",
       "      <td>0.915483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        auc       acc        f1\n",
       "type    use_summaries_for_atomics                              \n",
       "atomics False                      0.856410  0.502628  0.502628\n",
       "        True                       0.995757  0.915483  0.915483"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <td>0.926084</td>\n",
       "      <td>0.709055</td>\n",
       "      <td>0.709055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.967061</td>\n",
       "      <td>0.796697</td>\n",
       "      <td>0.796697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc       acc        f1\n",
       "type                                  \n",
       "atomics   0.926084  0.709055  0.709055\n",
       "original  0.967061  0.796697  0.796697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in sorted(set(list(all_config_permutations_og[0].keys()) + list(all_config_permutations_atomics[0].keys()))):\n",
    "    display(result_df.groupby([\"type\", key])[[\"auc\", \"acc\", \"f1\"]].mean())\n",
    "\n",
    "display(result_df.groupby(\"type\")[[\"auc\", \"acc\", \"f1\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
