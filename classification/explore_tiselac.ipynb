{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import collections\n",
    "import os\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "y = y.astype(int)\n",
    "display(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(_X, _y, batch_size = 4096, random_state = 1):    \n",
    "    # swap T and V axis\n",
    "    _X = _X.swapaxes(1,2)\n",
    "    \n",
    "    ## target\n",
    "    _y = _y-1\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    # class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    # split 60/20/20 %\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "    # normalize\n",
    "    X_train, X_val, X_test = normalize_across_time(X_train, X_val, X_test)\n",
    "\n",
    "    # tensor\n",
    "    X_train_pt = torch.tensor(X_train)\n",
    "    X_train_pt = add_indicators(X_train_pt)\n",
    "    y_train_pt = torch.tensor(y_train)\n",
    "\n",
    "    X_val_pt = torch.tensor(X_val)\n",
    "    X_val_pt = add_indicators(X_val_pt)\n",
    "    y_val_pt = torch.tensor(y_val)\n",
    "\n",
    "    X_test_pt = torch.tensor(X_test)\n",
    "    X_test_pt = add_indicators(X_test_pt)\n",
    "    y_test_pt = torch.tensor(y_test)\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = TensorDataset(X_train_pt, y_train_pt)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val_pt, y_val_pt)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = X_val_pt.shape[0], shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_pt, y_test_pt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = X_test_pt.shape[0], shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def add_indicators(data: torch.Tensor):\n",
    "    indicators_3d = ~torch.isnan(data)\n",
    "    data = torch.cat([data, indicators_3d], axis=-1) # (N x seq_len x 2*changing_dim)\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test):\n",
    "    \n",
    "    # scalerX=StandardScaler(with_std=False)\n",
    "    scalerX=RobustScaler()\n",
    "    n_variables = 10\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 23, 20])\n",
      "torch.Size([4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, weights, num_classes = preprocess_data(X,y)\n",
    "\n",
    "for a,b in train_loader:\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim, top_k=''):\n",
    "    model = original_models.CBM(input_dim = input_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                opt_lr = 2e-4,\n",
    "                                opt_weight_decay = 2e-05,\n",
    "                                l1_lambda=0.001,\n",
    "                                cos_sim_lambda=0.01,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, output_dim, use_summaries_for_atomics, use_indicators, top_k=''):\n",
    "    model = new_models.CBM(input_dim = input_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-4,\n",
    "                            l1_lambda=1e-6,\n",
    "                            cos_sim_lambda=1e-5,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 20 23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "seq_len = X.shape[2]\n",
    "changing_dim = X.shape[1]\n",
    "input_dim = 2 * changing_dim\n",
    "\n",
    "print(changing_dim, input_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/original/\"\n",
    "model_path = experiment_folder + \"tiselac_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 377/10000 [06:10<2:34:00,  1.04it/s]"
     ]
    }
   ],
   "source": [
    "history_original = []\n",
    "\n",
    "train_loader, val_loader, test_loader, weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "n_concepts_list = list(range(5, 50, 5))\n",
    "\n",
    "for n_concepts in n_concepts_list:\n",
    "    print(n_concepts)\n",
    "    \n",
    "    model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "    model.fit(train_loader, val_loader, weights.to(device), model_path.format(n_concepts), 10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            probs = model.forward_probabilities(Xb)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    history_original.append(np.array(history))\n",
    "    \n",
    "    plot_losses(model.train_losses, model.val_losses)\n",
    "    \n",
    "history_original = np.array(history_original)\n",
    "history_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_concepts_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 8\u001b[0m, in \u001b[0;36mplot_metrics\u001b[0;34m(history, n_concepts_list)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metrics\u001b[39m(history, n_concepts_list):\n\u001b[0;32m----> 8\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, history[:, \u001b[38;5;241m2\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history[:, \u001b[38;5;241m0\u001b[39m], history[:, \u001b[38;5;241m3\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot(history[:, \u001b[38;5;241m0\u001b[39m], history[:, \u001b[38;5;241m4\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "plot_metrics(history_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/atomics/\"\n",
    "model_path = experiment_folder + \"tiselac_a{}_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ? epoch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_concepts)\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, num_classes, use_summaries_for_atomics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_indicators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_atomics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_concepts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/workdir/optimal-summaries-public/classification/../models/models_3d_atomics_on_variate_to_concepts.py:579\u001b[0m, in \u001b[0;36mCBM.fit\u001b[0;34m(self, train_loader, val_loader, p_weight, save_model_path, max_epochs, save_every_n_epochs, patience, warmup_epochs, scheduler, trial, show_grad)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m Xb, yb \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    578\u001b[0m     Xb, yb \u001b[38;5;241m=\u001b[39m Xb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), yb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 579\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mXb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(yb, y_pred, p_weight)\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workdir/optimal-summaries-public/classification/../models/models_3d_atomics_on_variate_to_concepts.py:441\u001b[0m, in \u001b[0;36mCBM.forward\u001b[0;34m(self, patient_batch, epsilon_denom)\u001b[0m\n\u001b[1;32m    438\u001b[0m patient_and_summaries \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([rearranged] \u001b[38;5;241m+\u001b[39m summaries, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;66;03m# print(\"patient_and_summaries\", patient_and_summaries.shape)\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m atomics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_time_to_atomics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient_and_summaries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m atomics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_func(atomics)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# print(\"after atomics\", atomics.shape)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1212\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1209\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1210\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1212\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "train_loader, val_loader, test_loader, weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "n_atomics_list = list(range(5, 50, 5))\n",
    "n_concepts_list = list(range(5, 50, 5))\n",
    "\n",
    "for n_atomics in n_atomics_list:\n",
    "    for n_concepts in n_concepts_list:\n",
    "        print(n_concepts)\n",
    "        \n",
    "        model = initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, num_classes, use_summaries_for_atomics=True, use_indicators=False)\n",
    "        model.fit(train_loader, val_loader, p_weight=weights.to(device), save_model_path=model_path.format(n_atomics, n_concepts), max_epochs=10000)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                probs = model.forward_probabilities(Xb)\n",
    "                \n",
    "                auc = auroc_metric(probs, yb).item()\n",
    "                acc = accuracy_metric(probs, yb).item()\n",
    "                f1 = f1_metric(probs, yb).item()\n",
    "                # conf_matrix(probs, yb)\n",
    "            auc = auroc_metric.compute().item()\n",
    "            acc = accuracy_metric.compute().item()\n",
    "            f1 = f1_metric.compute().item()\n",
    "            # conf_matrix.plot()\n",
    "            # plt.show()\n",
    "            auroc_metric.reset()\n",
    "            accuracy_metric.reset()\n",
    "            # conf_matrix.reset()\n",
    "            f1_metric.reset()\n",
    "        \n",
    "        history = [n_atomics, n_concepts, model.val_losses[-1], auc, acc, f1]\n",
    "        print(history)\n",
    "        history_atomics.append(np.array(history))\n",
    "        \n",
    "        # plot_losses(model.train_losses, model.val_losses)\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history_atomics, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
