{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:10\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "from einops import rearrange\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "y = y.astype(int)\n",
    "display(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_time, _y, batch_size = 512, random_state = 1):\n",
    "    # X\n",
    "    X_time = rearrange(X_time, \"b v t -> b t v\")\n",
    "    \n",
    "    X_ind = ~np.isnan(X_time)\n",
    "    X_time = np.nan_to_num(X_time, nan=0.0)\n",
    "    \n",
    "    # Target\n",
    "    _y = _y - 1\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    \n",
    "    # Class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    \n",
    "    # Split\n",
    "    X_time_train, X_time_test, X_ind_train, X_ind_test, y_train, y_test = train_test_split(X_time, X_ind, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_time_test, X_time_val, X_ind_test, X_ind_val, y_test, y_val = train_test_split(X_time_test, X_ind_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "\n",
    "    # Normalize\n",
    "    X_time_train, X_time_val, X_time_test = normalize_across_time(X_time_train, X_time_val, X_time_test, X_time.shape[2])\n",
    "    \n",
    "    \n",
    "    # Datasets\n",
    "    X_time_train = torch.tensor(X_time_train, dtype=torch.float32)\n",
    "    X_ind_train = torch.tensor(X_ind_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train)\n",
    "\n",
    "    X_time_val = torch.tensor(X_time_val, dtype=torch.float32)\n",
    "    X_ind_val = torch.tensor(X_ind_val, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val)\n",
    "\n",
    "    X_time_test = torch.tensor(X_time_test, dtype=torch.float32)\n",
    "    X_ind_test = torch.tensor(X_ind_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "    # Dataloaders\n",
    "    train_dataset = TensorDataset(X_time_train, X_ind_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataset = TensorDataset(X_time_val, X_ind_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    test_dataset = TensorDataset(X_time_test, X_ind_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test, n_variables):\n",
    "    # scalerX=StandardScaler(with_std=False)\n",
    "    scalerX=StandardScaler()\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5538, 2.8525, 0.5538, 0.5710, 0.7132, 1.6248, 1.2057, 6.3149, 3.5524],\n",
      "       device='cuda:10') 9\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for batch in train_loader:\n",
    "    [print(t.shape) for t in batch]\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                    use_indicators, use_fixes, use_only_last_timestep, top_k=''):\n",
    "    model = original_models.CBM(static_dim = static_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = use_indicators,\n",
    "                                use_fixes = use_fixes,\n",
    "                                use_only_last_timestep = use_only_last_timestep,\n",
    "                                use_grad_norm = False,\n",
    "                                noise_std = False,\n",
    "                                use_multiplicative_interactions = False,\n",
    "                                use_summaries = True,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=1e-3,\n",
    "                                cos_sim_lambda=1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                                 use_summaries_for_atomics, use_indicators, use_fixes, top_k=''):\n",
    "    model = new_models.CBM(static_dim = static_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            use_fixes = use_fixes,\n",
    "                            use_grad_norm = False,\n",
    "                            noise_std = False,\n",
    "                            use_summaries = True,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=1e-3,\n",
    "                            cos_sim_lambda=1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 23\n"
     ]
    }
   ],
   "source": [
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "seq_len = X.shape[2]\n",
    "changing_dim = X.shape[1]\n",
    "static_dim = 0\n",
    "\n",
    "print(changing_dim, static_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "config_original = {\n",
    "    \"n_concepts\": [4, 20],\n",
    "    # \"use_summaries\": [True, False],\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_only_last_timestep\": [True, False],\n",
    "    # \"use_grad_norm\": [False, \"FULL\", \"COMPONENT_WISE\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_og = list(product(*config_original.values()))\n",
    "all_config_permutations_og = [dict(zip(config_original.keys(), permutation)) for permutation in all_config_permutations_og]\n",
    "print(len(all_config_permutations_og))\n",
    "# all_config_permutations_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/original/\"\n",
    "# model_path = experiment_folder + \"tiselac_c{n_concepts}_use_multiplicative_interactions_{use_multiplicative_interactions}.pt\"\n",
    "model_path = experiment_folder + \"tiselac_c{n_concepts}_ind{use_indicators}_fixes{use_fixes}_onlylasttimestep{use_only_last_timestep}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1669/10000 [59:04<4:54:54,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.8667049407958984, 0.9579613208770752, 0.753222644329071, 0.753222644329071]\n",
      "1 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 809/10000 [30:10<5:42:49,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.8356211185455322, 0.9638531804084778, 0.77980637550354, 0.77980637550354]\n",
      "2 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1719/10000 [1:02:53<5:02:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.8578628897666931, 0.9580385684967041, 0.761498749256134, 0.761498749256134]\n",
      "3 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 899/10000 [33:24<5:38:11,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.8300090432167053, 0.9632604718208313, 0.7772985100746155, 0.7772985100746155]\n",
      "4 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 24%|██▍       | 2389/10000 [1:18:35<4:10:24,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.8863508105278015, 0.9539850950241089, 0.7559311985969543, 0.7559311985969543]\n",
      "5 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 909/10000 [29:44<4:57:30,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.8466687202453613, 0.9609977006912231, 0.7555299401283264, 0.7555299401283264]\n",
      "6 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 989/10000 [32:31<4:56:16,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.9047031998634338, 0.9521624445915222, 0.7566334009170532, 0.7566334009170532]\n",
      "7 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 889/10000 [29:11<4:59:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 7, 0.8360020518302917, 0.9617575407028198, 0.7552791237831116, 0.7552791237831116]\n",
      "8 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▌        | 1529/10000 [55:09<5:05:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 8, 0.7979497313499451, 0.9674021601676941, 0.793148398399353, 0.793148398399353]\n",
      "9 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1029/10000 [37:24<5:26:07,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 9, 0.7601749300956726, 0.9729850888252258, 0.7724833488464355, 0.7724833488464355]\n",
      "10 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1559/10000 [56:21<5:05:09,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 10, 0.7911361455917358, 0.9674754738807678, 0.783568263053894, 0.783568263053894]\n",
      "11 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 699/10000 [26:12<5:48:44,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 11, 0.7855161428451538, 0.9720660448074341, 0.7974118590354919, 0.7974118590354919]\n",
      "12 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 11%|█▏        | 1129/10000 [37:05<4:51:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 12, 0.8191789388656616, 0.9618381857872009, 0.774941086769104, 0.774941086769104]\n",
      "13 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 729/10000 [24:17<5:08:50,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 13, 0.7515957951545715, 0.972728967666626, 0.7964588403701782, 0.7964588403701782]\n",
      "14 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▍        | 1499/10000 [49:09<4:38:49,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 14, 0.8195425271987915, 0.9632771611213684, 0.7796057462692261, 0.7796057462692261]\n",
      "15 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 899/10000 [29:48<5:01:43,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 15, 0.749521791934967, 0.973850667476654, 0.8213873505592346, 0.8213873505592346]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_og):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "    \n",
    "    model = initializeModel(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            *data, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(*data)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [\"original\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    histories_original.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "config_atomics = {\n",
    "    \"n_atomics\": [10, 30], # 30\n",
    "    \"n_concepts\": [4, 20], # 20\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_summaries_for_atomics\": [True, False],\n",
    "    # \"use_grad_norm\": [False, \"FULL\", \"COMPONENT_WISE\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_atomics = list(product(*config_atomics.values()))\n",
    "all_config_permutations_atomics = [dict(zip(config_atomics.keys(), permutation)) for permutation in all_config_permutations_atomics]\n",
    "print(len(all_config_permutations_atomics))\n",
    "# all_config_permutations_atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/atomics/\"\n",
    "model_path = experiment_folder + \"tiselac_c{n_atomics}_c{n_concepts}_ind{use_indicators}_fixes{use_fixes}_summaries{use_summaries_for_atomics}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 19%|█▊        | 1860/10000 [1:15:19<5:29:37,  2.43s/ epoch, Train Loss=0.83698, Val Loss=0.84341, Best Val Loss=0.84157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.8473899960517883, 0.9651008248329163, 0.7768470644950867, 0.7768470644950867]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1850/10000 [1:14:16<5:27:14,  2.41s/ epoch, Train Loss=0.85473, Val Loss=0.85909, Best Val Loss=0.85683]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.8595662117004395, 0.9578717350959778, 0.7650599479675293, 0.7650599479675293]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 23%|██▎       | 2310/10000 [1:33:57<5:12:47,  2.44s/ epoch, Train Loss=0.83745, Val Loss=0.83675, Best Val Loss=0.83415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.8348634839057922, 0.9635878801345825, 0.7762451767921448, 0.7762451767921448]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1610/10000 [1:04:40<5:37:02,  2.41s/ epoch, Train Loss=0.82691, Val Loss=0.83233, Best Val Loss=0.82939]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.8302735686302185, 0.9613693952560425, 0.7643577456474304, 0.7643577456474304]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 24%|██▍       | 2450/10000 [1:28:12<4:31:50,  2.16s/ epoch, Train Loss=0.85655, Val Loss=0.86431, Best Val Loss=0.86318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.8635403513908386, 0.9614143371582031, 0.7651602625846863, 0.7651602625846863]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 980/10000 [35:01<5:22:17,  2.14s/ epoch, Train Loss=0.87102, Val Loss=0.87722, Best Val Loss=0.87507]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.8759652972221375, 0.9554711580276489, 0.7512163519859314, 0.7512163519859314]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1820/10000 [1:05:42<4:55:20,  2.17s/ epoch, Train Loss=0.86861, Val Loss=0.87391, Best Val Loss=0.87174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.872816264629364, 0.9612035751342773, 0.7662637233734131, 0.7662637233734131]\n",
      "7 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▌        | 1520/10000 [54:31<5:04:08,  2.15s/ epoch, Train Loss=0.89217, Val Loss=0.90363, Best Val Loss=0.90037]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 7, 0.9015012979507446, 0.9525852203369141, 0.7496112585067749, 0.7496112585067749]\n",
      "8 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1690/10000 [1:07:35<5:32:21,  2.40s/ epoch, Train Loss=0.81003, Val Loss=0.81542, Best Val Loss=0.81233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 8, 0.8135256171226501, 0.9680449366569519, 0.7803581357002258, 0.7803581357002258]\n",
      "9 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1570/10000 [1:03:18<5:39:55,  2.42s/ epoch, Train Loss=0.76224, Val Loss=0.77543, Best Val Loss=0.77236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 9, 0.7742837071418762, 0.9694805145263672, 0.7917941808700562, 0.7917941808700562]\n",
      "10 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 19%|█▉        | 1910/10000 [1:22:20<5:48:44,  2.59s/ epoch, Train Loss=0.79033, Val Loss=0.79475, Best Val Loss=0.79292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 10, 0.8027811646461487, 0.9695811867713928, 0.7849726676940918, 0.7849726676940918]\n",
      "11 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 950/10000 [38:41<6:08:37,  2.44s/ epoch, Train Loss=0.78488, Val Loss=0.79495, Best Val Loss=0.79220]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 11, 0.7967868447303772, 0.9691286087036133, 0.7995184659957886, 0.7995184659957886]\n",
      "12 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▍        | 1460/10000 [50:31<4:55:29,  2.08s/ epoch, Train Loss=0.82078, Val Loss=0.82377, Best Val Loss=0.82315]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 12, 0.8257894515991211, 0.966426432132721, 0.7826653718948364, 0.7826653718948364]\n",
      "13 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 980/10000 [33:24<5:09:47,  2.06s/ epoch, Train Loss=0.80184, Val Loss=0.81867, Best Val Loss=0.81501]"
     ]
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_atomics):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)#, batch_size=8)\n",
    "    \n",
    "    model = initializeModel_with_atomics(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim = num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            X_time, X_ind, X_static, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(X_time, X_ind, X_static)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "\n",
    "    history = [\"atomics\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    history_atomics.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = pd.concat([df_og, pd.DataFrame(all_config_permutations_og)], axis=1)\n",
    "\n",
    "df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "df_atomics = pd.concat([df_atomics, pd.DataFrame(all_config_permutations_atomics)], axis=1)\n",
    "\n",
    "result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.790527880191803\n",
      "acc 0.38165220618247986\n",
      "f1 0.38165220618247986\n"
     ]
    }
   ],
   "source": [
    "for col in result_df.columns[3:6]:\n",
    "    baseline = result_df[(result_df['type'] == 'original') & (result_df['config'] == 0)][col].values[0]\n",
    "    print(col, baseline)\n",
    "    result_df[f'{col}_abs_imp'] = result_df[col] - baseline\n",
    "    # result_df[f'{col}_rel_imp'] = result_df[f'{col}_abs_imp'] / baseline\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>config</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th>auc_abs_imp</th>\n",
       "      <th>acc_abs_imp</th>\n",
       "      <th>f1_abs_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>original</td>\n",
       "      <td>10</td>\n",
       "      <td>1.428310</td>\n",
       "      <td>0.872840</td>\n",
       "      <td>0.523499</td>\n",
       "      <td>0.523499</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082313</td>\n",
       "      <td>0.141847</td>\n",
       "      <td>0.141847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>original</td>\n",
       "      <td>11</td>\n",
       "      <td>1.610414</td>\n",
       "      <td>0.845214</td>\n",
       "      <td>0.513718</td>\n",
       "      <td>0.513718</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054686</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.132066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>1.678972</td>\n",
       "      <td>0.817154</td>\n",
       "      <td>0.513066</td>\n",
       "      <td>0.513066</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026626</td>\n",
       "      <td>0.131414</td>\n",
       "      <td>0.131414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original</td>\n",
       "      <td>15</td>\n",
       "      <td>1.617902</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.510307</td>\n",
       "      <td>0.510307</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>0.128655</td>\n",
       "      <td>0.128655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>1.679120</td>\n",
       "      <td>0.819199</td>\n",
       "      <td>0.508050</td>\n",
       "      <td>0.508050</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.126398</td>\n",
       "      <td>0.126398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original</td>\n",
       "      <td>12</td>\n",
       "      <td>1.481312</td>\n",
       "      <td>0.858093</td>\n",
       "      <td>0.507850</td>\n",
       "      <td>0.507850</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067565</td>\n",
       "      <td>0.126198</td>\n",
       "      <td>0.126198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "      <td>1.451083</td>\n",
       "      <td>0.865080</td>\n",
       "      <td>0.503386</td>\n",
       "      <td>0.503386</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074552</td>\n",
       "      <td>0.121733</td>\n",
       "      <td>0.121733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original</td>\n",
       "      <td>9</td>\n",
       "      <td>1.607566</td>\n",
       "      <td>0.852465</td>\n",
       "      <td>0.502934</td>\n",
       "      <td>0.502934</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061938</td>\n",
       "      <td>0.121282</td>\n",
       "      <td>0.121282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>original</td>\n",
       "      <td>14</td>\n",
       "      <td>1.495261</td>\n",
       "      <td>0.854833</td>\n",
       "      <td>0.487536</td>\n",
       "      <td>0.487536</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064305</td>\n",
       "      <td>0.105884</td>\n",
       "      <td>0.105884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>1.670833</td>\n",
       "      <td>0.805878</td>\n",
       "      <td>0.483022</td>\n",
       "      <td>0.483022</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.101369</td>\n",
       "      <td>0.101369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>1.610055</td>\n",
       "      <td>0.809933</td>\n",
       "      <td>0.473542</td>\n",
       "      <td>0.473542</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019405</td>\n",
       "      <td>0.091889</td>\n",
       "      <td>0.091889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>1.688045</td>\n",
       "      <td>0.807421</td>\n",
       "      <td>0.461704</td>\n",
       "      <td>0.461704</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.080052</td>\n",
       "      <td>0.080052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "      <td>1.727158</td>\n",
       "      <td>0.799343</td>\n",
       "      <td>0.437277</td>\n",
       "      <td>0.437277</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.055625</td>\n",
       "      <td>0.055625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original</td>\n",
       "      <td>13</td>\n",
       "      <td>1.638783</td>\n",
       "      <td>0.837783</td>\n",
       "      <td>0.434318</td>\n",
       "      <td>0.434318</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047255</td>\n",
       "      <td>0.052666</td>\n",
       "      <td>0.052666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>1.616329</td>\n",
       "      <td>0.830558</td>\n",
       "      <td>0.400712</td>\n",
       "      <td>0.400712</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040030</td>\n",
       "      <td>0.019060</td>\n",
       "      <td>0.019060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>1.679723</td>\n",
       "      <td>0.790528</td>\n",
       "      <td>0.381652</td>\n",
       "      <td>0.381652</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>atomics</td>\n",
       "      <td>24</td>\n",
       "      <td>0.810045</td>\n",
       "      <td>0.580610</td>\n",
       "      <td>0.210764</td>\n",
       "      <td>0.210764</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.209918</td>\n",
       "      <td>-0.170888</td>\n",
       "      <td>-0.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.871616</td>\n",
       "      <td>0.554381</td>\n",
       "      <td>0.206651</td>\n",
       "      <td>0.206651</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.236147</td>\n",
       "      <td>-0.175001</td>\n",
       "      <td>-0.175001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857391</td>\n",
       "      <td>0.543016</td>\n",
       "      <td>0.197221</td>\n",
       "      <td>0.197221</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.247512</td>\n",
       "      <td>-0.184431</td>\n",
       "      <td>-0.184431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>atomics</td>\n",
       "      <td>30</td>\n",
       "      <td>0.841339</td>\n",
       "      <td>0.538251</td>\n",
       "      <td>0.192506</td>\n",
       "      <td>0.192506</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.252277</td>\n",
       "      <td>-0.189146</td>\n",
       "      <td>-0.189146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>atomics</td>\n",
       "      <td>19</td>\n",
       "      <td>0.867254</td>\n",
       "      <td>0.572738</td>\n",
       "      <td>0.190149</td>\n",
       "      <td>0.190149</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.217790</td>\n",
       "      <td>-0.191503</td>\n",
       "      <td>-0.191503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.536304</td>\n",
       "      <td>0.189998</td>\n",
       "      <td>0.189998</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.254224</td>\n",
       "      <td>-0.191654</td>\n",
       "      <td>-0.191654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>atomics</td>\n",
       "      <td>18</td>\n",
       "      <td>0.857374</td>\n",
       "      <td>0.526976</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.263552</td>\n",
       "      <td>-0.191854</td>\n",
       "      <td>-0.191854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>atomics</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809852</td>\n",
       "      <td>0.496724</td>\n",
       "      <td>0.187992</td>\n",
       "      <td>0.187992</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.293804</td>\n",
       "      <td>-0.193660</td>\n",
       "      <td>-0.193660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>atomics</td>\n",
       "      <td>23</td>\n",
       "      <td>0.983208</td>\n",
       "      <td>0.557478</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>0.180017</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.233050</td>\n",
       "      <td>-0.201635</td>\n",
       "      <td>-0.201635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>atomics</td>\n",
       "      <td>21</td>\n",
       "      <td>0.973377</td>\n",
       "      <td>0.518165</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>0.169634</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.272363</td>\n",
       "      <td>-0.212018</td>\n",
       "      <td>-0.212018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>atomics</td>\n",
       "      <td>13</td>\n",
       "      <td>0.824144</td>\n",
       "      <td>0.562654</td>\n",
       "      <td>0.167879</td>\n",
       "      <td>0.167879</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.227874</td>\n",
       "      <td>-0.213773</td>\n",
       "      <td>-0.213773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>atomics</td>\n",
       "      <td>8</td>\n",
       "      <td>0.809808</td>\n",
       "      <td>0.515674</td>\n",
       "      <td>0.165070</td>\n",
       "      <td>0.165070</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.274853</td>\n",
       "      <td>-0.216582</td>\n",
       "      <td>-0.216582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.860238</td>\n",
       "      <td>0.515150</td>\n",
       "      <td>0.162060</td>\n",
       "      <td>0.162060</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.275378</td>\n",
       "      <td>-0.219592</td>\n",
       "      <td>-0.219592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>atomics</td>\n",
       "      <td>7</td>\n",
       "      <td>0.890646</td>\n",
       "      <td>0.546477</td>\n",
       "      <td>0.160255</td>\n",
       "      <td>0.160255</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.244051</td>\n",
       "      <td>-0.221397</td>\n",
       "      <td>-0.221397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>atomics</td>\n",
       "      <td>12</td>\n",
       "      <td>0.817190</td>\n",
       "      <td>0.484343</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.306185</td>\n",
       "      <td>-0.226012</td>\n",
       "      <td>-0.226012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.864065</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.275677</td>\n",
       "      <td>-0.228720</td>\n",
       "      <td>-0.228720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>atomics</td>\n",
       "      <td>29</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.526162</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>0.151929</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.264366</td>\n",
       "      <td>-0.229724</td>\n",
       "      <td>-0.229724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>atomics</td>\n",
       "      <td>20</td>\n",
       "      <td>0.895609</td>\n",
       "      <td>0.560629</td>\n",
       "      <td>0.150825</td>\n",
       "      <td>0.150825</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.229899</td>\n",
       "      <td>-0.230827</td>\n",
       "      <td>-0.230827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.537894</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>0.147465</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.252633</td>\n",
       "      <td>-0.234188</td>\n",
       "      <td>-0.234188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>atomics</td>\n",
       "      <td>14</td>\n",
       "      <td>0.822551</td>\n",
       "      <td>0.510876</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>0.143753</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.279652</td>\n",
       "      <td>-0.237899</td>\n",
       "      <td>-0.237899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>atomics</td>\n",
       "      <td>28</td>\n",
       "      <td>0.862237</td>\n",
       "      <td>0.538899</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>0.142700</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.251629</td>\n",
       "      <td>-0.238953</td>\n",
       "      <td>-0.238953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>atomics</td>\n",
       "      <td>17</td>\n",
       "      <td>0.879067</td>\n",
       "      <td>0.591784</td>\n",
       "      <td>0.141747</td>\n",
       "      <td>0.141747</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.198744</td>\n",
       "      <td>-0.239906</td>\n",
       "      <td>-0.239906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>atomics</td>\n",
       "      <td>26</td>\n",
       "      <td>0.853337</td>\n",
       "      <td>0.493805</td>\n",
       "      <td>0.136380</td>\n",
       "      <td>0.136380</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.296723</td>\n",
       "      <td>-0.245273</td>\n",
       "      <td>-0.245273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>atomics</td>\n",
       "      <td>25</td>\n",
       "      <td>0.781285</td>\n",
       "      <td>0.543855</td>\n",
       "      <td>0.126198</td>\n",
       "      <td>0.126198</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.246673</td>\n",
       "      <td>-0.255455</td>\n",
       "      <td>-0.255455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>atomics</td>\n",
       "      <td>27</td>\n",
       "      <td>0.810739</td>\n",
       "      <td>0.556086</td>\n",
       "      <td>0.124994</td>\n",
       "      <td>0.124994</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.234442</td>\n",
       "      <td>-0.256658</td>\n",
       "      <td>-0.256658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>atomics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.857071</td>\n",
       "      <td>0.527303</td>\n",
       "      <td>0.109846</td>\n",
       "      <td>0.109846</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.263225</td>\n",
       "      <td>-0.271806</td>\n",
       "      <td>-0.271806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>atomics</td>\n",
       "      <td>22</td>\n",
       "      <td>0.886329</td>\n",
       "      <td>0.486191</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>0.104278</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.304336</td>\n",
       "      <td>-0.277374</td>\n",
       "      <td>-0.277374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>atomics</td>\n",
       "      <td>11</td>\n",
       "      <td>0.779027</td>\n",
       "      <td>0.508510</td>\n",
       "      <td>0.091237</td>\n",
       "      <td>0.091237</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.282018</td>\n",
       "      <td>-0.290415</td>\n",
       "      <td>-0.290415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>atomics</td>\n",
       "      <td>9</td>\n",
       "      <td>0.791102</td>\n",
       "      <td>0.497420</td>\n",
       "      <td>0.091087</td>\n",
       "      <td>0.091087</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.293108</td>\n",
       "      <td>-0.290565</td>\n",
       "      <td>-0.290565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>atomics</td>\n",
       "      <td>31</td>\n",
       "      <td>0.886055</td>\n",
       "      <td>0.489969</td>\n",
       "      <td>0.076993</td>\n",
       "      <td>0.076993</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.300559</td>\n",
       "      <td>-0.304660</td>\n",
       "      <td>-0.304660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>atomics</td>\n",
       "      <td>15</td>\n",
       "      <td>0.796267</td>\n",
       "      <td>0.536512</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>0.069569</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.254016</td>\n",
       "      <td>-0.312083</td>\n",
       "      <td>-0.312083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.861130</td>\n",
       "      <td>0.535435</td>\n",
       "      <td>0.058334</td>\n",
       "      <td>0.058334</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.255093</td>\n",
       "      <td>-0.323318</td>\n",
       "      <td>-0.323318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  config  val_loss       auc       acc        f1  n_concepts  \\\n",
       "10  original      10  1.428310  0.872840  0.523499  0.523499          20   \n",
       "11  original      11  1.610414  0.845214  0.513718  0.513718          20   \n",
       "6   original       6  1.678972  0.817154  0.513066  0.513066           4   \n",
       "15  original      15  1.617902  0.843800  0.510307  0.510307          20   \n",
       "5   original       5  1.679120  0.819199  0.508050  0.508050           4   \n",
       "12  original      12  1.481312  0.858093  0.507850  0.507850          20   \n",
       "8   original       8  1.451083  0.865080  0.503386  0.503386          20   \n",
       "9   original       9  1.607566  0.852465  0.502934  0.502934          20   \n",
       "14  original      14  1.495261  0.854833  0.487536  0.487536          20   \n",
       "4   original       4  1.670833  0.805878  0.483022  0.483022           4   \n",
       "2   original       2  1.610055  0.809933  0.473542  0.473542           4   \n",
       "3   original       3  1.688045  0.807421  0.461704  0.461704           4   \n",
       "7   original       7  1.727158  0.799343  0.437277  0.437277           4   \n",
       "13  original      13  1.638783  0.837783  0.434318  0.434318          20   \n",
       "1   original       1  1.616329  0.830558  0.400712  0.400712           4   \n",
       "0   original       0  1.679723  0.790528  0.381652  0.381652           4   \n",
       "40   atomics      24  0.810045  0.580610  0.210764  0.210764          20   \n",
       "22   atomics       6  0.871616  0.554381  0.206651  0.206651           4   \n",
       "17   atomics       1  0.857391  0.543016  0.197221  0.197221           4   \n",
       "46   atomics      30  0.841339  0.538251  0.192506  0.192506          20   \n",
       "35   atomics      19  0.867254  0.572738  0.190149  0.190149           4   \n",
       "16   atomics       0  0.854701  0.536304  0.189998  0.189998           4   \n",
       "34   atomics      18  0.857374  0.526976  0.189798  0.189798           4   \n",
       "26   atomics      10  0.809852  0.496724  0.187992  0.187992          20   \n",
       "39   atomics      23  0.983208  0.557478  0.180017  0.180017           4   \n",
       "37   atomics      21  0.973377  0.518165  0.169634  0.169634           4   \n",
       "29   atomics      13  0.824144  0.562654  0.167879  0.167879          20   \n",
       "24   atomics       8  0.809808  0.515674  0.165070  0.165070          20   \n",
       "18   atomics       2  0.860238  0.515150  0.162060  0.162060           4   \n",
       "23   atomics       7  0.890646  0.546477  0.160255  0.160255           4   \n",
       "28   atomics      12  0.817190  0.484343  0.155640  0.155640          20   \n",
       "20   atomics       4  0.864065  0.514851  0.152932  0.152932           4   \n",
       "45   atomics      29  0.899650  0.526162  0.151929  0.151929          20   \n",
       "36   atomics      20  0.895609  0.560629  0.150825  0.150825           4   \n",
       "21   atomics       5  0.898100  0.537894  0.147465  0.147465           4   \n",
       "30   atomics      14  0.822551  0.510876  0.143753  0.143753          20   \n",
       "44   atomics      28  0.862237  0.538899  0.142700  0.142700          20   \n",
       "33   atomics      17  0.879067  0.591784  0.141747  0.141747           4   \n",
       "42   atomics      26  0.853337  0.493805  0.136380  0.136380          20   \n",
       "41   atomics      25  0.781285  0.543855  0.126198  0.126198          20   \n",
       "43   atomics      27  0.810739  0.556086  0.124994  0.124994          20   \n",
       "32   atomics      16  0.857071  0.527303  0.109846  0.109846           4   \n",
       "38   atomics      22  0.886329  0.486191  0.104278  0.104278           4   \n",
       "27   atomics      11  0.779027  0.508510  0.091237  0.091237          20   \n",
       "25   atomics       9  0.791102  0.497420  0.091087  0.091087          20   \n",
       "47   atomics      31  0.886055  0.489969  0.076993  0.076993          20   \n",
       "31   atomics      15  0.796267  0.536512  0.069569  0.069569          20   \n",
       "19   atomics       3  0.861130  0.535435  0.058334  0.058334           4   \n",
       "\n",
       "    use_indicators  use_fixes use_only_last_timestep  n_atomics  \\\n",
       "10            True       True                   True        NaN   \n",
       "11            True       True                  False        NaN   \n",
       "6            False       True                   True        NaN   \n",
       "15           False       True                  False        NaN   \n",
       "5            False      False                  False        NaN   \n",
       "12           False      False                   True        NaN   \n",
       "8             True      False                   True        NaN   \n",
       "9             True      False                  False        NaN   \n",
       "14           False       True                   True        NaN   \n",
       "4            False      False                   True        NaN   \n",
       "2             True       True                   True        NaN   \n",
       "3             True       True                  False        NaN   \n",
       "7            False       True                  False        NaN   \n",
       "13           False      False                  False        NaN   \n",
       "1             True      False                  False        NaN   \n",
       "0             True      False                   True        NaN   \n",
       "40            True      False                    NaN       30.0   \n",
       "22           False       True                    NaN       10.0   \n",
       "17            True      False                    NaN       10.0   \n",
       "46           False       True                    NaN       30.0   \n",
       "35            True       True                    NaN       30.0   \n",
       "16            True      False                    NaN       10.0   \n",
       "34            True       True                    NaN       30.0   \n",
       "26            True       True                    NaN       10.0   \n",
       "39           False       True                    NaN       30.0   \n",
       "37           False      False                    NaN       30.0   \n",
       "29           False      False                    NaN       10.0   \n",
       "24            True      False                    NaN       10.0   \n",
       "18            True       True                    NaN       10.0   \n",
       "23           False       True                    NaN       10.0   \n",
       "28           False      False                    NaN       10.0   \n",
       "20           False      False                    NaN       10.0   \n",
       "45           False      False                    NaN       30.0   \n",
       "36           False      False                    NaN       30.0   \n",
       "21           False      False                    NaN       10.0   \n",
       "30           False       True                    NaN       10.0   \n",
       "44           False      False                    NaN       30.0   \n",
       "33            True      False                    NaN       30.0   \n",
       "42            True       True                    NaN       30.0   \n",
       "41            True      False                    NaN       30.0   \n",
       "43            True       True                    NaN       30.0   \n",
       "32            True      False                    NaN       30.0   \n",
       "38           False       True                    NaN       30.0   \n",
       "27            True       True                    NaN       10.0   \n",
       "25            True      False                    NaN       10.0   \n",
       "47           False       True                    NaN       30.0   \n",
       "31           False       True                    NaN       10.0   \n",
       "19            True       True                    NaN       10.0   \n",
       "\n",
       "   use_summaries_for_atomics  auc_abs_imp  acc_abs_imp  f1_abs_imp  \n",
       "10                       NaN     0.082313     0.141847    0.141847  \n",
       "11                       NaN     0.054686     0.132066    0.132066  \n",
       "6                        NaN     0.026626     0.131414    0.131414  \n",
       "15                       NaN     0.053272     0.128655    0.128655  \n",
       "5                        NaN     0.028671     0.126398    0.126398  \n",
       "12                       NaN     0.067565     0.126198    0.126198  \n",
       "8                        NaN     0.074552     0.121733    0.121733  \n",
       "9                        NaN     0.061938     0.121282    0.121282  \n",
       "14                       NaN     0.064305     0.105884    0.105884  \n",
       "4                        NaN     0.015350     0.101369    0.101369  \n",
       "2                        NaN     0.019405     0.091889    0.091889  \n",
       "3                        NaN     0.016893     0.080052    0.080052  \n",
       "7                        NaN     0.008815     0.055625    0.055625  \n",
       "13                       NaN     0.047255     0.052666    0.052666  \n",
       "1                        NaN     0.040030     0.019060    0.019060  \n",
       "0                        NaN     0.000000     0.000000    0.000000  \n",
       "40                      True    -0.209918    -0.170888   -0.170888  \n",
       "22                      True    -0.236147    -0.175001   -0.175001  \n",
       "17                     False    -0.247512    -0.184431   -0.184431  \n",
       "46                      True    -0.252277    -0.189146   -0.189146  \n",
       "35                     False    -0.217790    -0.191503   -0.191503  \n",
       "16                      True    -0.254224    -0.191654   -0.191654  \n",
       "34                      True    -0.263552    -0.191854   -0.191854  \n",
       "26                      True    -0.293804    -0.193660   -0.193660  \n",
       "39                     False    -0.233050    -0.201635   -0.201635  \n",
       "37                     False    -0.272363    -0.212018   -0.212018  \n",
       "29                     False    -0.227874    -0.213773   -0.213773  \n",
       "24                      True    -0.274853    -0.216582   -0.216582  \n",
       "18                      True    -0.275378    -0.219592   -0.219592  \n",
       "23                     False    -0.244051    -0.221397   -0.221397  \n",
       "28                      True    -0.306185    -0.226012   -0.226012  \n",
       "20                      True    -0.275677    -0.228720   -0.228720  \n",
       "45                     False    -0.264366    -0.229724   -0.229724  \n",
       "36                      True    -0.229899    -0.230827   -0.230827  \n",
       "21                     False    -0.252633    -0.234188   -0.234188  \n",
       "30                      True    -0.279652    -0.237899   -0.237899  \n",
       "44                      True    -0.251629    -0.238953   -0.238953  \n",
       "33                     False    -0.198744    -0.239906   -0.239906  \n",
       "42                      True    -0.296723    -0.245273   -0.245273  \n",
       "41                     False    -0.246673    -0.255455   -0.255455  \n",
       "43                     False    -0.234442    -0.256658   -0.256658  \n",
       "32                      True    -0.263225    -0.271806   -0.271806  \n",
       "38                      True    -0.304336    -0.277374   -0.277374  \n",
       "27                     False    -0.282018    -0.290415   -0.290415  \n",
       "25                     False    -0.293108    -0.290565   -0.290565  \n",
       "47                     False    -0.300559    -0.304660   -0.304660  \n",
       "31                     False    -0.254016    -0.312083   -0.312083  \n",
       "19                     False    -0.255093    -0.323318   -0.323318  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "result_df.sort_values(by='acc', ascending=False)\n",
    "# atomics: atomics, concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics\n",
    "# original: concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.524764</td>\n",
       "      <td>0.146696</td>\n",
       "      <td>0.146696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.538056</td>\n",
       "      <td>0.149922</td>\n",
       "      <td>0.149922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc       acc        f1\n",
       "type    n_atomics                              \n",
       "atomics 10.0       0.524764  0.146696  0.146696\n",
       "        30.0       0.538056  0.149922  0.149922"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>4</th>\n",
       "      <td>0.539048</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.156951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.523772</td>\n",
       "      <td>0.139668</td>\n",
       "      <td>0.139668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>4</th>\n",
       "      <td>0.810002</td>\n",
       "      <td>0.457378</td>\n",
       "      <td>0.457378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.853764</td>\n",
       "      <td>0.497944</td>\n",
       "      <td>0.497944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc       acc        f1\n",
       "type     n_concepts                              \n",
       "atomics  4           0.539048  0.156951  0.156951\n",
       "         20          0.523772  0.139668  0.139668\n",
       "original 4           0.810002  0.457378  0.457378\n",
       "         20          0.853764  0.497944  0.497944"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.536223</td>\n",
       "      <td>0.154433</td>\n",
       "      <td>0.154433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.526597</td>\n",
       "      <td>0.142185</td>\n",
       "      <td>0.142185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.832448</td>\n",
       "      <td>0.465241</td>\n",
       "      <td>0.465241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.831317</td>\n",
       "      <td>0.490081</td>\n",
       "      <td>0.490081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc       acc        f1\n",
       "type     use_fixes                              \n",
       "atomics  False      0.536223  0.154433  0.154433\n",
       "         True       0.526597  0.142185  0.142185\n",
       "original False      0.832448  0.465241  0.465241\n",
       "         True       0.831317  0.490081  0.490081"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.528983</td>\n",
       "      <td>0.148314</td>\n",
       "      <td>0.148314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.533837</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.148305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.829510</td>\n",
       "      <td>0.485178</td>\n",
       "      <td>0.485178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.834255</td>\n",
       "      <td>0.470143</td>\n",
       "      <td>0.470143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auc       acc        f1\n",
       "type     use_indicators                              \n",
       "atomics  False           0.528983  0.148314  0.148314\n",
       "         True            0.533837  0.148305  0.148305\n",
       "original False           0.829510  0.485178  0.485178\n",
       "         True            0.834255  0.470143  0.470143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.829473</td>\n",
       "      <td>0.471128</td>\n",
       "      <td>0.471128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.834292</td>\n",
       "      <td>0.484194</td>\n",
       "      <td>0.484194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      auc       acc        f1\n",
       "type     use_only_last_timestep                              \n",
       "original False                   0.829473  0.471128  0.471128\n",
       "         True                    0.834292  0.484194  0.484194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.53901</td>\n",
       "      <td>0.134044</td>\n",
       "      <td>0.134044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.162575</td>\n",
       "      <td>0.162575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       auc       acc        f1\n",
       "type    use_summaries_for_atomics                             \n",
       "atomics False                      0.53901  0.134044  0.134044\n",
       "        True                       0.52381  0.162575  0.162575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <td>0.531410</td>\n",
       "      <td>0.148309</td>\n",
       "      <td>0.148309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.831883</td>\n",
       "      <td>0.477661</td>\n",
       "      <td>0.477661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc       acc        f1\n",
       "type                                  \n",
       "atomics   0.531410  0.148309  0.148309\n",
       "original  0.831883  0.477661  0.477661"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in sorted(set(list(all_config_permutations_og[0].keys()) + list(all_config_permutations_atomics[0].keys()))):\n",
    "    display(result_df.groupby([\"type\", key])[[\"auc\", \"acc\", \"f1\"]].mean())\n",
    "\n",
    "display(result_df.groupby(\"type\")[[\"auc\", \"acc\", \"f1\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
