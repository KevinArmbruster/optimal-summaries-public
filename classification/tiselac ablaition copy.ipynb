{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:10\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "from einops import rearrange\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "y = y.astype(int)\n",
    "display(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_time, _y, batch_size = 512, random_state = 1):\n",
    "    # X\n",
    "    X_time = rearrange(X_time, \"b v t -> b t v\")\n",
    "    \n",
    "    X_ind = ~np.isnan(X_time)\n",
    "    X_time = np.nan_to_num(X_time, nan=0.0)\n",
    "    \n",
    "    # Target\n",
    "    _y = _y - 1\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    \n",
    "    # Class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    \n",
    "    # Split\n",
    "    X_time_train, X_time_test, X_ind_train, X_ind_test, y_train, y_test = train_test_split(X_time, X_ind, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_time_test, X_time_val, X_ind_test, X_ind_val, y_test, y_val = train_test_split(X_time_test, X_ind_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "\n",
    "    # Normalize\n",
    "    X_time_train, X_time_val, X_time_test = normalize_across_time(X_time_train, X_time_val, X_time_test, X_time.shape[2])\n",
    "    \n",
    "    \n",
    "    # Datasets\n",
    "    X_time_train = torch.tensor(X_time_train, dtype=torch.float32)\n",
    "    X_ind_train = torch.tensor(X_ind_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train)\n",
    "\n",
    "    X_time_val = torch.tensor(X_time_val, dtype=torch.float32)\n",
    "    X_ind_val = torch.tensor(X_ind_val, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val)\n",
    "\n",
    "    X_time_test = torch.tensor(X_time_test, dtype=torch.float32)\n",
    "    X_ind_test = torch.tensor(X_ind_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "    # Dataloaders\n",
    "    train_dataset = TensorDataset(X_time_train, X_ind_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataset = TensorDataset(X_time_val, X_ind_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    test_dataset = TensorDataset(X_time_test, X_ind_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test, n_variables):\n",
    "    # scalerX=StandardScaler(with_std=False)\n",
    "    scalerX=StandardScaler()\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5538, 2.8525, 0.5538, 0.5710, 0.7132, 1.6248, 1.2057, 6.3149, 3.5524],\n",
      "       device='cuda:10') 9\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for batch in train_loader:\n",
    "    [print(t.shape) for t in batch]\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                    use_indicators, use_fixes, use_only_last_timestep, top_k=''):\n",
    "    model = original_models.CBM(static_dim = static_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = use_indicators,\n",
    "                                use_fixes = use_fixes,\n",
    "                                use_only_last_timestep = use_only_last_timestep,\n",
    "                                use_grad_norm = False,\n",
    "                                noise_std = False,\n",
    "                                use_multiplicative_interactions = False,\n",
    "                                use_summaries = True,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=1e-3,\n",
    "                                cos_sim_lambda=1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                                 use_summaries_for_atomics, use_indicators, use_fixes, top_k=''):\n",
    "    model = new_models.CBM(static_dim = static_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            use_fixes = use_fixes,\n",
    "                            use_grad_norm = False,\n",
    "                            noise_std = False,\n",
    "                            use_summaries = True,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=1e-3,\n",
    "                            cos_sim_lambda=1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 23\n"
     ]
    }
   ],
   "source": [
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "seq_len = X.shape[2]\n",
    "changing_dim = X.shape[1]\n",
    "static_dim = 0\n",
    "\n",
    "print(changing_dim, static_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "config_original = {\n",
    "    \"n_concepts\": [4, 20],\n",
    "    # \"use_summaries\": [True, False],\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_only_last_timestep\": [True, False],\n",
    "    # \"use_grad_norm\": [False, \"FULL\", \"COMPONENT_WISE\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_og = list(product(*config_original.values()))\n",
    "all_config_permutations_og = [dict(zip(config_original.keys(), permutation)) for permutation in all_config_permutations_og]\n",
    "print(len(all_config_permutations_og))\n",
    "# all_config_permutations_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/original/\"\n",
    "model_path = experiment_folder + \"\".join([f\"{key}_{{{key}}}_\" for key in config_original.keys()]) + \"seed_{seed}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1669/10000 [59:04<4:54:54,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.8667049407958984, 0.9579613208770752, 0.753222644329071, 0.753222644329071]\n",
      "1 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 809/10000 [30:10<5:42:49,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.8356211185455322, 0.9638531804084778, 0.77980637550354, 0.77980637550354]\n",
      "2 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1719/10000 [1:02:53<5:02:57,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.8578628897666931, 0.9580385684967041, 0.761498749256134, 0.761498749256134]\n",
      "3 {'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 899/10000 [33:24<5:38:11,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.8300090432167053, 0.9632604718208313, 0.7772985100746155, 0.7772985100746155]\n",
      "4 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 24%|██▍       | 2389/10000 [1:18:35<4:10:24,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.8863508105278015, 0.9539850950241089, 0.7559311985969543, 0.7559311985969543]\n",
      "5 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 909/10000 [29:44<4:57:30,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.8466687202453613, 0.9609977006912231, 0.7555299401283264, 0.7555299401283264]\n",
      "6 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 989/10000 [32:31<4:56:16,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.9047031998634338, 0.9521624445915222, 0.7566334009170532, 0.7566334009170532]\n",
      "7 {'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 889/10000 [29:11<4:59:10,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 7, 0.8360020518302917, 0.9617575407028198, 0.7552791237831116, 0.7552791237831116]\n",
      "8 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▌        | 1529/10000 [55:09<5:05:37,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 8, 0.7979497313499451, 0.9674021601676941, 0.793148398399353, 0.793148398399353]\n",
      "9 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1029/10000 [37:24<5:26:07,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 9, 0.7601749300956726, 0.9729850888252258, 0.7724833488464355, 0.7724833488464355]\n",
      "10 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1559/10000 [56:21<5:05:09,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 10, 0.7911361455917358, 0.9674754738807678, 0.783568263053894, 0.783568263053894]\n",
      "11 {'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 699/10000 [26:12<5:48:44,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 11, 0.7855161428451538, 0.9720660448074341, 0.7974118590354919, 0.7974118590354919]\n",
      "12 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 11%|█▏        | 1129/10000 [37:05<4:51:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 12, 0.8191789388656616, 0.9618381857872009, 0.774941086769104, 0.774941086769104]\n",
      "13 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 729/10000 [24:17<5:08:50,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 13, 0.7515957951545715, 0.972728967666626, 0.7964588403701782, 0.7964588403701782]\n",
      "14 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▍        | 1499/10000 [49:09<4:38:49,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 14, 0.8195425271987915, 0.9632771611213684, 0.7796057462692261, 0.7796057462692261]\n",
      "15 {'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_only_last_timestep': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  9%|▉         | 899/10000 [29:48<5:01:43,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 15, 0.749521791934967, 0.973850667476654, 0.8213873505592346, 0.8213873505592346]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_og):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y, random_state = random_seed)\n",
    "    \n",
    "    model = initializeModel(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config, seed = random_seed), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            *data, yb = extract_to(batch, device)\n",
    "            probs = model(*data)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [\"original\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    histories_original.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "config_atomics = {\n",
    "    \"n_atomics\": [10, 30], # 30\n",
    "    \"n_concepts\": [4, 20], # 20\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_summaries_for_atomics\": [True, False],\n",
    "    # \"use_grad_norm\": [False, \"FULL\", \"COMPONENT_WISE\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_atomics = list(product(*config_atomics.values()))\n",
    "all_config_permutations_atomics = [dict(zip(config_atomics.keys(), permutation)) for permutation in all_config_permutations_atomics]\n",
    "print(len(all_config_permutations_atomics))\n",
    "# all_config_permutations_atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/atomics/\"\n",
    "model_path = experiment_folder + \"\".join([f\"{key}_{{{key}}}_\" for key in config_original.keys()]) + \"seed_{seed}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 19%|█▊        | 1860/10000 [1:15:19<5:29:37,  2.43s/ epoch, Train Loss=0.83698, Val Loss=0.84341, Best Val Loss=0.84157]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.8473899960517883, 0.9651008248329163, 0.7768470644950867, 0.7768470644950867]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1850/10000 [1:14:16<5:27:14,  2.41s/ epoch, Train Loss=0.85473, Val Loss=0.85909, Best Val Loss=0.85683]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.8595662117004395, 0.9578717350959778, 0.7650599479675293, 0.7650599479675293]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 23%|██▎       | 2310/10000 [1:33:57<5:12:47,  2.44s/ epoch, Train Loss=0.83745, Val Loss=0.83675, Best Val Loss=0.83415]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.8348634839057922, 0.9635878801345825, 0.7762451767921448, 0.7762451767921448]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1610/10000 [1:04:40<5:37:02,  2.41s/ epoch, Train Loss=0.82691, Val Loss=0.83233, Best Val Loss=0.82939]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.8302735686302185, 0.9613693952560425, 0.7643577456474304, 0.7643577456474304]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 24%|██▍       | 2450/10000 [1:28:12<4:31:50,  2.16s/ epoch, Train Loss=0.85655, Val Loss=0.86431, Best Val Loss=0.86318]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.8635403513908386, 0.9614143371582031, 0.7651602625846863, 0.7651602625846863]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 980/10000 [35:01<5:22:17,  2.14s/ epoch, Train Loss=0.87102, Val Loss=0.87722, Best Val Loss=0.87507]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.8759652972221375, 0.9554711580276489, 0.7512163519859314, 0.7512163519859314]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1820/10000 [1:05:42<4:55:20,  2.17s/ epoch, Train Loss=0.86861, Val Loss=0.87391, Best Val Loss=0.87174]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.872816264629364, 0.9612035751342773, 0.7662637233734131, 0.7662637233734131]\n",
      "7 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▌        | 1520/10000 [54:31<5:04:08,  2.15s/ epoch, Train Loss=0.89217, Val Loss=0.90363, Best Val Loss=0.90037]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 7, 0.9015012979507446, 0.9525852203369141, 0.7496112585067749, 0.7496112585067749]\n",
      "8 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1690/10000 [1:07:35<5:32:21,  2.40s/ epoch, Train Loss=0.81003, Val Loss=0.81542, Best Val Loss=0.81233]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 8, 0.8135256171226501, 0.9680449366569519, 0.7803581357002258, 0.7803581357002258]\n",
      "9 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1570/10000 [1:03:18<5:39:55,  2.42s/ epoch, Train Loss=0.76224, Val Loss=0.77543, Best Val Loss=0.77236]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 9, 0.7742837071418762, 0.9694805145263672, 0.7917941808700562, 0.7917941808700562]\n",
      "10 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 19%|█▉        | 1910/10000 [1:22:20<5:48:44,  2.59s/ epoch, Train Loss=0.79033, Val Loss=0.79475, Best Val Loss=0.79292]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 10, 0.8027811646461487, 0.9695811867713928, 0.7849726676940918, 0.7849726676940918]\n",
      "11 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|▉         | 950/10000 [38:41<6:08:37,  2.44s/ epoch, Train Loss=0.78488, Val Loss=0.79495, Best Val Loss=0.79220]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 11, 0.7967868447303772, 0.9691286087036133, 0.7995184659957886, 0.7995184659957886]\n",
      "12 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 15%|█▍        | 1460/10000 [50:31<4:55:29,  2.08s/ epoch, Train Loss=0.82078, Val Loss=0.82377, Best Val Loss=0.82315]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 12, 0.8257894515991211, 0.966426432132721, 0.7826653718948364, 0.7826653718948364]\n",
      "13 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 12%|█▏        | 1160/10000 [39:37<5:01:58,  2.05s/ epoch, Train Loss=0.79611, Val Loss=0.81265, Best Val Loss=0.81107]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 13, 0.8140682578086853, 0.9662600755691528, 0.7837187051773071, 0.7837187051773071]\n",
      "14 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1610/10000 [58:26<5:04:32,  2.18s/ epoch, Train Loss=0.81840, Val Loss=0.82956, Best Val Loss=0.82749]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 14, 0.835334062576294, 0.9665160775184631, 0.7856748700141907, 0.7856748700141907]\n",
      "15 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 14%|█▎        | 1350/10000 [52:12<5:34:28,  2.32s/ epoch, Train Loss=0.78550, Val Loss=0.80485, Best Val Loss=0.79795]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 15, 0.8033965229988098, 0.9662888646125793, 0.7851732969284058, 0.7851732969284058]\n",
      "16 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1790/10000 [1:17:05<5:53:37,  2.58s/ epoch, Train Loss=0.85866, Val Loss=0.86005, Best Val Loss=0.85929]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 16, 0.8623719215393066, 0.9624266028404236, 0.7600942850112915, 0.7600942850112915]\n",
      "17 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1040/10000 [46:58<6:44:40,  2.71s/ epoch, Train Loss=0.86751, Val Loss=0.88187, Best Val Loss=0.87773]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 17, 0.8796131610870361, 0.9568611979484558, 0.7598936557769775, 0.7598936557769775]\n",
      "18 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 14%|█▍        | 1400/10000 [1:04:04<6:33:37,  2.75s/ epoch, Train Loss=0.89620, Val Loss=0.90045, Best Val Loss=0.89971]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 18, 0.9015160799026489, 0.9580276608467102, 0.75748610496521, 0.75748610496521]\n",
      "19 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1050/10000 [46:00<6:32:10,  2.63s/ epoch, Train Loss=0.87830, Val Loss=0.88710, Best Val Loss=0.88686]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 19, 0.8884706497192383, 0.9584335684776306, 0.7611977458000183, 0.7611977458000183]\n",
      "20 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 22%|██▎       | 2250/10000 [1:28:58<5:06:27,  2.37s/ epoch, Train Loss=0.87633, Val Loss=0.87366, Best Val Loss=0.87310]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 20, 0.8788235783576965, 0.9617905020713806, 0.7605958580970764, 0.7605958580970764]\n",
      "21 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▋        | 1640/10000 [1:05:02<5:31:31,  2.38s/ epoch, Train Loss=0.97764, Val Loss=0.98160, Best Val Loss=0.98033]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 21, 0.9804694652557373, 0.9522088170051575, 0.748909056186676, 0.748909056186676]\n",
      "22 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1780/10000 [1:11:08<5:28:32,  2.40s/ epoch, Train Loss=0.86920, Val Loss=0.88323, Best Val Loss=0.87859]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 22, 0.8812747597694397, 0.9634850025177002, 0.7782514691352844, 0.7782514691352844]\n",
      "23 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1800/10000 [1:11:21<5:25:02,  2.38s/ epoch, Train Loss=0.97717, Val Loss=0.98705, Best Val Loss=0.98256]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 23, 0.9847234487533569, 0.9529554843902588, 0.7590911388397217, 0.7590911388397217]\n",
      "24 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 14%|█▎        | 1360/10000 [1:01:27<6:30:28,  2.71s/ epoch, Train Loss=0.81175, Val Loss=0.81863, Best Val Loss=0.81730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 24, 0.818527340888977, 0.9691840410232544, 0.7915934920310974, 0.7915934920310974]\n",
      "25 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 17%|█▋        | 1730/10000 [1:17:41<6:11:25,  2.69s/ epoch, Train Loss=0.77627, Val Loss=0.78705, Best Val Loss=0.78224]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 25, 0.7847665548324585, 0.9698143005371094, 0.7958569526672363, 0.7958569526672363]\n",
      "26 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 21%|██        | 2110/10000 [1:35:02<5:55:21,  2.70s/ epoch, Train Loss=0.80139, Val Loss=0.80269, Best Val Loss=0.80007]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 26, 0.8031461238861084, 0.9693675637245178, 0.7813612818717957, 0.7813612818717957]\n",
      "27 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1820/10000 [1:13:24<5:29:56,  2.42s/ epoch, Train Loss=0.77111, Val Loss=0.78294, Best Val Loss=0.78007]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 27, 0.7825690507888794, 0.9700115919113159, 0.8022270202636719, 0.8022270202636719]\n",
      "28 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1570/10000 [55:50<4:59:48,  2.13s/ epoch, Train Loss=0.84674, Val Loss=0.85284, Best Val Loss=0.85211]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 28, 0.8564141392707825, 0.9684802293777466, 0.7849224805831909, 0.7849224805831909]\n",
      "29 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 16%|█▌        | 1580/10000 [1:01:10<5:26:03,  2.32s/ epoch, Train Loss=0.87373, Val Loss=0.87922, Best Val Loss=0.87729]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 29, 0.8796805143356323, 0.966985821723938, 0.797211229801178, 0.797211229801178]\n",
      "30 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 18%|█▊        | 1850/10000 [1:13:11<5:22:26,  2.37s/ epoch, Train Loss=0.83270, Val Loss=0.85122, Best Val Loss=0.84658]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 30, 0.8554266095161438, 0.9673286080360413, 0.7761448621749878, 0.7761448621749878]\n",
      "31 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1000/10000 [37:23<5:36:29,  2.24s/ epoch, Train Loss=0.89542, Val Loss=0.90443, Best Val Loss=0.90264]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 31, 0.9064163565635681, 0.9634954929351807, 0.77980637550354, 0.77980637550354]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_atomics):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)#, batch_size=8)\n",
    "    \n",
    "    model = initializeModel_with_atomics(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim = num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            X_time, X_ind, X_static, yb = extract_to(batch, device)\n",
    "            probs = model(X_time, X_ind, X_static)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "\n",
    "    history = [\"atomics\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    history_atomics.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = pd.concat([df_og, pd.DataFrame(all_config_permutations_og)], axis=1)\n",
    "\n",
    "df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "df_atomics = pd.concat([df_atomics, pd.DataFrame(all_config_permutations_atomics)], axis=1)\n",
    "\n",
    "result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.9579613208770752\n",
      "acc 0.753222644329071\n",
      "f1 0.753222644329071\n"
     ]
    }
   ],
   "source": [
    "for col in result_df.columns[3:6]:\n",
    "    baseline = result_df[(result_df['type'] == 'original') & (result_df['config'] == 0)][col].values[0]\n",
    "    print(col, baseline)\n",
    "    result_df[f'{col}_abs_imp'] = result_df[col] - baseline\n",
    "    # result_df[f'{col}_rel_imp'] = result_df[f'{col}_abs_imp'] / baseline\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>config</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th>auc_abs_imp</th>\n",
       "      <th>acc_abs_imp</th>\n",
       "      <th>f1_abs_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original</td>\n",
       "      <td>15</td>\n",
       "      <td>0.749522</td>\n",
       "      <td>0.973851</td>\n",
       "      <td>0.821387</td>\n",
       "      <td>0.821387</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.068165</td>\n",
       "      <td>0.068165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>atomics</td>\n",
       "      <td>27</td>\n",
       "      <td>0.782569</td>\n",
       "      <td>0.970012</td>\n",
       "      <td>0.802227</td>\n",
       "      <td>0.802227</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.049004</td>\n",
       "      <td>0.049004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>atomics</td>\n",
       "      <td>11</td>\n",
       "      <td>0.796787</td>\n",
       "      <td>0.969129</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011167</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.046296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>original</td>\n",
       "      <td>11</td>\n",
       "      <td>0.785516</td>\n",
       "      <td>0.972066</td>\n",
       "      <td>0.797412</td>\n",
       "      <td>0.797412</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>0.044189</td>\n",
       "      <td>0.044189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>atomics</td>\n",
       "      <td>29</td>\n",
       "      <td>0.879681</td>\n",
       "      <td>0.966986</td>\n",
       "      <td>0.797211</td>\n",
       "      <td>0.797211</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.043989</td>\n",
       "      <td>0.043989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original</td>\n",
       "      <td>13</td>\n",
       "      <td>0.751596</td>\n",
       "      <td>0.972729</td>\n",
       "      <td>0.796459</td>\n",
       "      <td>0.796459</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014768</td>\n",
       "      <td>0.043236</td>\n",
       "      <td>0.043236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>atomics</td>\n",
       "      <td>25</td>\n",
       "      <td>0.784767</td>\n",
       "      <td>0.969814</td>\n",
       "      <td>0.795857</td>\n",
       "      <td>0.795857</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011853</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.042634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original</td>\n",
       "      <td>8</td>\n",
       "      <td>0.797950</td>\n",
       "      <td>0.967402</td>\n",
       "      <td>0.793148</td>\n",
       "      <td>0.793148</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009441</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.039926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>atomics</td>\n",
       "      <td>9</td>\n",
       "      <td>0.774284</td>\n",
       "      <td>0.969481</td>\n",
       "      <td>0.791794</td>\n",
       "      <td>0.791794</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.038572</td>\n",
       "      <td>0.038572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>atomics</td>\n",
       "      <td>24</td>\n",
       "      <td>0.818527</td>\n",
       "      <td>0.969184</td>\n",
       "      <td>0.791593</td>\n",
       "      <td>0.791593</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011223</td>\n",
       "      <td>0.038371</td>\n",
       "      <td>0.038371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>atomics</td>\n",
       "      <td>14</td>\n",
       "      <td>0.835334</td>\n",
       "      <td>0.966516</td>\n",
       "      <td>0.785675</td>\n",
       "      <td>0.785675</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008555</td>\n",
       "      <td>0.032452</td>\n",
       "      <td>0.032452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>atomics</td>\n",
       "      <td>15</td>\n",
       "      <td>0.803397</td>\n",
       "      <td>0.966289</td>\n",
       "      <td>0.785173</td>\n",
       "      <td>0.785173</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008328</td>\n",
       "      <td>0.031951</td>\n",
       "      <td>0.031951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>atomics</td>\n",
       "      <td>10</td>\n",
       "      <td>0.802781</td>\n",
       "      <td>0.969581</td>\n",
       "      <td>0.784973</td>\n",
       "      <td>0.784973</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.031750</td>\n",
       "      <td>0.031750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>atomics</td>\n",
       "      <td>28</td>\n",
       "      <td>0.856414</td>\n",
       "      <td>0.968480</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>0.784922</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010519</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>atomics</td>\n",
       "      <td>13</td>\n",
       "      <td>0.814068</td>\n",
       "      <td>0.966260</td>\n",
       "      <td>0.783719</td>\n",
       "      <td>0.783719</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>original</td>\n",
       "      <td>10</td>\n",
       "      <td>0.791136</td>\n",
       "      <td>0.967475</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009514</td>\n",
       "      <td>0.030346</td>\n",
       "      <td>0.030346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>atomics</td>\n",
       "      <td>12</td>\n",
       "      <td>0.825789</td>\n",
       "      <td>0.966426</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>0.782665</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.029443</td>\n",
       "      <td>0.029443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>atomics</td>\n",
       "      <td>26</td>\n",
       "      <td>0.803146</td>\n",
       "      <td>0.969368</td>\n",
       "      <td>0.781361</td>\n",
       "      <td>0.781361</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011406</td>\n",
       "      <td>0.028139</td>\n",
       "      <td>0.028139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>atomics</td>\n",
       "      <td>8</td>\n",
       "      <td>0.813526</td>\n",
       "      <td>0.968045</td>\n",
       "      <td>0.780358</td>\n",
       "      <td>0.780358</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.027135</td>\n",
       "      <td>0.027135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835621</td>\n",
       "      <td>0.963853</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>0.026584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>atomics</td>\n",
       "      <td>31</td>\n",
       "      <td>0.906416</td>\n",
       "      <td>0.963495</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>0.026584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>original</td>\n",
       "      <td>14</td>\n",
       "      <td>0.819543</td>\n",
       "      <td>0.963277</td>\n",
       "      <td>0.779606</td>\n",
       "      <td>0.779606</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.026383</td>\n",
       "      <td>0.026383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>atomics</td>\n",
       "      <td>22</td>\n",
       "      <td>0.881275</td>\n",
       "      <td>0.963485</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>0.778251</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>0.025029</td>\n",
       "      <td>0.025029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.830009</td>\n",
       "      <td>0.963260</td>\n",
       "      <td>0.777299</td>\n",
       "      <td>0.777299</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>0.024076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.965101</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>0.776847</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.023624</td>\n",
       "      <td>0.023624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.834863</td>\n",
       "      <td>0.963588</td>\n",
       "      <td>0.776245</td>\n",
       "      <td>0.776245</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.023023</td>\n",
       "      <td>0.023023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>atomics</td>\n",
       "      <td>30</td>\n",
       "      <td>0.855427</td>\n",
       "      <td>0.967329</td>\n",
       "      <td>0.776145</td>\n",
       "      <td>0.776145</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.022922</td>\n",
       "      <td>0.022922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original</td>\n",
       "      <td>12</td>\n",
       "      <td>0.819179</td>\n",
       "      <td>0.961838</td>\n",
       "      <td>0.774941</td>\n",
       "      <td>0.774941</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>0.021718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original</td>\n",
       "      <td>9</td>\n",
       "      <td>0.760175</td>\n",
       "      <td>0.972985</td>\n",
       "      <td>0.772483</td>\n",
       "      <td>0.772483</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.019261</td>\n",
       "      <td>0.019261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.872816</td>\n",
       "      <td>0.961204</td>\n",
       "      <td>0.766264</td>\n",
       "      <td>0.766264</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.013041</td>\n",
       "      <td>0.013041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.863540</td>\n",
       "      <td>0.961414</td>\n",
       "      <td>0.765160</td>\n",
       "      <td>0.765160</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.011938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.859566</td>\n",
       "      <td>0.957872</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>0.765060</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>0.011837</td>\n",
       "      <td>0.011837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.830274</td>\n",
       "      <td>0.961369</td>\n",
       "      <td>0.764358</td>\n",
       "      <td>0.764358</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.011135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.857863</td>\n",
       "      <td>0.958039</td>\n",
       "      <td>0.761499</td>\n",
       "      <td>0.761499</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>0.008276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>atomics</td>\n",
       "      <td>19</td>\n",
       "      <td>0.888471</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>0.761198</td>\n",
       "      <td>0.761198</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.007975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>atomics</td>\n",
       "      <td>20</td>\n",
       "      <td>0.878824</td>\n",
       "      <td>0.961791</td>\n",
       "      <td>0.760596</td>\n",
       "      <td>0.760596</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.007373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>atomics</td>\n",
       "      <td>16</td>\n",
       "      <td>0.862372</td>\n",
       "      <td>0.962427</td>\n",
       "      <td>0.760094</td>\n",
       "      <td>0.760094</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>0.006872</td>\n",
       "      <td>0.006872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>atomics</td>\n",
       "      <td>17</td>\n",
       "      <td>0.879613</td>\n",
       "      <td>0.956861</td>\n",
       "      <td>0.759894</td>\n",
       "      <td>0.759894</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001100</td>\n",
       "      <td>0.006671</td>\n",
       "      <td>0.006671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>atomics</td>\n",
       "      <td>23</td>\n",
       "      <td>0.984723</td>\n",
       "      <td>0.952955</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.005006</td>\n",
       "      <td>0.005868</td>\n",
       "      <td>0.005868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>atomics</td>\n",
       "      <td>18</td>\n",
       "      <td>0.901516</td>\n",
       "      <td>0.958028</td>\n",
       "      <td>0.757486</td>\n",
       "      <td>0.757486</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.004263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.904703</td>\n",
       "      <td>0.952162</td>\n",
       "      <td>0.756633</td>\n",
       "      <td>0.756633</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.003411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.886351</td>\n",
       "      <td>0.953985</td>\n",
       "      <td>0.755931</td>\n",
       "      <td>0.755931</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003976</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.002709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.846669</td>\n",
       "      <td>0.960998</td>\n",
       "      <td>0.755530</td>\n",
       "      <td>0.755530</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.002307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original</td>\n",
       "      <td>7</td>\n",
       "      <td>0.836002</td>\n",
       "      <td>0.961758</td>\n",
       "      <td>0.755279</td>\n",
       "      <td>0.755279</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866705</td>\n",
       "      <td>0.957961</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>0.753223</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.875965</td>\n",
       "      <td>0.955471</td>\n",
       "      <td>0.751216</td>\n",
       "      <td>0.751216</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.002490</td>\n",
       "      <td>-0.002006</td>\n",
       "      <td>-0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>atomics</td>\n",
       "      <td>7</td>\n",
       "      <td>0.901501</td>\n",
       "      <td>0.952585</td>\n",
       "      <td>0.749611</td>\n",
       "      <td>0.749611</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>-0.003611</td>\n",
       "      <td>-0.003611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>atomics</td>\n",
       "      <td>21</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.952209</td>\n",
       "      <td>0.748909</td>\n",
       "      <td>0.748909</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.004314</td>\n",
       "      <td>-0.004314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  config  val_loss       auc       acc        f1  n_concepts  \\\n",
       "15  original      15  0.749522  0.973851  0.821387  0.821387          20   \n",
       "43   atomics      27  0.782569  0.970012  0.802227  0.802227          20   \n",
       "27   atomics      11  0.796787  0.969129  0.799518  0.799518          20   \n",
       "11  original      11  0.785516  0.972066  0.797412  0.797412          20   \n",
       "45   atomics      29  0.879681  0.966986  0.797211  0.797211          20   \n",
       "13  original      13  0.751596  0.972729  0.796459  0.796459          20   \n",
       "41   atomics      25  0.784767  0.969814  0.795857  0.795857          20   \n",
       "8   original       8  0.797950  0.967402  0.793148  0.793148          20   \n",
       "25   atomics       9  0.774284  0.969481  0.791794  0.791794          20   \n",
       "40   atomics      24  0.818527  0.969184  0.791593  0.791593          20   \n",
       "30   atomics      14  0.835334  0.966516  0.785675  0.785675          20   \n",
       "31   atomics      15  0.803397  0.966289  0.785173  0.785173          20   \n",
       "26   atomics      10  0.802781  0.969581  0.784973  0.784973          20   \n",
       "44   atomics      28  0.856414  0.968480  0.784922  0.784922          20   \n",
       "29   atomics      13  0.814068  0.966260  0.783719  0.783719          20   \n",
       "10  original      10  0.791136  0.967475  0.783568  0.783568          20   \n",
       "28   atomics      12  0.825789  0.966426  0.782665  0.782665          20   \n",
       "42   atomics      26  0.803146  0.969368  0.781361  0.781361          20   \n",
       "24   atomics       8  0.813526  0.968045  0.780358  0.780358          20   \n",
       "1   original       1  0.835621  0.963853  0.779806  0.779806           4   \n",
       "47   atomics      31  0.906416  0.963495  0.779806  0.779806          20   \n",
       "14  original      14  0.819543  0.963277  0.779606  0.779606          20   \n",
       "38   atomics      22  0.881275  0.963485  0.778251  0.778251           4   \n",
       "3   original       3  0.830009  0.963260  0.777299  0.777299           4   \n",
       "16   atomics       0  0.847390  0.965101  0.776847  0.776847           4   \n",
       "18   atomics       2  0.834863  0.963588  0.776245  0.776245           4   \n",
       "46   atomics      30  0.855427  0.967329  0.776145  0.776145          20   \n",
       "12  original      12  0.819179  0.961838  0.774941  0.774941          20   \n",
       "9   original       9  0.760175  0.972985  0.772483  0.772483          20   \n",
       "22   atomics       6  0.872816  0.961204  0.766264  0.766264           4   \n",
       "20   atomics       4  0.863540  0.961414  0.765160  0.765160           4   \n",
       "17   atomics       1  0.859566  0.957872  0.765060  0.765060           4   \n",
       "19   atomics       3  0.830274  0.961369  0.764358  0.764358           4   \n",
       "2   original       2  0.857863  0.958039  0.761499  0.761499           4   \n",
       "35   atomics      19  0.888471  0.958434  0.761198  0.761198           4   \n",
       "36   atomics      20  0.878824  0.961791  0.760596  0.760596           4   \n",
       "32   atomics      16  0.862372  0.962427  0.760094  0.760094           4   \n",
       "33   atomics      17  0.879613  0.956861  0.759894  0.759894           4   \n",
       "39   atomics      23  0.984723  0.952955  0.759091  0.759091           4   \n",
       "34   atomics      18  0.901516  0.958028  0.757486  0.757486           4   \n",
       "6   original       6  0.904703  0.952162  0.756633  0.756633           4   \n",
       "4   original       4  0.886351  0.953985  0.755931  0.755931           4   \n",
       "5   original       5  0.846669  0.960998  0.755530  0.755530           4   \n",
       "7   original       7  0.836002  0.961758  0.755279  0.755279           4   \n",
       "0   original       0  0.866705  0.957961  0.753223  0.753223           4   \n",
       "21   atomics       5  0.875965  0.955471  0.751216  0.751216           4   \n",
       "23   atomics       7  0.901501  0.952585  0.749611  0.749611           4   \n",
       "37   atomics      21  0.980469  0.952209  0.748909  0.748909           4   \n",
       "\n",
       "    use_indicators  use_fixes use_only_last_timestep  n_atomics  \\\n",
       "15           False       True                  False        NaN   \n",
       "43            True       True                    NaN       30.0   \n",
       "27            True       True                    NaN       10.0   \n",
       "11            True       True                  False        NaN   \n",
       "45           False      False                    NaN       30.0   \n",
       "13           False      False                  False        NaN   \n",
       "41            True      False                    NaN       30.0   \n",
       "8             True      False                   True        NaN   \n",
       "25            True      False                    NaN       10.0   \n",
       "40            True      False                    NaN       30.0   \n",
       "30           False       True                    NaN       10.0   \n",
       "31           False       True                    NaN       10.0   \n",
       "26            True       True                    NaN       10.0   \n",
       "44           False      False                    NaN       30.0   \n",
       "29           False      False                    NaN       10.0   \n",
       "10            True       True                   True        NaN   \n",
       "28           False      False                    NaN       10.0   \n",
       "42            True       True                    NaN       30.0   \n",
       "24            True      False                    NaN       10.0   \n",
       "1             True      False                  False        NaN   \n",
       "47           False       True                    NaN       30.0   \n",
       "14           False       True                   True        NaN   \n",
       "38           False       True                    NaN       30.0   \n",
       "3             True       True                  False        NaN   \n",
       "16            True      False                    NaN       10.0   \n",
       "18            True       True                    NaN       10.0   \n",
       "46           False       True                    NaN       30.0   \n",
       "12           False      False                   True        NaN   \n",
       "9             True      False                  False        NaN   \n",
       "22           False       True                    NaN       10.0   \n",
       "20           False      False                    NaN       10.0   \n",
       "17            True      False                    NaN       10.0   \n",
       "19            True       True                    NaN       10.0   \n",
       "2             True       True                   True        NaN   \n",
       "35            True       True                    NaN       30.0   \n",
       "36           False      False                    NaN       30.0   \n",
       "32            True      False                    NaN       30.0   \n",
       "33            True      False                    NaN       30.0   \n",
       "39           False       True                    NaN       30.0   \n",
       "34            True       True                    NaN       30.0   \n",
       "6            False       True                   True        NaN   \n",
       "4            False      False                   True        NaN   \n",
       "5            False      False                  False        NaN   \n",
       "7            False       True                  False        NaN   \n",
       "0             True      False                   True        NaN   \n",
       "21           False      False                    NaN       10.0   \n",
       "23           False       True                    NaN       10.0   \n",
       "37           False      False                    NaN       30.0   \n",
       "\n",
       "   use_summaries_for_atomics  auc_abs_imp  acc_abs_imp  f1_abs_imp  \n",
       "15                       NaN     0.015889     0.068165    0.068165  \n",
       "43                     False     0.012050     0.049004    0.049004  \n",
       "27                     False     0.011167     0.046296    0.046296  \n",
       "11                       NaN     0.014105     0.044189    0.044189  \n",
       "45                     False     0.009025     0.043989    0.043989  \n",
       "13                       NaN     0.014768     0.043236    0.043236  \n",
       "41                     False     0.011853     0.042634    0.042634  \n",
       "8                        NaN     0.009441     0.039926    0.039926  \n",
       "25                     False     0.011519     0.038572    0.038572  \n",
       "40                      True     0.011223     0.038371    0.038371  \n",
       "30                      True     0.008555     0.032452    0.032452  \n",
       "31                     False     0.008328     0.031951    0.031951  \n",
       "26                      True     0.011620     0.031750    0.031750  \n",
       "44                      True     0.010519     0.031700    0.031700  \n",
       "29                     False     0.008299     0.030496    0.030496  \n",
       "10                       NaN     0.009514     0.030346    0.030346  \n",
       "28                      True     0.008465     0.029443    0.029443  \n",
       "42                      True     0.011406     0.028139    0.028139  \n",
       "24                      True     0.010084     0.027135    0.027135  \n",
       "1                        NaN     0.005892     0.026584    0.026584  \n",
       "47                     False     0.005534     0.026584    0.026584  \n",
       "14                       NaN     0.005316     0.026383    0.026383  \n",
       "38                      True     0.005524     0.025029    0.025029  \n",
       "3                        NaN     0.005299     0.024076    0.024076  \n",
       "16                      True     0.007140     0.023624    0.023624  \n",
       "18                      True     0.005627     0.023023    0.023023  \n",
       "46                      True     0.009367     0.022922    0.022922  \n",
       "12                       NaN     0.003877     0.021718    0.021718  \n",
       "9                        NaN     0.015024     0.019261    0.019261  \n",
       "22                      True     0.003242     0.013041    0.013041  \n",
       "20                      True     0.003453     0.011938    0.011938  \n",
       "17                     False    -0.000090     0.011837    0.011837  \n",
       "19                     False     0.003408     0.011135    0.011135  \n",
       "2                        NaN     0.000077     0.008276    0.008276  \n",
       "35                     False     0.000472     0.007975    0.007975  \n",
       "36                      True     0.003829     0.007373    0.007373  \n",
       "32                      True     0.004465     0.006872    0.006872  \n",
       "33                     False    -0.001100     0.006671    0.006671  \n",
       "39                     False    -0.005006     0.005868    0.005868  \n",
       "34                      True     0.000066     0.004263    0.004263  \n",
       "6                        NaN    -0.005799     0.003411    0.003411  \n",
       "4                        NaN    -0.003976     0.002709    0.002709  \n",
       "5                        NaN     0.003036     0.002307    0.002307  \n",
       "7                        NaN     0.003796     0.002056    0.002056  \n",
       "0                        NaN     0.000000     0.000000    0.000000  \n",
       "21                     False    -0.002490    -0.002006   -0.002006  \n",
       "23                     False    -0.005376    -0.003611   -0.003611  \n",
       "37                     False    -0.005753    -0.004314   -0.004314  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "result_df.sort_values(by='acc', ascending=False)\n",
    "# atomics: atomics, concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics\n",
    "# original: concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.963771</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.775540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.0</th>\n",
       "      <td>0.963179</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.774665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auc       acc        f1\n",
       "type    n_atomics                              \n",
       "atomics 10.0       0.963771  0.775540  0.775540\n",
       "        30.0       0.963179  0.774665  0.774665"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>4</th>\n",
       "      <td>0.959050</td>\n",
       "      <td>0.762518</td>\n",
       "      <td>0.762518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.967900</td>\n",
       "      <td>0.787687</td>\n",
       "      <td>0.787687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>4</th>\n",
       "      <td>0.959002</td>\n",
       "      <td>0.761900</td>\n",
       "      <td>0.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.968953</td>\n",
       "      <td>0.789876</td>\n",
       "      <td>0.789876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc       acc        f1\n",
       "type     n_concepts                              \n",
       "atomics  4           0.959050  0.762518  0.762518\n",
       "         20          0.967900  0.787687  0.787687\n",
       "original 4           0.959002  0.761900  0.761900\n",
       "         20          0.968953  0.789876  0.789876"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_fixes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.963614</td>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.774744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.963335</td>\n",
       "      <td>0.775461</td>\n",
       "      <td>0.775461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.963969</td>\n",
       "      <td>0.772690</td>\n",
       "      <td>0.772690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.779085</td>\n",
       "      <td>0.779085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc       acc        f1\n",
       "type     use_fixes                              \n",
       "atomics  False      0.963614  0.774744  0.774744\n",
       "         True       0.963335  0.775461  0.775461\n",
       "original False      0.963969  0.772690  0.772690\n",
       "         True       0.963986  0.779085  0.779085"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_indicators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.962056</td>\n",
       "      <td>0.772151</td>\n",
       "      <td>0.772151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.964893</td>\n",
       "      <td>0.778054</td>\n",
       "      <td>0.778054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.962575</td>\n",
       "      <td>0.774471</td>\n",
       "      <td>0.774471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.965380</td>\n",
       "      <td>0.777305</td>\n",
       "      <td>0.777305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              auc       acc        f1\n",
       "type     use_indicators                              \n",
       "atomics  False           0.962056  0.772151  0.772151\n",
       "         True            0.964893  0.778054  0.778054\n",
       "original False           0.962575  0.774471  0.774471\n",
       "         True            0.965380  0.777305  0.777305"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_only_last_timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.967687</td>\n",
       "      <td>0.781957</td>\n",
       "      <td>0.781957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.960268</td>\n",
       "      <td>0.769819</td>\n",
       "      <td>0.769819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      auc       acc        f1\n",
       "type     use_only_last_timestep                              \n",
       "original False                   0.967687  0.781957  0.781957\n",
       "         True                    0.960268  0.769819  0.769819"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">atomics</th>\n",
       "      <th>False</th>\n",
       "      <td>0.961826</td>\n",
       "      <td>0.774665</td>\n",
       "      <td>0.774665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.965123</td>\n",
       "      <td>0.775540</td>\n",
       "      <td>0.775540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        auc       acc        f1\n",
       "type    use_summaries_for_atomics                              \n",
       "atomics False                      0.961826  0.774665  0.774665\n",
       "        True                       0.965123  0.775540  0.775540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <td>0.963475</td>\n",
       "      <td>0.775103</td>\n",
       "      <td>0.775103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.963978</td>\n",
       "      <td>0.775888</td>\n",
       "      <td>0.775888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc       acc        f1\n",
       "type                                  \n",
       "atomics   0.963475  0.775103  0.775103\n",
       "original  0.963978  0.775888  0.775888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in sorted(set(list(all_config_permutations_og[0].keys()) + list(all_config_permutations_atomics[0].keys()))):\n",
    "    display(result_df.groupby([\"type\", key])[[\"auc\", \"acc\", \"f1\"]].mean())\n",
    "\n",
    "display(result_df.groupby(\"type\")[[\"auc\", \"acc\", \"f1\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
