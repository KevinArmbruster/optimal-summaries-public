{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:10\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "from einops import rearrange\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "y = y.astype(int)\n",
    "display(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAE8CAYAAAAFVlxaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0s0lEQVR4nO3dd1QUZ9sG8GtBWDoISFkFxIqCnWiwG4moaDAau7FhjAkkKraQGPXVJCYaC7HGNxE0BqP4JiaxIYpd7CIWVLChUuwiKsXl+f7wY44r1p1lF+T6nTPnODP3znPPJu7l7MzOKIQQAkRERDIYGboBIiIq+xgmREQkG8OEiIhkY5gQEZFsDBMiIpKNYUJERLIxTIiISDaGCRERycYwISIi2Rgm9EaoWrUqBg8ebOg2ZJsyZQoUCoVexmrbti3atm0rzW/fvh0KhQJr1qzRy/iDBw9G1apV9TIWlTyGCZVq586dw8cff4xq1arBzMwMNjY2aNGiBSIiIvDw4UNDt/dCUVFRUCgU0mRmZgaVSoWAgAD89NNPuHfvnk7GSU9Px5QpU5CYmKiT7elSae6NdKuCoRsgep7169ejZ8+eUCqVGDhwIHx8fJCfn4/du3dj3LhxOHnyJJYsWWLoNl9q6tSp8PT0REFBATIzM7F9+3aMGjUKs2fPxj///IP69etLtRMnTsQXX3zxWttPT0/Hf/7zH1StWhUNGzZ85ddt3rz5tcbRxot6++9//4vCwsIS74H0g2FCpdKFCxfQp08feHh4ID4+Hq6urtK6kJAQpKamYv369Qbs8NV16tQJvr6+0nx4eDji4+PRpUsXvPfee0hOToa5uTkAoEKFCqhQoWT/Wj548AAWFhYwNTUt0XFexsTExKDjk27xay4qlWbMmIGcnBz8+uuvGkFSpEaNGhg5cuRzX3/r1i2MHTsW9erVg5WVFWxsbNCpUyccO3asWO28efPg7e0NCwsLVKxYEb6+voiOjpbW37t3D6NGjULVqlWhVCrh5OSEd999F0eOHNF6/9555x18/fXXuHTpElasWCEtf9Y5k7i4OLRs2RJ2dnawsrJC7dq18eWXXwJ4fJ7jrbfeAgAMGTJE+kotKioKwOPzIj4+Pjh8+DBat24NCwsL6bVPnzMpolar8eWXX8LFxQWWlpZ47733cPnyZY2a552jenKbL+vtWedM7t+/jzFjxsDNzQ1KpRK1a9fGjz/+iKdvbq5QKBAaGoq1a9fCx8cHSqUS3t7e2LRp07PfcCpxPDKhUunff/9FtWrV0Lx5c61ef/78eaxduxY9e/aEp6cnsrKy8PPPP6NNmzY4deoUVCoVgMdftXz++ef44IMPMHLkSOTm5iIpKQn79+9Hv379AAAjRozAmjVrEBoairp16+LmzZvYvXs3kpOT0bhxY6338cMPP8SXX36JzZs346OPPnpmzcmTJ9GlSxfUr18fU6dOhVKpRGpqKvbs2QMAqFOnDqZOnYpJkyZh+PDhaNWqFQBovG83b95Ep06d0KdPHwwYMADOzs4v7Ovbb7+FQqHAhAkTcO3aNcydOxf+/v5ITEyUjqBexav09iQhBN577z1s27YNwcHBaNiwIWJjYzFu3DhcvXoVc+bM0ajfvXs3/vzzT3z66aewtrbGTz/9hB49eiAtLQ0ODg6v3CfpiCAqZe7evSsAiKCgoFd+jYeHhxg0aJA0n5ubK9RqtUbNhQsXhFKpFFOnTpWWBQUFCW9v7xdu29bWVoSEhLxyL0UiIyMFAHHw4MEXbrtRo0bS/OTJk8WTfy3nzJkjAIjr168/dxsHDx4UAERkZGSxdW3atBEAxOLFi5+5rk2bNtL8tm3bBABRuXJlkZ2dLS1fvXq1ACAiIiKkZU+/38/b5ot6GzRokPDw8JDm165dKwCIb775RqPugw8+EAqFQqSmpkrLAAhTU1ONZceOHRMAxLx584qNRSWPX3NRqZOdnQ0AsLa21nobSqUSRkaP//dWq9W4efOm9BXRk19P2dnZ4cqVKzh48OBzt2VnZ4f9+/cjPT1d636ex8rK6oVXddnZ2QEA/v77b61PViuVSgwZMuSV6wcOHKjx3n/wwQdwdXXFhg0btBr/VW3YsAHGxsb4/PPPNZaPGTMGQghs3LhRY7m/vz+qV68uzdevXx82NjY4f/58ifZJz8YwoVLHxsYGAGRdOltYWIg5c+agZs2aUCqVcHR0RKVKlZCUlIS7d+9KdRMmTICVlRWaNm2KmjVrIiQkRPoKqciMGTNw4sQJuLm5oWnTppgyZYrOPrBycnJeGJq9e/dGixYtMGzYMDg7O6NPnz5YvXr1awVL5cqVX+tke82aNTXmFQoFatSogYsXL77yNrRx6dIlqFSqYu9HnTp1pPVPcnd3L7aNihUr4vbt2yXXJD0Xw4RKHRsbG6hUKpw4cULrbXz33XcICwtD69atsWLFCsTGxiIuLg7e3t4aH8R16tTBmTNn8Mcff6Bly5b43//+h5YtW2Ly5MlSTa9evXD+/HnMmzcPKpUKM2fOhLe3d7F/Kb+uK1eu4O7du6hRo8Zza8zNzbFz505s2bIFH374IZKSktC7d2+8++67UKvVrzTO65zneFXP+2Hlq/akC8bGxs9cLvgkcoNgmFCp1KVLF5w7dw4JCQlavX7NmjVo164dfv31V/Tp0wcdOnSAv78/7ty5U6zW0tISvXv3RmRkJNLS0hAYGIhvv/0Wubm5Uo2rqys+/fRTrF27FhcuXICDgwO+/fZbbXcPAPDbb78BAAICAl5YZ2RkhPbt22P27Nk4deoUvv32W8THx2Pbtm0Anv/Brq2UlBSNeSEEUlNTNa68qlix4jPfy6ePHl6nNw8PD6Snpxc7Ij19+rS0nkovhgmVSuPHj4elpSWGDRuGrKysYuvPnTuHiIiI577e2Ni42L9QY2JicPXqVY1lN2/e1Jg3NTVF3bp1IYRAQUEB1Gq1xtdiAODk5ASVSoW8vLzX3S1JfHw8pk2bBk9PT/Tv3/+5dbdu3Sq2rOjHf0XjW1paAsAzP9y1sXz5co0P9DVr1iAjIwOdOnWSllWvXh379u1Dfn6+tGzdunXFLiF+nd46d+4MtVqN+fPnayyfM2cOFAqFxvhU+vDSYCqVqlevjujoaPTu3Rt16tTR+AX83r17ERMT88J7cXXp0gVTp07FkCFD0Lx5cxw/fhy///47qlWrplHXoUMHuLi4oEWLFnB2dkZycjLmz5+PwMBAWFtb486dO6hSpQo++OADNGjQAFZWVtiyZQsOHjyIWbNmvdK+bNy4EadPn8ajR4+QlZWF+Ph4xMXFwcPDA//88w/MzMye+9qpU6di586dCAwMhIeHB65du4aFCxeiSpUqaNmypfRe2dnZYfHixbC2toalpSWaNWsGT0/PV+rvafb29mjZsiWGDBmCrKwszJ07FzVq1NC4fHnYsGFYs2YNOnbsiF69euHcuXNYsWKFxgnx1+2ta9euaNeuHb766itcvHgRDRo0wObNm/H3339j1KhRxbZNpYxBryUjeomzZ8+Kjz76SFStWlWYmpoKa2tr0aJFCzFv3jyRm5sr1T3r0uAxY8YIV1dXYW5uLlq0aCESEhKKXbr6888/i9atWwsHBwehVCpF9erVxbhx48Tdu3eFEELk5eWJcePGiQYNGghra2thaWkpGjRoIBYuXPjS3osuDS6aTE1NhYuLi3j33XdFRESExuW3RZ6+NHjr1q0iKChIqFQqYWpqKlQqlejbt684e/asxuv+/vtvUbduXVGhQgWNS3HbtGnz3Eufn3dp8MqVK0V4eLhwcnIS5ubmIjAwUFy6dKnY62fNmiUqV64slEqlaNGihTh06FCxbb6ot6cvDRZCiHv37onRo0cLlUolTExMRM2aNcXMmTNFYWGhRh2AZ16u/bxLlqnkKYTg2SoiIpKH50yIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbPzRoo4UFhYiPT0d1tbWOr+9BRGRIQghcO/ePahUKuku3M/DMNGR9PR0uLm5GboNIiKdu3z5MqpUqfLCGoaJjhTdNvvy5cvSLdSJiMqy7OxsuLm5vdKzhRgmOlL01ZaNjQ3DhIjeKK/y1T1PwBMRkWwMEyIiko1hQkREsjFMiIhINoOGyfTp0/HWW2/B2toaTk5O6NatG86cOaNRk5ubi5CQEDg4OMDKygo9evQo9uS9oketWlhYwMnJCePGjcOjR480arZv347GjRtDqVSiRo0aiIqKKtbPggULULVqVZiZmaFZs2Y4cOCAzveZiOhNZNAw2bFjB0JCQrBv3z7ExcWhoKAAHTp0wP3796Wa0aNH499//0VMTAx27NiB9PR0dO/eXVqvVqsRGBgoPYFv2bJliIqKwqRJk6SaCxcuIDAwEO3atUNiYiJGjRqFYcOGITY2VqpZtWoVwsLCMHnyZBw5cgQNGjRAQEAArl27pp83g4ioLDPww7k0XLt2TQAQO3bsEEIIcefOHWFiYiJiYmKkmuTkZAFAJCQkCCGE2LBhgzAyMhKZmZlSzaJFi4SNjY3Iy8sTQggxfvz4Yk+b6927twgICJDmmzZtqvHkNrVaLVQqlZg+ffor9X737l0BQHpCHxFRWfc6n2ul6ncmd+/eBfD4GdQAcPjwYRQUFMDf31+q8fLygru7OxISEvD2228jISEB9erVg7Ozs1QTEBCATz75BCdPnkSjRo2QkJCgsY2imlGjRgEA8vPzcfjwYYSHh0vrjYyM4O/vj4SEhGf2mpeXh7y8PGk+Oztb6/1OS0vDjRs3tH69XI6OjnB3dzfI2Ibcd0PuN9GbptSESWFhIUaNGoUWLVrAx8cHAJCZmQlTU1PY2dlp1Do7OyMzM1OqeTJIitYXrXtRTXZ2Nh4+fIjbt29DrVY/s+b06dPP7Hf69On4z3/+o93OPiEtLQ21veog9+ED2dvSlpm5Bc6cTtb7B6uh991Q+030Jio1YRISEoITJ05g9+7dhm7llYSHhyMsLEyaL7rtwOu6ceMGch8+gEOXMTBx0P+9vQpuXsbNdbNw48YNvX+oGnLfDbnfRG+iUhEmoaGhWLduHXbu3KlxMzEXFxfk5+fjzp07GkcnWVlZcHFxkWqevuqq6GqvJ2uevgIsKysLNjY2MDc3h7GxMYyNjZ9ZU7SNpymVSiiVSu12+BlMHNygdKmhs+2VJeV534neFAa9mksIgdDQUPz111+Ij4+Hp6enxvomTZrAxMQEW7dulZadOXMGaWlp8PPzAwD4+fnh+PHjGlddxcXFwcbGBnXr1pVqntxGUU3RNkxNTdGkSRONmsLCQmzdulWqISKi5zPokUlISAiio6Px999/w9raWjrHYWtrC3Nzc9ja2iI4OBhhYWGwt7eHjY0NPvvsM/j5+eHtt98GAHTo0AF169bFhx9+iBkzZiAzMxMTJ05ESEiIdOQwYsQIzJ8/H+PHj8fQoUMRHx+P1atXY/369VIvYWFhGDRoEHx9fdG0aVPMnTsX9+/fx5AhQ/T/xhARlTEGDZNFixYBANq2bauxPDIyEoMHDwYAzJkzB0ZGRujRowfy8vIQEBCAhQsXSrXGxsZYt24dPvnkE/j5+cHS0hKDBg3C1KlTpRpPT0+sX78eo0ePRkREBKpUqYJffvkFAQEBUk3v3r1x/fp1TJo0CZmZmWjYsCE2bdpU7KQ8vVmSk5MNMi6vJKM3jUHDRAjx0hozMzMsWLAACxYseG6Nh4cHNmzY8MLttG3bFkePHn1hTWhoKEJDQ1/aE5V96pzbgEKBAQMGGGR8XklGb5pScQKeSN8K83IAIXglGZGOMEyoXOOVZES6wbsGExGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJFsFQzdAVF4lJycbbGxHR0e4u7sbbHx68zBMiPRMnXMbUCgwYMAAg/VgZm6BM6eTGSikMwwTIj0rzMsBhIBDlzEwcXDT+/gFNy/j5rpZuHHjBsOEdMag50x27tyJrl27QqVSQaFQYO3atRrrBw8eDIVCoTF17NhRo+bWrVvo378/bGxsYGdnh+DgYOTk5GjUJCUloVWrVjAzM4ObmxtmzJhRrJeYmBh4eXnBzMwM9erVw4YNG3S+v0RPMnFwg9Klht4nQwQYvfkMGib3799HgwYNsGDBgufWdOzYERkZGdK0cuVKjfX9+/fHyZMnERcXh3Xr1mHnzp0YPny4tD47OxsdOnSAh4cHDh8+jJkzZ2LKlClYsmSJVLN371707dsXwcHBOHr0KLp164Zu3brhxIkTut9pIqI3kEG/5urUqRM6der0whqlUgkXF5dnrktOTsamTZtw8OBB+Pr6AgDmzZuHzp0748cff4RKpcLvv/+O/Px8LF26FKampvD29kZiYiJmz54thU5ERAQ6duyIcePGAQCmTZuGuLg4zJ8/H4sXL9bhHhMRvZlK/aXB27dvh5OTE2rXro1PPvkEN2/elNYlJCTAzs5OChIA8Pf3h5GREfbv3y/VtG7dGqamplJNQEAAzpw5g9u3b0s1/v7+GuMGBAQgISHhuX3l5eUhOztbYyIiKq9KdZh07NgRy5cvx9atW/HDDz9gx44d6NSpE9RqNQAgMzMTTk5OGq+pUKEC7O3tkZmZKdU4Oztr1BTNv6ymaP2zTJ8+Hba2ttLk5sbvoYmo/CrVV3P16dNH+nO9evVQv359VK9eHdu3b0f79u0N2BkQHh6OsLAwaT47O5uBQkTlVqk+MnlatWrV4OjoiNTUVACAi4sLrl27plHz6NEj3Lp1SzrP4uLigqysLI2aovmX1TzvXA3w+FyOjY2NxkREVF6VqTC5cuUKbt68CVdXVwCAn58f7ty5g8OHD0s18fHxKCwsRLNmzaSanTt3oqCgQKqJi4tD7dq1UbFiRalm69atGmPFxcXBz8+vpHeJiOiNYNAwycnJQWJiIhITEwEAFy5cQGJiItLS0pCTk4Nx48Zh3759uHjxIrZu3YqgoCDUqFEDAQEBAIA6deqgY8eO+Oijj3DgwAHs2bMHoaGh6NOnD1QqFQCgX79+MDU1RXBwME6ePIlVq1YhIiJC4yuqkSNHYtOmTZg1axZOnz6NKVOm4NChQwgNDdX7e0JEVBYZNEwOHTqERo0aoVGjRgCAsLAwNGrUCJMmTYKxsTGSkpLw3nvvoVatWggODkaTJk2wa9cuKJVKaRu///47vLy80L59e3Tu3BktW7bU+A2Jra0tNm/ejAsXLqBJkyYYM2YMJk2apPFblObNmyM6OhpLlixBgwYNsGbNGqxduxY+Pj76ezOIiMowg56Ab9u2LYQQz10fGxv70m3Y29sjOjr6hTX169fHrl27XljTs2dP9OzZ86XjERFRcWXqnAkREZVODBMiIpKNYUJERLIxTIiISDaGCRERycYwISIi2RgmREQkG8OEiIhkY5gQEZFsDBMiIpJNqzA5f/68rvsgIqIyTKswqVGjBtq1a4cVK1YgNzdX1z0REVEZo1WYHDlyBPXr10dYWBhcXFzw8ccf48CBA7rujYiIygitwqRhw4aIiIhAeno6li5dioyMDLRs2RI+Pj6YPXs2rl+/rus+iYioFJN1Ar5ChQro3r07YmJi8MMPPyA1NRVjx46Fm5sbBg4ciIyMDF31SUREpZisMDl06BA+/fRTuLq6Yvbs2Rg7dizOnTuHuLg4pKenIygoSFd9EhFRKabVw7Fmz56NyMhInDlzBp07d8by5cvRuXNnGBk9ziZPT09ERUWhatWquuyViIhKKa3CZNGiRRg6dCgGDx4MV1fXZ9Y4OTnh119/ldUcERGVDVqFSUpKyktrTE1NMWjQIG02T0REZYxW50wiIyMRExNTbHlMTAyWLVsmuykiIipbtAqT6dOnw9HRsdhyJycnfPfdd7KbIiKiskWrMElLS4Onp2ex5R4eHkhLS5PdFBERlS1ahYmTkxOSkpKKLT927BgcHBxkN0VERGWLVmHSt29ffP7559i2bRvUajXUajXi4+MxcuRI9OnTR9c9EhFRKafV1VzTpk3DxYsX0b59e1So8HgThYWFGDhwIM+ZEBGVQ1qFiampKVatWoVp06bh2LFjMDc3R7169eDh4aHr/oiIqAzQKkyK1KpVC7Vq1dJVL0REVEZpFSZqtRpRUVHYunUrrl27hsLCQo318fHxOmmOiIjKBq3CZOTIkYiKikJgYCB8fHygUCh03RcREZUhWoXJH3/8gdWrV6Nz58667oeIiMogrS4NNjU1RY0aNXTdCxERlVFahcmYMWMQEREBIYSu+yEiojJIq6+5du/ejW3btmHjxo3w9vaGiYmJxvo///xTJ80REVHZoFWY2NnZ4f3339d1L0REVEZpFSaRkZG67oOIiMowrZ8B/+jRI2zZsgU///wz7t27BwBIT09HTk6OzpojIqKyQasjk0uXLqFjx45IS0tDXl4e3n33XVhbW+OHH35AXl4eFi9erOs+iYioFNPqyGTkyJHw9fXF7du3YW5uLi1///33sXXrVp01R0REZYNWRya7du3C3r17YWpqqrG8atWquHr1qk4aIyKiskOrI5PCwkKo1epiy69cuQJra2vZTRERUdmiVZh06NABc+fOleYVCgVycnIwefJk3mKFiKgc0uprrlmzZiEgIAB169ZFbm4u+vXrh5SUFDg6OmLlypW67pGIiEo5rcKkSpUqOHbsGP744w8kJSUhJycHwcHB6N+/v8YJeSIiKh+0fjhWhQoVMGDAAF32QkREZZRW50yWL1/+wulV7dy5E127doVKpYJCocDatWs11gshMGnSJLi6usLc3Bz+/v5ISUnRqLl16xb69+8PGxsb2NnZITg4uNgPJ5OSktCqVSuYmZnBzc0NM2bMKNZLTEwMvLy8YGZmhnr16mHDhg2v/oYQEZVzWj8c60kFBQV48OABTE1NYWFhgYEDB77Sdu7fv48GDRpg6NCh6N69e7H1M2bMwE8//YRly5bB09MTX3/9NQICAnDq1CmYmZkBAPr374+MjAzExcWhoKAAQ4YMwfDhwxEdHQ0AyM7ORocOHeDv74/Fixfj+PHjGDp0KOzs7DB8+HAAwN69e9G3b19Mnz4dXbp0QXR0NLp164YjR47Ax8dHm7eIiKhc0SpMbt++XWxZSkoKPvnkE4wbN+6Vt9OpUyd06tTpmeuEEJg7dy4mTpyIoKAgAI+PiJydnbF27Vr06dMHycnJ2LRpEw4ePAhfX18AwLx589C5c2f8+OOPUKlU+P3335Gfn4+lS5fC1NQU3t7eSExMxOzZs6UwiYiIQMeOHaXep02bhri4OMyfP5+/5iciegVa35vraTVr1sT3339f7KhFWxcuXEBmZib8/f2lZba2tmjWrBkSEhIAAAkJCbCzs5OCBAD8/f1hZGSE/fv3SzWtW7fW+IFlQEAAzpw5I4ViQkKCxjhFNUXjPEteXh6ys7M1JiKi8kpnYQI8Pimfnp6uk21lZmYCAJydnTWWOzs7S+syMzPh5ORUrAd7e3uNmmdt48kxnldTtP5Zpk+fDltbW2lyc3N73V0kInpjaPU11z///KMxL4RARkYG5s+fjxYtWuiksdIuPDwcYWFh0nx2djYDhYjKLa3CpFu3bhrzCoUClSpVwjvvvINZs2bpoi+4uLgAALKysuDq6iotz8rKQsOGDaWaa9euabzu0aNHuHXrlvR6FxcXZGVladQUzb+spmj9syiVSiiVSi32jIjozaP1vbmenNRqNTIzMxEdHa3xwS+Hp6cnXFxcNO5CnJ2djf3798PPzw8A4Ofnhzt37uDw4cNSTXx8PAoLC9GsWTOpZufOnSgoKJBq4uLiULt2bVSsWFGqefpux3FxcdI4RET0Yjo9Z/K6cnJykJiYiMTERACPT7onJiYiLS0NCoUCo0aNwjfffIN//vkHx48fx8CBA6FSqaQjozp16qBjx4746KOPcODAAezZswehoaHo06cPVCoVAKBfv34wNTVFcHAwTp48iVWrViEiIkLjK6qRI0di06ZNmDVrFk6fPo0pU6bg0KFDCA0N1fdbQkRUJmn1NdeTH8QvM3v27OeuO3ToENq1a1dsu4MGDUJUVBTGjx+P+/fvY/jw4bhz5w5atmyJTZs2Sb8xAYDff/8doaGhaN++PYyMjNCjRw/89NNP0npbW1ts3rwZISEhaNKkCRwdHTFp0iTpsmAAaN68OaKjozFx4kR8+eWXqFmzJtauXcvfmBARvSKtwuTo0aM4evQoCgoKULt2bQDA2bNnYWxsjMaNG0t1CoXihdtp27YthBDPXa9QKDB16lRMnTr1uTX29vbSDxSfp379+ti1a9cLa3r27ImePXu+sIaIiJ5NqzDp2rUrrK2tsWzZMum8w+3btzFkyBC0atUKY8aM0WmTRERUuml9C/rNmzdLQQIAFStWxDfffIMOHTowTIjoudLS0nDjxg2DjO3o6Ah3d3eDjP2m0ypMsrOzcf369WLLr1+/jnv37sluiojeTGlpaajtVQe5Dx8YZHwzcwucOZ3MQCkBWoXJ+++/jyFDhmDWrFlo2rQpAGD//v0YN27cM2/YSEQEADdu3EDuwwdw6DIGJg76/ZFvwc3LuLluFm7cuMEwKQFahcnixYsxduxY9OvXT/r9RoUKFRAcHIyZM2fqtEEievOYOLhB6VLD0G2QDmkVJhYWFli4cCFmzpyJc+fOAQCqV68OS0tLnTZHRERlg6wfLWZkZCAjIwM1a9aEpaXlCy/zJSKiN5dWYXLz5k20b98etWrVQufOnZGRkQEACA4O5pVcRETlkFZhMnr0aJiYmCAtLQ0WFhbS8t69e2PTpk06a46IiMoGrc6ZbN68GbGxsahSpYrG8po1a+LSpUs6aYyIiMoOrY5M7t+/r3FEUuTWrVu8LTsRUTmkVZi0atUKy5cvl+YVCgUKCwsxY8YMjRs3EhFR+aDV11wzZsxA+/btcejQIeTn52P8+PE4efIkbt26hT179ui6RyIiKuW0OjLx8fHB2bNn0bJlSwQFBeH+/fvo3r07jh49iurVq+u6RyIiKuVe+8ikoKAAHTt2xOLFi/HVV1+VRE9ERFTGvPaRiYmJCZKSkkqiFyIiKqO0+pprwIAB+PXXX3XdCxERlVFanYB/9OgRli5dii1btqBJkybF7sn1okf1EhHRm+e1wuT8+fOoWrUqTpw4IT2e9+zZsxo1L3tULxERvXleK0xq1qyJjIwMbNu2DcDj26f89NNPcHZ2LpHmiIiobHitcyZP3xV448aNuH//vk4bIiKiskfWLeh5y3kiIgJeM0wUCkWxcyI8R0JERK91zkQIgcGDB0s3c8zNzcWIESOKXc31559/6q5DIiIq9V4rTAYNGqQxP2DAAJ02Q0REZdNrhUlkZGRJ9UFERGWYrBPwREREgJa/gCeisi85OblcjEn6wTAhKmfUObcBhYLnPEmnGCZE5UxhXg4gBBy6jIGJg5tex354/hDu7lqh1zFJPxgmROWUiYMblC419Dpmwc3Leh2P9Icn4ImISDaGCRERycYwISIi2RgmREQkG8OEiIhkY5gQEZFsDBMiIpKNYUJERLIxTIiISDaGCRERycYwISIi2RgmREQkG8OEiIhkK9VhMmXKFCgUCo3Jy8tLWp+bm4uQkBA4ODjAysoKPXr0QFZWlsY20tLSEBgYCAsLCzg5OWHcuHF49OiRRs327dvRuHFjKJVK1KhRA1FRUfrYPSKiN0apDhMA8Pb2RkZGhjTt3r1bWjd69Gj8+++/iImJwY4dO5Ceno7u3btL69VqNQIDA5Gfn4+9e/di2bJliIqKwqRJk6SaCxcuIDAwEO3atUNiYiJGjRqFYcOGITY2Vq/7SURUlpX655lUqFABLi4uxZbfvXsXv/76K6Kjo/HOO+8AACIjI1GnTh3s27cPb7/9NjZv3oxTp05hy5YtcHZ2RsOGDTFt2jRMmDABU6ZMgampKRYvXgxPT0/MmjULAFCnTh3s3r0bc+bMQUBAgF73lYiorCr1RyYpKSlQqVSoVq0a+vfvj7S0NADA4cOHUVBQAH9/f6nWy8sL7u7uSEhIAAAkJCSgXr16cHZ2lmoCAgKQnZ2NkydPSjVPbqOopmgbz5OXl4fs7GyNiYiovCrVYdKsWTNERUVh06ZNWLRoES5cuIBWrVrh3r17yMzMhKmpKezs7DRe4+zsjMzMTABAZmamRpAUrS9a96Ka7OxsPHz48Lm9TZ8+Hba2ttLk5qbfx58SEZUmpfprrk6dOkl/rl+/Ppo1awYPDw+sXr0a5ubmBuwMCA8PR1hYmDSfnZ3NQCGicqtUH5k8zc7ODrVq1UJqaipcXFyQn5+PO3fuaNRkZWVJ51hcXFyKXd1VNP+yGhsbmxcGllKphI2NjcZERFRelakwycnJwblz5+Dq6oomTZrAxMQEW7duldafOXMGaWlp8PPzAwD4+fnh+PHjuHbtmlQTFxcHGxsb1K1bV6p5chtFNUXbICKilyvVYTJ27Fjs2LEDFy9exN69e/H+++/D2NgYffv2ha2tLYKDgxEWFoZt27bh8OHDGDJkCPz8/PD2228DADp06IC6deviww8/xLFjxxAbG4uJEyciJCQESqUSADBixAicP38e48ePx+nTp7Fw4UKsXr0ao0ePNuSuExGVKaX6nMmVK1fQt29f3Lx5E5UqVULLli2xb98+VKpUCQAwZ84cGBkZoUePHsjLy0NAQAAWLlwovd7Y2Bjr1q3DJ598Aj8/P1haWmLQoEGYOnWqVOPp6Yn169dj9OjRiIiIQJUqVfDLL7/wsmAiotdQqsPkjz/+eOF6MzMzLFiwAAsWLHhujYeHBzZs2PDC7bRt2xZHjx7VqkciIirlX3MREVHZwDAhIiLZGCZERCQbw4SIiGQr1SfgSX+Sk5PLxZhEVDIYJuWcOuc2oFBgwIABhm6FiMowhkk5V5iXAwgBhy5jYOKg33uLPTx/CHd3rdDrmERUMhgmBAAwcXCD0qWGXscsuHlZr+MRUcnhCXgiIpKNYUJERLIxTIiISDaGCRERycYT8EREepKWloYbN24YZGxHR0e4u7uX2PYZJkREepCWlobaXnWQ+/CBQcY3M7fAmdPJJRYoDBMiIj24ceMGch8+MMhvugpuXsbNdbNw48YNhgkR0ZvAEL/p0geegCciItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZOO9uYioXElOTi5X4+oLw4SIygV1zm1AocCAAQMM3cobiWFCROVCYV4OIIRBbgEPAA/PH8LdXSv0Pq6+MEyIqFwx1C3gC25e1vuY+sQT8EREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyesmDBAlStWhVmZmZo1qwZDhw4YOiWiIhKPYbJE1atWoWwsDBMnjwZR44cQYMGDRAQEIBr164ZujUiolKNYfKE2bNn46OPPsKQIUNQt25dLF68GBYWFli6dKmhWyMiKtX4cKz/l5+fj8OHDyM8PFxaZmRkBH9/fyQkJBSrz8vLQ15enjR/9+5dAEB2dvZrjZuTk/N4e5mpKMzP1aZ1WYoe2GOI8Tk2/5uXl7ENPX7BrSsAHn/evM5nVFGtEOLlxYKEEEJcvXpVABB79+7VWD5u3DjRtGnTYvWTJ08WADhx4sTpjZ8uX7780s9QHploKTw8HGFhYdJ8YWEhbt26BQcHBygUilfeTnZ2Ntzc3HD58mXY2NiURKtlspfS1g97Kf29lLZ+3oRehBC4d+8eVCrVS2sZJv/P0dERxsbGyMrK0lielZUFFxeXYvVKpRJKpVJjmZ2dndbj29jYGPx/uCKlqRegdPXDXp6tNPUClK5+ynovtra2r1THE/D/z9TUFE2aNMHWrVulZYWFhdi6dSv8/PwM2BkRUenHI5MnhIWFYdCgQfD19UXTpk0xd+5c3L9/H0OGDDF0a0REpRrD5Am9e/fG9evXMWnSJGRmZqJhw4bYtGkTnJ2dS2xMpVKJyZMnF/vKzBBKUy9A6eqHvZT+XoDS1U9560UhxKtc80VERPR8PGdCRESyMUyIiEg2hgkREcnGMCEiItkYJgayc+dOdO3aFSqVCgqFAmvXrjVYL9OnT8dbb70Fa2trODk5oVu3bjhz5oxBelm0aBHq168v/bjKz88PGzduNEgvT/v++++hUCgwatQog4w/ZcoUKBQKjcnLy8sgvQDA1atXMWDAADg4OMDc3Bz16tXDoUOH9N5H1apVi70vCoUCISEheu9FrVbj66+/hqenJ8zNzVG9enVMmzbt1e5tVQLu3buHUaNGwcPDA+bm5mjevDkOHjxYImPx0mADuX//Pho0aIChQ4eie/fuBu1lx44dCAkJwVtvvYVHjx7hyy+/RIcOHXDq1ClYWlrqtZcqVarg+++/R82aNSGEwLJlyxAUFISjR4/C29tbr7086eDBg/j5559Rv359g/UAAN7e3tiyZYs0X6GCYf4K3759Gy1atEC7du2wceNGVKpUCSkpKahYsaLeezl48CDUarU0f+LECbz77rvo2bOn3nv54YcfsGjRIixbtgze3t44dOgQhgwZAltbW3z++ed672fYsGE4ceIEfvvtN6hUKqxYsQL+/v44deoUKleurNvBdHGTRJIHgPjrr78M3Ybk2rVrAoDYsWOHoVsRQghRsWJF8csvvxhs/Hv37omaNWuKuLg40aZNGzFy5EiD9DF58mTRoEEDg4z9tAkTJoiWLVsauo1nGjlypKhevbooLCzU+9iBgYFi6NChGsu6d+8u+vfvr/deHjx4IIyNjcW6des0ljdu3Fh89dVXOh+PX3NRMUW307e3tzdoH2q1Gn/88Qfu379v0FvahISEIDAwEP7+/gbroUhKSgpUKhWqVauG/v37Iy0tzSB9/PPPP/D19UXPnj3h5OSERo0a4b///a9BenlSfn4+VqxYgaFDh77WDVd1pXnz5ti6dSvOnj0LADh27Bh2796NTp066b2XR48eQa1Ww8zMTGO5ubk5du/erfsBdR5P9NpQio5M1Gq1CAwMFC1atDBYD0lJScLS0lIYGxsLW1tbsX79eoP1snLlSuHj4yMePnwohBAGPTLZsGGDWL16tTh27JjYtGmT8PPzE+7u7iI7O1vvvSiVSqFUKkV4eLg4cuSI+Pnnn4WZmZmIiorSey9PWrVqlTA2NhZXr141yPhqtVpMmDBBKBQKUaFCBaFQKMR3331nkF6EEMLPz0+0adNGXL16VTx69Ej89ttvwsjISNSqVUvnYzFMSoHSFCYjRowQHh4er/T8gpKSl5cnUlJSxKFDh8QXX3whHB0dxcmTJ/XeR1pamnBychLHjh2TlhkyTJ52+/ZtYWNjY5CvAE1MTISfn5/Gss8++0y8/fbbeu/lSR06dBBdunQx2PgrV64UVapUEStXrhRJSUli+fLlwt7e3mAhm5qaKlq3bi0ACGNjY/HWW2+J/v37Cy8vL52PxTApBUpLmISEhIgqVaqI8+fPG7oVDe3btxfDhw/X+7h//fWX9JewaAIgFAqFMDY2Fo8ePdJ7T0/z9fUVX3zxhd7HdXd3F8HBwRrLFi5cKFQqld57KXLx4kVhZGQk1q5da7AeqlSpIubPn6+xbNq0aaJ27doG6uixnJwckZ6eLoQQolevXqJz5846H4PnTAhCCISGhuKvv/5CfHw8PD09Dd2ShsLCQo1HJOtL+/btcfz4cSQmJkqTr68v+vfvj8TERBgbG+u9pyfl5OTg3LlzcHV11fvYLVq0KHb5+NmzZ+Hh4aH3XopERkbCyckJgYGBBuvhwYMHMDLS/Fg1NjZGYWGhgTp6zNLSEq6urrh9+zZiY2MRFBSk8zF4abCB5OTkIDU1VZq/cOECEhMTYW9vD3d3d732EhISgujoaPz999+wtrZGZmYmgMcPxTE3N9drL+Hh4ejUqRPc3d1x7949REdHY/v27YiNjdVrHwBgbW0NHx8fjWWWlpZwcHAotlwfxo4di65du8LDwwPp6emYPHkyjI2N0bdvX733Mnr0aDRv3hzfffcdevXqhQMHDmDJkiVYsmSJ3nsBHv+DIzIyEoMGDTLY5dIA0LVrV3z77bdwd3eHt7c3jh49itmzZ2Po0KEG6Sc2NhZCCNSuXRupqakYN24cvLy8SuaxGjo/1qFXsm3btmc+a3nQoEF67+VZfQAQkZGReu9l6NChwsPDQ5iamopKlSqJ9u3bi82bN+u9j+cx5DmT3r17C1dXV2FqaioqV64sevfuLVJTUw3SixBC/Pvvv8LHx0colUrh5eUllixZYrBeYmNjBQBx5swZg/UghBDZ2dli5MiRwt3dXZiZmYlq1aqJr776SuTl5Rmkn1WrVolq1aoJU1NT4eLiIkJCQsSdO3dKZCzegp6IiGTjORMiIpKNYUJERLIxTIiISDaGCRERycYwISIi2RgmREQkG8OEiIhkY5gQEZFsDBOiUq5t27YGe1Qw0atimBCVoK5du6Jjx47PXLdr1y4oFAokJSXpuSsi3WOYEJWg4OBgxMXF4cqVK8XWRUZGwtfX1+DPlSfSBYYJUQnq0qULKlWqhKioKI3lOTk5iImJQbdu3dC3b19UrlwZFhYWqFevHlauXPnCbSoUCqxdu1ZjmZ2dncYYly9fRq9evWBnZwd7e3sEBQXh4sWL0vrt27ejadOmsLS0hJ2dHVq0aIFLly7J3FsqzxgmRCWoQoUKGDhwIKKiovDkPVVjYmKgVqsxYMAANGnSBOvXr8eJEycwfPhwfPjhhzhw4IDWYxYUFCAgIADW1tbYtWsX9uzZAysrK3Ts2BH5+fl49OgRunXrhjZt2iApKQkJCQkYPny4QZ6ZTm8OPs+EqIQNHToUM2fOxI4dO9C2bVsAj7/i6tGjBzw8PDB27Fip9rPPPkNsbCxWr16Npk2bajXeqlWrUFhYiF9++UUKiMjISNjZ2WH79u3w9fXF3bt30aVLF1SvXh0AUKdOHXk7SeUej0yISpiXlxeaN2+OpUuXAgBSU1Oxa9cuBAcHQ61WY9q0aahXrx7s7e1hZWWF2NhYpKWlaT3esWPHkJqaCmtra1hZWcHKygr29vbIzc3FuXPnYG9vj8GDByMgIABdu3ZFREQEMjIydLW7VE4xTIj0IDg4GP/73/9w7949REZGonr16mjTpg1mzpyJiIgITJgwAdu2bUNiYiICAgKQn5//3G0pFAo8/RiigoIC6c85OTlo0qSJxuOGExMTcfbsWfTr1w/A4yOVhIQENG/eHKtWrUKtWrWwb9++ktl5KhcYJkR60KtXLxgZGSE6OhrLly/H0KFDoVAosGfPHgQFBWHAgAFo0KABqlWrhrNnz75wW5UqVdI4kkhJScGDBw+k+caNGyMlJQVOTk6oUaOGxmRrayvVNWrUCOHh4di7dy98fHwQHR2t+x2ncoNhQqQHVlZW6N27N8LDw5GRkYHBgwcDAGrWrIm4uDjs3bsXycnJ+Pjjj5GVlfXCbb3zzjuYP38+jh49ikOHDmHEiBEwMTGR1vfv3x+Ojo4ICgrCrl27cOHCBWzfvh2ff/45rly5ggsXLiA8PBwJCQm4dOkSNm/ejJSUFJ43IVkYJkR6EhwcjNu3byMgIAAqlQoAMHHiRDRu3BgBAQFo27YtXFxc0K1btxduZ9asWXBzc0OrVq3Qr18/jB07FhYWFtJ6CwsL7Ny5E+7u7ujevTvq1KmD4OBg5ObmwsbGBhYWFjh9+jR69OiBWrVqYfjw4QgJCcHHH39ckrtPbzg+A56IiGTjkQkREcnGMCEiItkYJkREJBvDhIiIZGOYEBGRbAwTIiKSjWFCRESyMUyIiEg2hgkREcnGMCEiItkYJkREJNv/AVdrllyjkHHlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X_time, _y, batch_size = 512, random_state = 1):\n",
    "    # X\n",
    "    X_time = rearrange(X_time, \"b v t -> b t v\")\n",
    "    \n",
    "    X_ind = ~np.isnan(X_time)\n",
    "    X_time = np.nan_to_num(X_time, nan=0.0)\n",
    "    \n",
    "    # Target\n",
    "    _y = _y - 1\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    \n",
    "    # Class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    \n",
    "    # Split\n",
    "    X_time_train, X_time_test, X_ind_train, X_ind_test, y_train, y_test = train_test_split(X_time, X_ind, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_time_test, X_time_val, X_ind_test, X_ind_val, y_test, y_val = train_test_split(X_time_test, X_ind_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "\n",
    "    # Normalize\n",
    "    # X_time_train, X_time_val, X_time_test = normalize_across_time(X_time_train, X_time_val, X_time_test, X_time.shape[2])\n",
    "    \n",
    "    \n",
    "    # Datasets\n",
    "    X_time_train = torch.tensor(X_time_train, dtype=torch.float32)\n",
    "    X_ind_train = torch.tensor(X_ind_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train)\n",
    "\n",
    "    X_time_val = torch.tensor(X_time_val, dtype=torch.float32)\n",
    "    X_ind_val = torch.tensor(X_ind_val, dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val)\n",
    "\n",
    "    X_time_test = torch.tensor(X_time_test, dtype=torch.float32)\n",
    "    X_ind_test = torch.tensor(X_ind_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test)\n",
    "\n",
    "\n",
    "    # Dataloaders\n",
    "    train_dataset = TensorDataset(X_time_train, X_ind_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    val_dataset = TensorDataset(X_time_val, X_ind_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    test_dataset = TensorDataset(X_time_test, X_ind_test, y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test, n_variables = 10):\n",
    "    # scalerX=StandardScaler(with_std=False)\n",
    "    scalerX=RobustScaler()\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5538, 2.8525, 0.5538, 0.5710, 0.7132, 1.6248, 1.2057, 6.3149, 3.5524],\n",
      "       device='cuda:10') 9\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512, 23, 10])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for batch in train_loader:\n",
    "    [print(t.shape) for t in batch]\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                    use_multiplicative_interactions, top_k=''):\n",
    "    model = original_models.CBM(static_dim = static_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = True,\n",
    "                                use_fixes = False,\n",
    "                                use_only_last_timestep = False,\n",
    "                                use_grad_norm = False,\n",
    "                                noise_std = False,\n",
    "                                use_multiplicative_interactions = use_multiplicative_interactions,\n",
    "                                use_summaries = True,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=0, #1e-3,\n",
    "                                cos_sim_lambda=0, #1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, static_dim, changing_dim, seq_len, output_dim, \n",
    "                                 use_summaries_for_atomics, use_indicators, use_fixes, top_k=''):\n",
    "    model = new_models.CBM(static_dim = static_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            use_fixes = use_fixes,\n",
    "                            use_grad_norm = False,\n",
    "                            noise_std = False,\n",
    "                            use_summaries = True,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=0, #1e-3,\n",
    "                            cos_sim_lambda=0, #1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0 23\n"
     ]
    }
   ],
   "source": [
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "f1_metric = F1Score(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "seq_len = X.shape[2]\n",
    "changing_dim = X.shape[1]\n",
    "static_dim = 0\n",
    "\n",
    "print(changing_dim, static_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "config_original = {\n",
    "    \"n_concepts\": [4, 20],\n",
    "    \"use_multiplicative_interactions\": [False, \"MI\", \"SA\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_og = list(product(*config_original.values()))\n",
    "all_config_permutations_og = [dict(zip(config_original.keys(), permutation)) for permutation in all_config_permutations_og]\n",
    "print(len(all_config_permutations_og))\n",
    "# all_config_permutations_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/original/\"\n",
    "# model_path = experiment_folder + \"tiselac_c{n_concepts}_use_multiplicative_interactions_{use_multiplicative_interactions}.pt\"\n",
    "model_path = experiment_folder + \"c_{n_concepts}_use_multiplicative_interactions_{use_multiplicative_interactions}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_concepts': 4, 'use_multiplicative_interactions': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/original/c_4_use_multiplicative_interactions_False.pt\n",
      "['original', 0, 1.4785268306732178, 0.8440092206001282, 0.5190349817276001, 0.5190349817276001]\n",
      "1 {'n_concepts': 4, 'use_multiplicative_interactions': 'MI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/original/c_4_use_multiplicative_interactions_MI.pt\n",
      "['original', 1, 2.0618937015533447, 0.6306192278862, 0.28334254026412964, 0.28334254026412964]\n",
      "2 {'n_concepts': 4, 'use_multiplicative_interactions': 'SA'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 719/10000 [23:37<5:05:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 1.9729722738265991, 0.686274528503418, 0.2801825702190399, 0.2801825702190399]\n",
      "3 {'n_concepts': 20, 'use_multiplicative_interactions': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 509/10000 [15:28<4:48:24,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 1.3518584966659546, 0.8853154182434082, 0.5339820384979248, 0.5339820384979248]\n",
      "4 {'n_concepts': 20, 'use_multiplicative_interactions': 'MI'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 249/10000 [21:41<14:09:30,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 2.1236886978149414, 0.5889959335327148, 0.16271254420280457, 0.16271254420280457]\n",
      "5 {'n_concepts': 20, 'use_multiplicative_interactions': 'SA'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 279/10000 [09:16<5:23:26,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 2.115729570388794, 0.5838969349861145, 0.17620503902435303, 0.17620503902435303]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_og):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)\n",
    "    \n",
    "    model = initializeModel(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            *data, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(*data)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [\"original\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    histories_original.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "config_atomics = {\n",
    "    \"n_atomics\": [10, 30], # 30\n",
    "    \"n_concepts\": [4, 20], # 20\n",
    "    \"use_indicators\": [True, False],\n",
    "    \"use_fixes\": [False, True],\n",
    "    \"use_summaries_for_atomics\": [True, False],\n",
    "    # \"use_grad_norm\": [False, \"FULL\", \"COMPONENT_WISE\"],\n",
    "}\n",
    "\n",
    "all_config_permutations_atomics = list(product(*config_atomics.values()))\n",
    "all_config_permutations_atomics = [dict(zip(config_atomics.keys(), permutation)) for permutation in all_config_permutations_atomics]\n",
    "print(len(all_config_permutations_atomics))\n",
    "# all_config_permutations_atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/tiselac/atomics/\"\n",
    "model_path = experiment_folder + \"tiselac_c{n_atomics}_c{n_concepts}_ind{use_indicators}_fixes{use_fixes}_summaries{use_summaries_for_atomics}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 0, 0.8547009229660034, 0.5363042950630188, 0.18999849259853363, 0.18999849259853363, 0.0039618900045752525]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 1, 0.8573909401893616, 0.5430161356925964, 0.19722124934196472, 0.19722124934196472, 0.006042663939297199]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 2, 0.8602383136749268, 0.5151497721672058, 0.16206048429012299, 0.16206048429012299, 0.004117134027183056]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 3, 0.8611301779747009, 0.5354346632957458, 0.05833375081419945, 0.05833375081419945, 0.0053949481807649136]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 4, 0.8640652298927307, 0.5148511528968811, 0.15293173491954803, 0.15293173491954803, 0.0041381134651601315]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 5, 0.8980997204780579, 0.5378944873809814, 0.14746451377868652, 0.14746451377868652, 0.008012873120605946]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 6, 0.8716155886650085, 0.5543808341026306, 0.20665095746517181, 0.20665095746517181, 0.0045175980776548386]\n",
      "7 {'n_atomics': 10, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c4_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 7, 0.8906461596488953, 0.5464768409729004, 0.1602548062801361, 0.1602548062801361, 0.009425458498299122]\n",
      "8 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 8, 0.8098080158233643, 0.5156744122505188, 0.16506996750831604, 0.16506996750831604, 0.009448070079088211]\n",
      "9 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 9, 0.7911016345024109, 0.4974201023578644, 0.09108692407608032, 0.09108692407608032, 0.007826822809875011]\n",
      "10 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 10, 0.8098523616790771, 0.49672433733940125, 0.1879921704530716, 0.1879921704530716, 0.009856680408120155]\n",
      "11 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 11, 0.779026985168457, 0.5085098147392273, 0.0912373960018158, 0.0912373960018158, 0.006344075780361891]\n",
      "12 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 12, 0.8171895146369934, 0.48434320092201233, 0.15564027428627014, 0.15564027428627014, 0.00967267993837595]\n",
      "13 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 13, 0.8241443037986755, 0.562653660774231, 0.16787882149219513, 0.16787882149219513, 0.007165620569139719]\n",
      "14 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 14, 0.8225510716438293, 0.5108758807182312, 0.1437528282403946, 0.1437528282403946, 0.009143858216702938]\n",
      "15 {'n_atomics': 10, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c10_c20_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 15, 0.7962673306465149, 0.5365119576454163, 0.06956914067268372, 0.06956914067268372, 0.007072619162499905]\n",
      "16 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 16, 0.8570713996887207, 0.527302622795105, 0.10984601825475693, 0.10984601825475693, 0.014536398462951183]\n",
      "17 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 17, 0.8790673017501831, 0.5917842388153076, 0.14174650609493256, 0.14174650609493256, 0.013960089534521103]\n",
      "18 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 18, 0.8573738932609558, 0.5269755125045776, 0.18979786336421967, 0.18979786336421967, 0.012066208757460117]\n",
      "19 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 19, 0.8672535419464111, 0.5727379322052002, 0.1901489645242691, 0.1901489645242691, 0.014132418669760227]\n",
      "20 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 20, 0.8956088423728943, 0.5606287717819214, 0.15082509815692902, 0.15082509815692902, 0.04475754126906395]\n",
      "21 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 21, 0.9733768701553345, 0.5181649327278137, 0.16963434219360352, 0.16963434219360352, 0.22039665281772614]\n",
      "22 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 22, 0.8863288760185242, 0.4861914813518524, 0.10427847504615784, 0.10427847504615784, 0.044113535434007645]\n",
      "23 {'n_atomics': 30, 'n_concepts': 4, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c4_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 23, 0.9832081198692322, 0.5574777126312256, 0.18001705408096313, 0.18001705408096313, 0.2212042361497879]\n",
      "24 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indTrue_fixesFalse_summariesTrue.pt\n",
      "['atomics', 24, 0.8100447058677673, 0.5806098580360413, 0.21076390147209167, 0.21076390147209167, 0.012843810021877289]\n",
      "25 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indTrue_fixesFalse_summariesFalse.pt\n",
      "['atomics', 25, 0.7812846899032593, 0.5438549518585205, 0.12619751691818237, 0.12619751691818237, 0.013408645987510681]\n",
      "26 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indTrue_fixesTrue_summariesTrue.pt\n",
      "['atomics', 26, 0.8533369302749634, 0.4938051402568817, 0.13637959957122803, 0.13637959957122803, 0.01285081822425127]\n",
      "27 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': True, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indTrue_fixesTrue_summariesFalse.pt\n",
      "['atomics', 27, 0.8107386827468872, 0.5560857057571411, 0.12499372661113739, 0.12499372661113739, 0.013472150079905987]\n",
      "28 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indFalse_fixesFalse_summariesTrue.pt\n",
      "['atomics', 28, 0.8622366189956665, 0.5388990640640259, 0.14269950985908508, 0.14269950985908508, 0.03373926505446434]\n",
      "29 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': False, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indFalse_fixesFalse_summariesFalse.pt\n",
      "['atomics', 29, 0.8996496796607971, 0.5261619091033936, 0.15192857384681702, 0.15192857384681702, 0.1524268537759781]\n",
      "30 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indFalse_fixesTrue_summariesTrue.pt\n",
      "['atomics', 30, 0.8413392305374146, 0.5382510423660278, 0.19250638782978058, 0.19250638782978058, 0.0351271778345108]\n",
      "31 {'n_atomics': 30, 'n_concepts': 20, 'use_indicators': False, 'use_fixes': True, 'use_summaries_for_atomics': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/tiselac/atomics/tiselac_c30_c20_indFalse_fixesTrue_summariesFalse.pt\n",
      "['atomics', 31, 0.8860554695129395, 0.4899686872959137, 0.07699252665042877, 0.07699252665042877, 0.1536286473274231]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for i, config in enumerate(all_config_permutations_atomics):\n",
    "    print(i, config)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, y)#, batch_size=8)\n",
    "    \n",
    "    model = initializeModel_with_atomics(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim = num_classes)\n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config), max_epochs=10000)\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch in test_loader:\n",
    "            X_time, X_ind, X_static, yb = extract_to(batch, device)\n",
    "            probs = model.forward_probabilities(X_time, X_ind, X_static)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "\n",
    "    history = [\"atomics\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    history_atomics.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = pd.concat([df_og, pd.DataFrame(all_config_permutations_og)], axis=1)\n",
    "\n",
    "# df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "# df_atomics = pd.concat([df_atomics, pd.DataFrame(all_config_permutations_atomics)], axis=1)\n",
    "\n",
    "# result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.8440092206001282\n",
      "acc 0.5190349817276001\n",
      "f1 0.5190349817276001\n"
     ]
    }
   ],
   "source": [
    "for col in df_og.columns[3:6]:\n",
    "    baseline = df_og[(df_og['type'] == 'original') & (df_og['config'] == 0)][col].values[0]\n",
    "    print(col, baseline)\n",
    "    df_og[f'{col}_abs_imp'] = df_og[col] - baseline\n",
    "    # result_df[f'{col}_rel_imp'] = result_df[f'{col}_abs_imp'] / baseline\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>config</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>use_multiplicative_interactions</th>\n",
       "      <th>auc_abs_imp</th>\n",
       "      <th>acc_abs_imp</th>\n",
       "      <th>f1_abs_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>1.351858</td>\n",
       "      <td>0.885315</td>\n",
       "      <td>0.533982</td>\n",
       "      <td>0.533982</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041306</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.014947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>1.478527</td>\n",
       "      <td>0.844009</td>\n",
       "      <td>0.519035</td>\n",
       "      <td>0.519035</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>2.061894</td>\n",
       "      <td>0.630619</td>\n",
       "      <td>0.283343</td>\n",
       "      <td>0.283343</td>\n",
       "      <td>4</td>\n",
       "      <td>MI</td>\n",
       "      <td>-0.213390</td>\n",
       "      <td>-0.235692</td>\n",
       "      <td>-0.235692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>1.972972</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.280183</td>\n",
       "      <td>0.280183</td>\n",
       "      <td>4</td>\n",
       "      <td>SA</td>\n",
       "      <td>-0.157735</td>\n",
       "      <td>-0.238852</td>\n",
       "      <td>-0.238852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>2.115730</td>\n",
       "      <td>0.583897</td>\n",
       "      <td>0.176205</td>\n",
       "      <td>0.176205</td>\n",
       "      <td>20</td>\n",
       "      <td>SA</td>\n",
       "      <td>-0.260112</td>\n",
       "      <td>-0.342830</td>\n",
       "      <td>-0.342830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>2.123689</td>\n",
       "      <td>0.588996</td>\n",
       "      <td>0.162713</td>\n",
       "      <td>0.162713</td>\n",
       "      <td>20</td>\n",
       "      <td>MI</td>\n",
       "      <td>-0.255013</td>\n",
       "      <td>-0.356322</td>\n",
       "      <td>-0.356322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type  config  val_loss       auc       acc        f1  n_concepts  \\\n",
       "3  original       3  1.351858  0.885315  0.533982  0.533982          20   \n",
       "0  original       0  1.478527  0.844009  0.519035  0.519035           4   \n",
       "1  original       1  2.061894  0.630619  0.283343  0.283343           4   \n",
       "2  original       2  1.972972  0.686275  0.280183  0.280183           4   \n",
       "5  original       5  2.115730  0.583897  0.176205  0.176205          20   \n",
       "4  original       4  2.123689  0.588996  0.162713  0.162713          20   \n",
       "\n",
       "  use_multiplicative_interactions  auc_abs_imp  acc_abs_imp  f1_abs_imp  \n",
       "3                           False     0.041306     0.014947    0.014947  \n",
       "0                           False     0.000000     0.000000    0.000000  \n",
       "1                              MI    -0.213390    -0.235692   -0.235692  \n",
       "2                              SA    -0.157735    -0.238852   -0.238852  \n",
       "5                              SA    -0.260112    -0.342830   -0.342830  \n",
       "4                              MI    -0.255013    -0.356322   -0.356322  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "df_og.sort_values(by='acc', ascending=False)\n",
    "# atomics: atomics, concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics\n",
    "# original: concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">original</th>\n",
       "      <th>4</th>\n",
       "      <td>0.720301</td>\n",
       "      <td>0.360853</td>\n",
       "      <td>0.360853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.686069</td>\n",
       "      <td>0.290967</td>\n",
       "      <td>0.290967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc       acc        f1\n",
       "type     n_concepts                              \n",
       "original 4           0.720301  0.360853  0.360853\n",
       "         20          0.686069  0.290967  0.290967"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_multiplicative_interactions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">original</th>\n",
       "      <th>False</th>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.526509</td>\n",
       "      <td>0.526509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>0.609808</td>\n",
       "      <td>0.223028</td>\n",
       "      <td>0.223028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>0.635086</td>\n",
       "      <td>0.228194</td>\n",
       "      <td>0.228194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               auc       acc        f1\n",
       "type     use_multiplicative_interactions                              \n",
       "original False                            0.864662  0.526509  0.526509\n",
       "         MI                               0.609808  0.223028  0.223028\n",
       "         SA                               0.635086  0.228194  0.228194"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.32591</td>\n",
       "      <td>0.32591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc      acc       f1\n",
       "type                                \n",
       "original  0.703185  0.32591  0.32591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in sorted(set(list(all_config_permutations_og[0].keys()) )): # + list(all_config_permutations_atomics[0].keys())\n",
    "    display(df_og.groupby([\"type\", key])[[\"auc\", \"acc\", \"f1\"]].mean())\n",
    "\n",
    "display(df_og.groupby(\"type\")[[\"auc\", \"acc\", \"f1\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
