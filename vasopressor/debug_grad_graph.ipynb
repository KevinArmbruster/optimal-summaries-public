{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tgraph [size=\"12,12\"]\n",
      "\tnode [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]\n",
      "\t140349087695104 [label=MulBackward0 fillcolor=red]\n",
      "\t140348414082544 -> 140349087695104\n",
      "\t140348414082544 [label=SumBackward0 fillcolor=white]\n",
      "\t140348408787776 -> 140348414082544\n",
      "\t140348408787776 [label=DivBackward0 fillcolor=red]\n",
      "\t140349086023824 -> 140348408787776\n",
      "\t140348408787920 -> 140348408787776\n",
      "\t140348408787920 [label=MulBackward0 fillcolor=red]\n",
      "\t140349086023744 -> 140348408787920\n",
      "\t140349086023744 [label=\"Variable\n",
      " (10, 10)\" fillcolor=lightblue]\n",
      "\t140349086023824 [label=\"Variable\n",
      " (10, 10)\" fillcolor=lightblue]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "import torch\n",
    "from torch.autograd import Variable, Function\n",
    "\n",
    "\n",
    "def iter_graph(root, callback):\n",
    "    queue = [root]\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        fn = queue.pop()\n",
    "        if fn in seen:\n",
    "            continue\n",
    "        seen.add(fn)\n",
    "        for next_fn, _ in fn.next_functions:\n",
    "            if next_fn is not None:\n",
    "                queue.append(next_fn)\n",
    "        callback(fn)\n",
    "\n",
    "def register_hooks(var):\n",
    "    fn_dict = {}\n",
    "    def hook_cb(fn):\n",
    "        def register_grad(grad_input, grad_output):\n",
    "            fn_dict[fn] = grad_input\n",
    "        fn.register_hook(register_grad)\n",
    "    iter_graph(var.grad_fn, hook_cb)\n",
    "\n",
    "    def is_bad_grad(grad_output):\n",
    "        if grad_output is None:\n",
    "                return True\n",
    "        grad_output = grad_output.data\n",
    "        return torch.isnan(grad_output).any() or grad_output.gt(1e6).any()\n",
    "\n",
    "    def make_dot():\n",
    "        node_attr = dict(style='filled',\n",
    "                        shape='box',\n",
    "                        align='left',\n",
    "                        fontsize='12',\n",
    "                        ranksep='0.1',\n",
    "                        height='0.2')\n",
    "        dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "\n",
    "        def size_to_str(size):\n",
    "            return '('+(', ').join(map(str, size))+')'\n",
    "\n",
    "        def build_graph(fn):\n",
    "            if hasattr(fn, 'variable'):  # if GradAccumulator\n",
    "                u = fn.variable\n",
    "                node_name = 'Variable\\n ' + size_to_str(u.size())\n",
    "                dot.node(str(id(u)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                assert fn in fn_dict, fn\n",
    "                fillcolor = 'white'\n",
    "                if any(is_bad_grad(gi) for gi in fn_dict[fn]):\n",
    "                    fillcolor = 'red'\n",
    "                dot.node(str(id(fn)), str(type(fn).__name__), fillcolor=fillcolor)\n",
    "            for next_fn, _ in fn.next_functions:\n",
    "                if next_fn is not None:\n",
    "                    next_id = id(getattr(next_fn, 'variable', next_fn))\n",
    "                    dot.edge(str(next_id), str(id(fn)))\n",
    "        iter_graph(var.grad_fn, build_graph)\n",
    "\n",
    "        return dot\n",
    "\n",
    "    return make_dot\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    x = Variable(torch.randn(10, 10), requires_grad=True)\n",
    "    y = Variable(torch.randn(10, 10), requires_grad=True)\n",
    "\n",
    "    z = x / (y * 0)\n",
    "    z = z.sum() * 2\n",
    "    get_dot = register_hooks(z)\n",
    "    z.backward()\n",
    "    dot = get_dot()\n",
    "    path = 'aDebugGraph.dot'\n",
    "    dot.save(path)\n",
    "    print(dot)\n",
    "    \n",
    "    s = Source.from_file(path)\n",
    "    s.render('aDebugGraph', format='png', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input layer to hidden layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden layer to output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph {\n",
      "\tgraph [size=\"12,12\"]\n",
      "\tnode [align=left fontsize=12 height=0.2 ranksep=0.1 shape=box style=filled]\n",
      "\t140349087690912 [label=AddmmBackward0 fillcolor=white]\n",
      "\t140349087626432 -> 140349087690912\n",
      "\t140349087689856 -> 140349087690912\n",
      "\t140349087691104 -> 140349087690912\n",
      "\t140349087691104 [label=TBackward0 fillcolor=white]\n",
      "\t140349087626032 -> 140349087691104\n",
      "\t140349087626032 [label=\"Variable\n",
      " (2, 100)\" fillcolor=lightblue]\n",
      "\t140349087689856 [label=ReluBackward0 fillcolor=white]\n",
      "\t140349087686448 -> 140349087689856\n",
      "\t140349087686448 [label=AddmmBackward0 fillcolor=white]\n",
      "\t140349087615312 -> 140349087686448\n",
      "\t140349087626512 -> 140349087686448\n",
      "\t140349087696928 -> 140349087686448\n",
      "\t140349087696928 [label=TBackward0 fillcolor=white]\n",
      "\t140349087614672 -> 140349087696928\n",
      "\t140349087614672 [label=\"Variable\n",
      " (100, 13)\" fillcolor=lightblue]\n",
      "\t140349087626512 [label=\"Variable\n",
      " (1, 13)\" fillcolor=lightblue]\n",
      "\t140349087615312 [label=\"Variable\n",
      " (100)\" fillcolor=lightblue]\n",
      "\t140349087626432 [label=\"Variable\n",
      " (2)\" fillcolor=lightblue]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'aDebugGraph.png'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(1, 13), requires_grad=True)\n",
    "y = Variable(torch.randn(1, 2), requires_grad=True)\n",
    "\n",
    "\n",
    "model = SimpleNN(13, 100, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.1, weight_decay=0.01)\n",
    "pred = model(x)\n",
    "\n",
    "loss = torch.nn.functional.mse_loss(y, pred)\n",
    "\n",
    "get_dot = register_hooks(pred)\n",
    "loss.backward()\n",
    "dot = get_dot()\n",
    "path = 'aDebugGraph.dot'\n",
    "dot.save(path)\n",
    "print(dot)\n",
    "\n",
    "s = Source.from_file(path)\n",
    "s.render('aDebugGraph', format='png', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
