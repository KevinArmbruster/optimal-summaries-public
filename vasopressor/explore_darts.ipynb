{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from darts.datasets import ETTh1Dataset\n",
    "from darts.models import NLinearModel\n",
    "from darts.metrics.metrics import mae, mse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torchmetrics.regression import MeanAbsoluteError, MeanSquaredError\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances, plot_timeline\n",
    "\n",
    "import models\n",
    "import models_3d_concepts_on_time\n",
    "import models_3d_atomics_on_variate_to_concepts\n",
    "from preprocess_helpers import *\n",
    "from helper import *\n",
    "from param_initializations import *\n",
    "from optimization_strategy import greedy_selection\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-07-01 00:00:00\n",
      "2018-06-26 19:00:00\n"
     ]
    }
   ],
   "source": [
    "series = ETTh1Dataset().load()\n",
    "\n",
    "print(series.start_time())\n",
    "print(series.end_time())\n",
    "\n",
    "# series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series, test_series = series.split_before(0.6)\n",
    "val_series, test_series = test_series.split_before(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, targets, T, window_stride=1, pred_len=1):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        assert targets.size(0) == data.size(0)\n",
    "        self.T = T # time window\n",
    "        self.window_stride = window_stride\n",
    "        self.pred_len = pred_len\n",
    "        self.N, self.V = data.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(range(0, self.N - self.T - self.pred_len + 1, self.window_stride))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.window_stride\n",
    "        end = start + self.T\n",
    "\n",
    "        X = self.data[start:end]\n",
    "        # if mode == \"S\": # predict only target\n",
    "        y = self.targets[end:end + self.pred_len].flatten()\n",
    "        # elif mode == \"MS\": # predict all variables\n",
    "        #   y = self.data[end:end + self.pred_len, :7].flatten()\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(series, seq_len, window_stride=1, pred_len=1, batch_size = 512):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    train, test = series.split_before(0.6)\n",
    "    val, test = test.split_before(0.5)\n",
    "    \n",
    "    print(\"Train/Val/Test\", len(train), len(val), len(test))\n",
    "    \n",
    "    train_og = train.pd_dataframe()\n",
    "    train = scaler.fit_transform(train_og)\n",
    "    train = pd.DataFrame(train, columns=train_og.columns)\n",
    "    X_train = train\n",
    "    y_train = train[[\"OT\"]]\n",
    "    X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    indicators = torch.isfinite(X_train)\n",
    "    X_train = torch.cat([X_train, indicators], axis=1)\n",
    "    \n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train, seq_len, window_stride, pred_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_og = val.pd_dataframe()\n",
    "    val = scaler.transform(val_og)\n",
    "    val = pd.DataFrame(val, columns=val_og.columns)\n",
    "    X_val = val\n",
    "    y_val = val[[\"OT\"]]\n",
    "    X_val = torch.tensor(X_val.to_numpy(), dtype=torch.float32)\n",
    "    y_val = torch.tensor(y_val.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    indicators = torch.isfinite(X_val)\n",
    "    X_val = torch.cat([X_val, indicators], axis=1)\n",
    "    \n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val, seq_len, window_stride, pred_len)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    test_og = test.pd_dataframe()\n",
    "    test = scaler.transform(test_og)\n",
    "    test = pd.DataFrame(test, columns=test_og.columns)\n",
    "    X_test = test\n",
    "    y_test = test[[\"OT\"]]\n",
    "    X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test.to_numpy(), dtype=torch.float32)\n",
    "    \n",
    "    indicators = torch.isfinite(X_test)\n",
    "    X_test = torch.cat([X_test, indicators], axis=1)\n",
    "    \n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test, seq_len, window_stride, pred_len)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test 10451 3484 3485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10, 14])\n",
      "torch.Size([512, 24])\n",
      "Batches 21 7 7\n"
     ]
    }
   ],
   "source": [
    "seq_len = 10\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=24)\n",
    "\n",
    "for X,y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break\n",
    "\n",
    "print(\"Batches\", len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_mae_mse(history, title, dec=\"{:.3g}\"):\n",
    "    xticks = range(len(history[:, 0]))\n",
    "    plt.plot(xticks, history[:, 2], label='MAE')\n",
    "    plt.plot(xticks, history[:, 3], label='MSE')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    # plt.ylim(0, 1)\n",
    "    xtick_labels = list(map(int, history[:, 0]))\n",
    "    plt.xticks(xticks, xtick_labels)\n",
    "    plt.yscale('log')\n",
    "\n",
    "    if dec:\n",
    "        for x,_y in zip(xticks, history[:, 2]):\n",
    "            label = dec.format(_y)\n",
    "            plt.annotate(label, # this is the text\n",
    "                        (x,_y), # these are the coordinates to position the label\n",
    "                        textcoords=\"offset points\", # how to position the text\n",
    "                        xytext=(0,-10), # distance from text to points (x,y)\n",
    "                        ha='center') # horizontal alignment can be left, right or center\n",
    "            \n",
    "        for x,_y in zip(xticks, history[:, 3]):\n",
    "            label = dec.format(_y)\n",
    "            plt.annotate(label, # this is the text\n",
    "                        (x,_y), # these are the coordinates to position the label\n",
    "                        textcoords=\"offset points\", # how to position the text\n",
    "                        xytext=(0,-10), # distance from text to points (x,y)\n",
    "                        ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_prediction_vs_true(yb, preds, title):\n",
    "    plt.plot(yb, color=\"black\", label=\"True\")\n",
    "    plt.plot(preds, color=\"red\", label=\"Pred\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim, top_k=''):\n",
    "    model = models.CBM(input_dim = input_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            opt_lr = 3e-3, # 2e-4\n",
    "                            opt_weight_decay = 1e-05,\n",
    "                            l1_lambda=0.001,\n",
    "                            cos_sim_lambda=0.01,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            task_type=models.TaskType.REGRESSION,\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, output_dim, use_summaries_for_atomics, top_k=''):\n",
    "    model = models_3d_atomics_on_variate_to_concepts.CBM(input_dim = input_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics = n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            opt_lr = 3e-3, # 2e-4\n",
    "                            opt_weight_decay = 1e-05,\n",
    "                            l1_lambda=0.001,\n",
    "                            cos_sim_lambda=0.01,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            task_type=models_3d_atomics_on_variate_to_concepts.TaskType.REGRESSION,\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 336\n",
    "pred_len = 96\n",
    "n_atomics_list = list(range(2,11,2))\n",
    "n_concepts_list = list(range(2,11,2))\n",
    "changing_dim = len(series.columns)\n",
    "input_dim = 2 * changing_dim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = f\"/workdir/optimal-summaries-public/vasopressor/models/etth1/multi2single-L{seq_len}-T{pred_len}/\"\n",
    "model_path_og = experiment_folder + \"forecasting_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test 10451 3484 3485\n",
      "n_concepts 2\n",
      "test 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_path_og' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim\u001b[38;5;241m=\u001b[39mpred_len)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m.\u001b[39moutput_dim)\n\u001b[0;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_loader, val_loader, \u001b[38;5;28;01mNone\u001b[39;00m, save_model_path\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_path_og\u001b[49m\u001b[38;5;241m.\u001b[39mformat(n_concepts), max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     15\u001b[0m display(model)\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_path_og' is not defined"
     ]
    }
   ],
   "source": [
    "history_og = []\n",
    "\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "\n",
    "for n_concepts in n_concepts_list:\n",
    "    print(\"n_concepts\", n_concepts)\n",
    "    \n",
    "    model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "    model.fit(train_loader, val_loader, None, save_model_path=model_path_og.format(n_concepts), max_epochs=10000)\n",
    "    \n",
    "    display(model)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = model.forward(Xb)\n",
    "            \n",
    "            mae = mae_metric(preds, yb).item()\n",
    "            mse = mse_metric(preds, yb).item()\n",
    "        mae = mae_metric.compute().item()\n",
    "        mse = mse_metric.compute().item()\n",
    "        mae_metric.reset()\n",
    "        mse_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, round(model.val_losses[-1],2), mae, mse]\n",
    "    display(history)\n",
    "    history_og.append(np.array(history))\n",
    "    \n",
    "    plot_losses(model.train_losses, model.val_losses)\n",
    "    \n",
    "history_og = np.array(history_og)\n",
    "history_og.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae_mse(history_og, \"Original\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prediction vs actual\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "n_concepts = 10\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "model.fit(train_loader, val_loader, None, save_model_path=model_path_og.format(n_concepts), max_epochs=10000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(val_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model.forward(Xb)\n",
    "        \n",
    "        mae = mae_metric(preds, yb).item()\n",
    "        mse = mse_metric(preds, yb).item()\n",
    "        break\n",
    "    mae = mae_metric.compute().item()\n",
    "    mse = mse_metric.compute().item()\n",
    "    mae_metric.reset()\n",
    "    mse_metric.reset()\n",
    "\n",
    "\n",
    "i = 20\n",
    "yb = yb.cpu().numpy()[i]\n",
    "preds = preds.cpu().numpy()[i]\n",
    "\n",
    "print(yb.shape)\n",
    "print(preds.shape)\n",
    "\n",
    "plot_prediction_vs_true(yb, preds, title=f\"Original - Predictions with {n_concepts} Concepts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redesigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = f\"/workdir/optimal-summaries-public/vasopressor/models/etth1/atomics-from-summaries-L{seq_len}-T{pred_len}/\"\n",
    "model_path_re = experiment_folder + \"forecasting_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test 10451 3484 3485\n",
      "n_atomics 2 n_concepts 2\n",
      "test 96\n",
      "Loaded model from /workdir/optimal-summaries-public/vasopressor/models/etth1/atomics-from-summaries-L336-T96/forecasting_c2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9980 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/9980 [00:00<1:04:09,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/9980 [00:00<1:04:25,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/9980 [00:01<1:03:34,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/9980 [00:01<1:03:06,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/9980 [00:01<1:03:52,  2.60it/s]Exception ignored in: <function _releaseLock at 0x7ff256da9750>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/9980 [00:02<1:03:35,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/9980 [00:02<1:02:47,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/9980 [00:03<1:01:55,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/9980 [00:03<1:01:14,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/9980 [00:03<1:01:52,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/9980 [00:04<1:02:37,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/9980 [00:04<1:01:59,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/9980 [00:04<1:01:56,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/9980 [00:05<1:01:42,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/9980 [00:05<1:02:39,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/9980 [00:06<1:02:31,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/9980 [00:06<1:02:46,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/9980 [00:06<1:02:51,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/9980 [00:07<1:03:31,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/9980 [00:07<1:13:14,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([493, 7])\n",
      "var_feats torch.Size([493, 7])\n",
      "out torch.Size([493, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/9980 [00:08<1:09:48,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 22/9980 [00:08<1:07:12,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/9980 [00:08<1:05:31,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/9980 [00:09<1:04:37,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/9980 [00:09<1:04:20,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/9980 [00:09<1:03:04,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/9980 [00:10<1:02:40,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/9980 [00:10<1:02:39,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 29/9980 [00:11<1:03:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/9980 [00:11<1:03:09,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/9980 [00:11<1:03:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/9980 [00:12<1:03:41,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/9980 [00:12<1:03:37,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/9980 [00:13<1:03:32,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([512, 7])\n",
      "var_feats torch.Size([512, 7])\n",
      "out torch.Size([512, 96])\n",
      "mean_feats torch.Size([292, 7])\n",
      "var_feats torch.Size([292, 7])\n",
      "out torch.Size([292, 96])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/9980 [00:13<1:03:04,  2.63it/s]"
     ]
    }
   ],
   "source": [
    "history_re = []\n",
    "\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "\n",
    "for n_concepts in n_concepts_list:\n",
    "    for n_atomics in n_atomics_list:\n",
    "        print(\"n_atomics\", n_atomics, \"n_concepts\", n_concepts)\n",
    "        \n",
    "        model = initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len, use_summaries_for_atomics=True)\n",
    "        print(\"test\", model.output_dim)\n",
    "        model.fit(train_loader, val_loader, None, save_model_path=model_path_re.format(n_concepts), max_epochs=10000)\n",
    "        \n",
    "        print(\"Trained for \", model.curr_epoch+1)\n",
    "        display(model)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                preds = model.forward(Xb)\n",
    "                \n",
    "                mae = mae_metric(preds, yb).item()\n",
    "                mse = mse_metric(preds, yb).item()\n",
    "            mae = mae_metric.compute().item()\n",
    "            mse = mse_metric.compute().item()\n",
    "            mae_metric.reset()\n",
    "            mse_metric.reset()\n",
    "        \n",
    "        history = [n_atomics, n_concepts, round(model.val_losses[-1],2), mae, mse]\n",
    "        display(history)\n",
    "        history_re.append(np.array(history))\n",
    "    \n",
    "        plot_losses(model.train_losses, model.val_losses)\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "history_re = np.array(history_re)\n",
    "history_re.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae_mse(history_re, \"Redesigned\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prediction vs actual\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "n_concepts = 600\n",
    "\n",
    "model = initializeModel_redesigned(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "model.fit(train_loader, val_loader, None, save_model_path=model_path_re.format(n_concepts), max_epochs=10000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(val_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model.forward(Xb)\n",
    "        \n",
    "        mae = mae_metric(preds, yb).item()\n",
    "        mse = mse_metric(preds, yb).item()\n",
    "        break\n",
    "    mae = mae_metric.compute().item()\n",
    "    mse = mse_metric.compute().item()\n",
    "    mae_metric.reset()\n",
    "    mse_metric.reset()\n",
    "\n",
    "\n",
    "i = 20\n",
    "yb = yb.cpu().numpy()[i]\n",
    "preds = preds.cpu().numpy()[i]\n",
    "\n",
    "print(yb.shape)\n",
    "print(preds.shape)\n",
    "\n",
    "plot_prediction_vs_true(yb, preds, title=f\"Redesigned - Predictions with {n_concepts} Concepts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redesigned + LambdaLR as paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = f\"/workdir/optimal-summaries-public/vasopressor/models/etth1/time2con-lambdalr-multi2single-L{seq_len}-T{pred_len}/\"\n",
    "model_path_re_lamdalr = experiment_folder + \"forecasting_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_re_lambdalr = []\n",
    "\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "\n",
    "for n_concepts in n_concepts_list:\n",
    "    print(\"n_concepts\", n_concepts)\n",
    "    \n",
    "    model = initializeModel_redesigned(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=model.optimizer, patience=5)\n",
    "    lr_lambda = lambda epoch: 0.5 ** ((epoch - 1) // 1)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=model.optimizer, lr_lambda=lr_lambda)\n",
    "    model.fit(train_loader, val_loader, None, save_model_path=model_path_re_lamdalr.format(n_concepts), max_epochs=10000, scheduler=scheduler)\n",
    "    \n",
    "    display(model)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = model.forward(Xb)\n",
    "            \n",
    "            mae = mae_metric(preds, yb).item()\n",
    "            mse = mse_metric(preds, yb).item()\n",
    "        mae = mae_metric.compute().item()\n",
    "        mse = mse_metric.compute().item()\n",
    "        mae_metric.reset()\n",
    "        mse_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, round(model.val_losses[-1],2), mae, mse]\n",
    "    display(history)\n",
    "    history_re_lambdalr.append(np.array(history))\n",
    "    \n",
    "    plot_losses(model.train_losses, model.val_losses)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "history_re_lambdalr = np.array(history_re_lambdalr)\n",
    "history_re_lambdalr.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae_mse(history_re_lambdalr, \"Redesigned + LambdaLR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prediction vs actual\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel_redesigned(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "# model.fit(train_loader, val_loader, None, save_model_path=model_path_re_lamdalr.format(n_concepts), max_epochs=10000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(val_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model.forward(Xb)\n",
    "        \n",
    "        mae = mae_metric(preds, yb).item()\n",
    "        mse = mse_metric(preds, yb).item()\n",
    "        break\n",
    "    mae = mae_metric.compute().item()\n",
    "    mse = mse_metric.compute().item()\n",
    "    mae_metric.reset()\n",
    "    mse_metric.reset()\n",
    "\n",
    "\n",
    "i = 20\n",
    "yb = yb.cpu().numpy()[i]\n",
    "preds = preds.cpu().numpy()[i]\n",
    "\n",
    "print(yb.shape)\n",
    "print(preds.shape)\n",
    "\n",
    "plot_prediction_vs_true(yb, preds, title=f\"Redesigned + LambdaLR - Predictions with {n_concepts} Concepts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redesigned + ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = f\"/workdir/optimal-summaries-public/vasopressor/models/etth1/time2con-reduceonplateau-multi2single-L{seq_len}-T{pred_len}/\"\n",
    "model_path_re_reduceonplateau = experiment_folder + \"forecasting_c{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_re_reduceonplateau = []\n",
    "\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "\n",
    "for n_concepts in n_concepts_list:\n",
    "    print(\"n_concepts\", n_concepts)\n",
    "    \n",
    "    model = initializeModel_redesigned(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=model.optimizer, patience=5) # half patience of early stopping\n",
    "    model.fit(train_loader, val_loader, None, save_model_path=model_path_re_reduceonplateau.format(n_concepts), max_epochs=10000, scheduler=scheduler)\n",
    "    \n",
    "    display(model)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            preds = model.forward(Xb)\n",
    "            \n",
    "            mae = mae_metric(preds, yb).item()\n",
    "            mse = mse_metric(preds, yb).item()\n",
    "        mae = mae_metric.compute().item()\n",
    "        mse = mse_metric.compute().item()\n",
    "        mae_metric.reset()\n",
    "        mse_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, round(model.val_losses[-1],2), mae, mse]\n",
    "    display(history)\n",
    "    history_re_reduceonplateau.append(np.array(history))\n",
    "    \n",
    "    plot_losses(model.train_losses, model.val_losses)\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "history_re_reduceonplateau = np.array(history_re_reduceonplateau)\n",
    "history_re_reduceonplateau.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mae_mse(history_re_reduceonplateau, \"Redesigned + ReduceLROnPlateau\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Prediction vs actual\n",
    "train_loader, val_loader, test_loader, scaler = preprocess_data(series, seq_len, pred_len=pred_len)\n",
    "\n",
    "mae_metric = MeanAbsoluteError().to(device)\n",
    "mse_metric = MeanSquaredError().to(device)\n",
    "n_concepts = 10\n",
    "\n",
    "model = initializeModel_redesigned(n_concepts, input_dim, changing_dim, seq_len, output_dim=pred_len)\n",
    "# model.fit(train_loader, val_loader, None, save_model_path=model_path_re_reduceonplateau.format(n_concepts), max_epochs=10000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(val_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        preds = model.forward(Xb)\n",
    "        \n",
    "        mae = mae_metric(preds, yb).item()\n",
    "        mse = mse_metric(preds, yb).item()\n",
    "        break\n",
    "    mae = mae_metric.compute().item()\n",
    "    mse = mse_metric.compute().item()\n",
    "    mae_metric.reset()\n",
    "    mse_metric.reset()\n",
    "\n",
    "\n",
    "i = 20\n",
    "yb = yb.cpu().numpy()[i]\n",
    "preds = preds.cpu().numpy()[i]\n",
    "\n",
    "print(yb.shape)\n",
    "print(preds.shape)\n",
    "\n",
    "plot_prediction_vs_true(yb, preds, title=f\"Redesigned + ReduceLROnPlateau - Predictions with {n_concepts} Concepts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 5\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len)\n",
    "model.fit(train_loader, val_loader, None, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aucs, best_auc_inds, best_auc_concepts = greedy_selection(auroc_metric, test_loader, top_k_inds, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow([\"Best AUC\", \"Best AUC Concept #\", \"Best AUC ind #\"])\n",
    "    # writing the data rows \n",
    "    for row in zip(best_aucs, best_auc_concepts, best_auc_inds):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/vasopressor/models/arabic/multiclass/\"\n",
    "model_path = experiment_folder + \"arabic_c{}.pt\"\n",
    "random_seed = 1\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_multiclass = []\n",
    "\n",
    "set_seed(random_seed)\n",
    "\n",
    "data, y_ohe, num_classes, weights = preprocess_data_multiclass(X, y)\n",
    "train_loader, val_loader, test_loader = initialize_data(1, data, y_ohe, multiclass=True)\n",
    "\n",
    "input_dim = data.shape[2]\n",
    "changing_dim = X[0].shape[0]\n",
    "seq_len = data.shape[1]\n",
    "\n",
    "auroc_metric = AUROC(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "accuracy_metric = Accuracy(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "for n_concepts in range(1,16):\n",
    "    print(n_concepts)\n",
    "    \n",
    "    model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "    model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "    \n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, model.val_losses[-1], auc, acc]\n",
    "    history_multiclass.append(np.array(history))\n",
    "history_multiclass = np.array(history_multiclass)\n",
    "history_multiclass.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.plot(history_multiclass[:, 0], history_multiclass[:, 2], label='AUC')\n",
    "plt.plot(history_multiclass[:, 0], history_multiclass[:, 3], label='ACC')\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "plt.xticks(np.arange(min(history_multiclass[:, 0]), max(history_multiclass[:, 0])+1, 1))\n",
    "\n",
    "for x,_y in zip(history_multiclass[:, 0], history_multiclass[:, 2]):\n",
    "    label = \"{:.2f}\".format(_y)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,_y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    \n",
    "for x,_y in zip(history_multiclass[:, 0], history_multiclass[:, 3]):\n",
    "    label = \"{:.2f}\".format(_y)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,_y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,-10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 5\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = [i for i in range(1,14)] + [str(i) + \"_ind\" for i in range(1,14)]\n",
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = [i for i in range(1,14)] + [str(i) + \"_ind\" for i in range(1,14)]\n",
    "\n",
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"])\n",
    "plt.plot(greedy_results[\"acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/vasopressor/models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, weights, save_model_path=\"/workdir/optimal-summaries-public/vasopressor/models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", epochs=3000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
