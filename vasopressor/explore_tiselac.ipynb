{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from aeon.datasets import load_classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy, MulticlassConfusionMatrix, MulticlassF1Score\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from models import LogisticRegressionWithSummariesAndBottleneck_Wrapper\n",
    "from preprocess_helpers import *\n",
    "from helper import *\n",
    "from param_initializations import *\n",
    "from optimization_strategy import greedy_selection\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape of X =  (99687, 10, 23) <class 'numpy.ndarray'> float64\n",
      " Shape of y =  (99687,) <class 'numpy.ndarray'> <U1\n",
      " Meta data =  {'problemname': 'tiselac', 'timestamps': False, 'missing': False, 'univariate': False, 'equallength': True, 'classlabel': True, 'targetlabel': False, 'class_values': ['1', '2', '3', '4', '5', '6', '7', '8', '9']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6, 1, 6, ..., 3, 4, 5])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y, meta_data = load_classification(\"Tiselac\", extract_path=\"/workdir/data\")\n",
    "print(\" Shape of X = \", X.shape, type(X), X.dtype)\n",
    "print(\" Shape of y = \", y.shape, type(y), y.dtype)\n",
    "print(\" Meta data = \", meta_data)\n",
    "y = y.astype(int)\n",
    "display(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ad2072410>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAEDCAYAAABptE1mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUwklEQVR4nO3df2xV9f3H8de9l/a2sNsrBftrFKhOh/zcxo+Oke27fWn4ESSymQUXlnSd8bvorQybuck3gY74o0MX0+gITpMpyxcQTb7MzWQspoMaIwiWbRmJqeCIFGuputligUu59/P9A73fVSnllvfp6Wmfj+Qk9vSc93nbz/2U1z339JyQc84JAADAQNjvBgAAwMhBsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMECwAAICZMUN9wHQ6rfb2dsViMYVCoaE+PAAAGATnnE6fPq2ysjKFw/2flxjyYNHe3q7y8vKhPiwAADDQ1tamSZMm9fv9IQ8WsVhMkjR9zQZFcvOG+vAYJpxHH8K5sP1ZsFDam7veh7y6mb4XdTm56A2PXgOevbbS9iU96xXmUufP6ciu+zP/jvdnyIPFJx9/RHLzCBajGMGCYAERLESwCKKBLmPg4k0AAGCGYAEAAMwQLAAAgJlBBYstW7Zo6tSpysvLU2VlpQ4ePGjdFwAACKCsg8WuXbtUV1en+vp6HT58WHPmzNHSpUvV2dnpRX8AACBAsg4Wjz76qO644w7V1NRo+vTpeuKJJzR27Fj95je/8aI/AAAQIFkFi/Pnz6ulpUVVVVX/XyAcVlVVlfbv33/JfZLJpLq7u/ssAABgZMoqWLz//vtKpVIqLi7us764uFgdHR2X3KehoUHxeDyzcNdNAABGLs//KmT9+vXq6urKLG1tbV4fEgAA+CSrO29OnDhRkUhEp06d6rP+1KlTKikpueQ+0WhU0Wh08B0CAIDAyOqMRW5urubOnaumpqbMunQ6raamJi1cuNC8OQAAECxZPyukrq5O1dXVmjdvnhYsWKDGxkb19PSopqbGi/4AAECAZB0sVq9erffee08bN25UR0eHvvSlL2nPnj2fuaATAACMPoN6umltba1qa2utewEAAAHHs0IAAIAZggUAADBDsAAAAGYIFgAAwMygLt4ERpWQN2WdN2W9atcTLkjNetBrKG1fU/LwteXBW1Hn0c8A9q50vnLGAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMjPHrwC58ccHolM4JeVI3FbWvGUp702vIeVJWzpt2g8Oj/38vfq6htH1NL+vKg9esZ73CXCpyZZOAf9oBAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAM1kFi4aGBs2fP1+xWExFRUVatWqVWltbveoNAAAETFbBorm5WYlEQgcOHNBLL72k3t5eLVmyRD09PV71BwAAAiSrG2Tt2bOnz9fPPPOMioqK1NLSom984xumjQEAgOC5qmssurq6JEmFhYUmzQAAgGAb9C290+m01q1bp0WLFmnmzJn9bpdMJpVMJjNfd3d3D/aQAABgmBv0GYtEIqEjR47o2Wefvex2DQ0NisfjmaW8vHywhwQAAMPcoIJFbW2tXnzxRe3du1eTJk267Lbr169XV1dXZmlraxtUowAAYPjL6qMQ55zuvvtu7d69W/v27VNFRcWA+0SjUUWjHjxyEgAADDtZBYtEIqEdO3bohRdeUCwWU0dHhyQpHo8rPz/fkwYBAEBwZPVRyNatW9XV1aVvfvObKi0tzSy7du3yqj8AABAgWX8UAgAA0B+eFQIAAMwQLAAAgBmCBQAAMEOwAAAAZgZ9S++rFvp4wagUSntTN5IceJtsedWrgnQttFdz1YO6zqO3S57U9eg14NVrNuRFv0GaB6PclY4/ZywAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwMwYvw6cyg1J0ZBfh4fPTlekPakbn/qhec0xEW96HRNJeVI36kHdtPNmrvam7d/bpDyoebGu/c8g7VWvHo2XF/06Z14SHkmdSUpPDrwdZywAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABg5qqCxS9+8QuFQiGtW7fOqB0AABBkgw4Whw4d0q9//WvNnj3bsh8AABBggwoWH330kdasWaOnnnpK48ePt+4JAAAE1KCCRSKR0IoVK1RVVTXgtslkUt3d3X0WAAAwMmX9rJBnn31Whw8f1qFDh65o+4aGBm3atCnrxgAAQPBkdcaira1NP/7xj7V9+3bl5eVd0T7r169XV1dXZmlraxtUowAAYPjL6oxFS0uLOjs79ZWvfCWzLpVK6eWXX9avfvUrJZNJRSKRPvtEo1FFo1GbbgEAwLCWVbBYvHix/v73v/dZV1NTo2nTpulnP/vZZ0IFAAAYXbIKFrFYTDNnzuyzbty4cZowYcJn1gMAgNGHO28CAAAzWf9VyKft27fPoA0AADAScMYCAACYIVgAAAAzBAsAAGDmqq+xGKx0jhTK8evo8Fv0n95k2o/OBejZNSFvyjoP6oacfU1JcmH7ws6rt0se1PVirCR5N2Be8OpnAHPps1cWGThjAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJghWAAAADMECwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMDMGN8OfFaKpPw6OvwW7vWm7pgzIW8Kj3Ye/VhdyL6w8+rtEi8tOX4Go1oqGbmi7ThjAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMAMwQIAAJjJOli88847+v73v68JEyYoPz9fs2bN0uuvv+5FbwAAIGCyuo/Fv/71Ly1atEjf+ta39Mc//lHXXnutjh49qvHjx3vVHwAACJCsgsXmzZtVXl6up59+OrOuoqLCvCkAABBMWX0U8vvf/17z5s3Td7/7XRUVFenLX/6ynnrqqcvuk0wm1d3d3WcBAAAjU1bB4h//+Ie2bt2qG264QX/605905513au3atdq2bVu/+zQ0NCgej2eW8vLyq24aAAAMTyHnnLvSjXNzczVv3jy9+uqrmXVr167VoUOHtH///kvuk0wmlUwmM193d3ervLxcM/7rIUVy866idQRZOidYdUc9z54V4kFNnhXiGZ4VMrqlkud07JH/VldXlwoKCvrdLqspWFpaqunTp/dZd9NNN+nEiRP97hONRlVQUNBnAQAAI1NWwWLRokVqbW3ts+7NN9/UlClTTJsCAADBlFWwuOeee3TgwAE99NBDOnbsmHbs2KEnn3xSiUTCq/4AAECAZBUs5s+fr927d2vnzp2aOXOm7r//fjU2NmrNmjVe9QcAAAIkq/tYSNLNN9+sm2++2YteAABAwPGsEAAAYIZgAQAAzBAsAACAmayvsbDSNbNX4fyIX4eHzx74j//1pO78vP7vqTJYhR7F71g415O60ZD9XcKSrte8piT9M5UceKMsvZf25tfae6lx5jXHhc6b15SksWFvxmtc6IJ5zViYu24FxenTad34yMDbccYCAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgJkxfh0472SOItEcvw4Pn21f9Z+e1P2ft98xr+l6L5jXlCSXSnlSV2mP6nogPHasec1Qfp55zYt18+2L5njzK9iNiXhS14t+XY5HvcLchVRS0sMDbscZCwAAYIZgAQAAzBAsAACAGYIFAAAwQ7AAAABmCBYAAMBMVsEilUppw4YNqqioUH5+vq6//nrdf//9cs551R8AAAiQrP4oefPmzdq6dau2bdumGTNm6PXXX1dNTY3i8bjWrl3rVY8AACAgsgoWr776qm655RatWLFCkjR16lTt3LlTBw8e9KQ5AAAQLFl9FPK1r31NTU1NevPNNyVJf/vb3/TKK69o+fLl/e6TTCbV3d3dZwEAACNTVmcs7rvvPnV3d2vatGmKRCJKpVJ68MEHtWbNmn73aWho0KZNm666UQAAMPxldcbiueee0/bt27Vjxw4dPnxY27Zt0y9/+Utt27at333Wr1+vrq6uzNLW1nbVTQMAgOEpqzMW9957r+677z7ddtttkqRZs2bp7bffVkNDg6qrqy+5TzQaVTQavfpOAQDAsJfVGYszZ84oHO67SyQSUTqdNm0KAAAEU1ZnLFauXKkHH3xQkydP1owZM/SXv/xFjz76qH74wx961R8AAAiQrILF448/rg0bNuiuu+5SZ2enysrK9KMf/UgbN270qj8AABAgWQWLWCymxsZGNTY2etQOAAAIMp4VAgAAzBAsAACAGYIFAAAwk9U1FpZcWHIRv44Ov71xb9yTujdV9JjXzAl78+fUueELntTNi9jXveCC8x4k7UKe1A2HzprXPJ/y5pdg2qPx8uJ14NV4wV6oJymtGHi74Py2AAAAwx7BAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABghmABAADMECwAAIAZggUAADBDsAAAAGYIFgAAwAzBAgAAmCFYAAAAMwQLAABgZsxQH9A5J0lKJ88N9aExjKTPnvek7oWepHlNF3bmNSUpFL7gSd1IxL7uBRec9yBpF/Kkbjhk/zroTUXMa0pS2qPx8uJ14LyZXvDAhTMXf2+7AQYt5AbawtjJkydVXl4+lIcEAABG2traNGnSpH6/P+TBIp1Oq729XbFYTKFQ/+8suru7VV5erra2NhUUFAxhhxgMxitYGK9gYbyCZaSOl3NOp0+fVllZmcLh/s9eDflHIeFw+LJJ59MKCgpG1MCMdIxXsDBewcJ4BctIHK94PD7gNsH54BQAAAx7BAsAAGBm2AaLaDSq+vp6RaNRv1vBFWC8goXxChbGK1hG+3gN+cWbAABg5Bq2ZywAAEDwECwAAIAZggUAADBDsAAAAGaGbbDYsmWLpk6dqry8PFVWVurgwYN+t4RL+PnPf65QKNRnmTZtmt9t4WMvv/yyVq5cqbKyMoVCIf3ud7/r833nnDZu3KjS0lLl5+erqqpKR48e9adZDDheP/jBDz4z35YtW+ZPs6NcQ0OD5s+fr1gspqKiIq1atUqtra19tjl37pwSiYQmTJigz33uc7r11lt16tQpnzoeOsMyWOzatUt1dXWqr6/X4cOHNWfOHC1dulSdnZ1+t4ZLmDFjht59993M8sorr/jdEj7W09OjOXPmaMuWLZf8/sMPP6zHHntMTzzxhF577TWNGzdOS5cu1blzPCTQDwONlyQtW7asz3zbuXPnEHaITzQ3NyuRSOjAgQN66aWX1NvbqyVLlqinpyezzT333KM//OEPev7559Xc3Kz29nZ95zvf8bHrIeKGoQULFrhEIpH5OpVKubKyMtfQ0OBjV7iU+vp6N2fOHL/bwBWQ5Hbv3p35Op1Ou5KSEvfII49k1n344YcuGo26nTt3+tAh/t2nx8s556qrq90tt9ziSz+4vM7OTifJNTc3O+cuzqWcnBz3/PPPZ7Z54403nCS3f/9+v9ocEsPujMX58+fV0tKiqqqqzLpwOKyqqirt37/fx87Qn6NHj6qsrEzXXXed1qxZoxMnTvjdEq7A8ePH1dHR0WeuxeNxVVZWMteGsX379qmoqEhf/OIXdeedd+qDDz7wuyVI6urqkiQVFhZKklpaWtTb29tnfk2bNk2TJ08e8fNr2AWL999/X6lUSsXFxX3WFxcXq6Ojw6eu0J/Kyko988wz2rNnj7Zu3arjx4/r61//uk6fPu13axjAJ/OJuRYcy5Yt029/+1s1NTVp8+bNam5u1vLly5VKpfxubVRLp9Nat26dFi1apJkzZ0q6OL9yc3N1zTXX9Nl2NMyvIX+6KUaW5cuXZ/579uzZqqys1JQpU/Tcc8/p9ttv97EzYOS57bbbMv89a9YszZ49W9dff7327dunxYsX+9jZ6JZIJHTkyBGuL/vYsDtjMXHiREUikc9cOXvq1CmVlJT41BWu1DXXXKMbb7xRx44d87sVDOCT+cRcC67rrrtOEydOZL75qLa2Vi+++KL27t2rSZMmZdaXlJTo/Pnz+vDDD/tsPxrm17ALFrm5uZo7d66ampoy69LptJqamrRw4UIfO8OV+Oijj/TWW2+ptLTU71YwgIqKCpWUlPSZa93d3XrttdeYawFx8uRJffDBB8w3HzjnVFtbq927d+vPf/6zKioq+nx/7ty5ysnJ6TO/WltbdeLEiRE/v4blRyF1dXWqrq7WvHnztGDBAjU2Nqqnp0c1NTV+t4ZP+clPfqKVK1dqypQpam9vV319vSKRiL73ve/53Rp0Mej9+7vZ48eP669//asKCws1efJkrVu3Tg888IBuuOEGVVRUaMOGDSorK9OqVav8a3oUu9x4FRYWatOmTbr11ltVUlKit956Sz/96U/1hS98QUuXLvWx69EpkUhox44deuGFFxSLxTLXTcTjceXn5ysej+v2229XXV2dCgsLVVBQoLvvvlsLFy7UV7/6VZ+795jff5bSn8cff9xNnjzZ5ebmugULFrgDBw743RIuYfXq1a60tNTl5ua6z3/+82716tXu2LFjfreFj+3du9dJ+sxSXV3tnLv4J6cbNmxwxcXFLhqNusWLF7vW1lZ/mx7FLjdeZ86ccUuWLHHXXnuty8nJcVOmTHF33HGH6+jo8LvtUelS4yTJPf3005ltzp496+666y43fvx4N3bsWPftb3/bvfvuu/41PUR4bDoAADAz7K6xAAAAwUWwAAAAZggWAADADMECAACYIVgAAAAzBAsAAGCGYAEAAMwQLAAAgBmCBQAAMEOwAAAAZggWAADADMECAACY+T/MoOC6ZKFSigAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(_X, _y, batch_size = 4096, random_state = 1, scaler = StandardScaler()):\n",
    "    # swap T and V axis\n",
    "    _X = _X.swapaxes(1,2)\n",
    "    \n",
    "    ## target\n",
    "    y_unique = np.unique(_y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    # class weights\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=y_unique, y=_y)\n",
    "    weights = torch.Tensor(weights).to(device)\n",
    "    \n",
    "    # split 60/20/20 %\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, _y, test_size = 0.40, random_state = random_state, stratify = _y)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "    # normalize\n",
    "    X_train, X_val, X_test = normalize_across_time(X_train, X_val, X_test)\n",
    "\n",
    "    # tensor\n",
    "    X_train_pt = torch.tensor(X_train)\n",
    "    X_train_pt = add_indicators(X_train_pt)\n",
    "    y_train_pt = torch.tensor(y_train)\n",
    "\n",
    "    X_val_pt = torch.tensor(X_val)\n",
    "    X_val_pt = add_indicators(X_val_pt)\n",
    "    y_val_pt = torch.tensor(y_val)\n",
    "\n",
    "    X_test_pt = torch.tensor(X_test)\n",
    "    X_test_pt = add_indicators(X_test_pt)\n",
    "    y_test_pt = torch.tensor(y_test)\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = TensorDataset(X_train_pt, y_train_pt)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val_pt, y_val_pt)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = X_val_pt.shape[0], shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_pt, y_test_pt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = X_test_pt.shape[0], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, weights, num_classes\n",
    "\n",
    "\n",
    "def add_indicators(data: torch.Tensor):\n",
    "    indicators_3d = ~torch.isnan(data)\n",
    "    data = torch.cat([data, indicators_3d], axis=-1) # (N x time_len x 2*changing_dim)\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_across_time(X_train, X_val, X_test):\n",
    "    \n",
    "    scalerX=StandardScaler(with_std=False)\n",
    "    n_variables = 10\n",
    "    \n",
    "    # N x T x V => N*T x V\n",
    "    X_train_reshaped = X_train.reshape(-1, n_variables)\n",
    "    X_val_reshaped = X_val.reshape(-1, n_variables)\n",
    "    X_test_reshaped = X_test.reshape(-1, n_variables)\n",
    "\n",
    "    nX_train = scalerX.fit_transform(X_train_reshaped)\n",
    "    nX_val = scalerX.transform(X_val_reshaped)\n",
    "    nX_test = scalerX.transform(X_test_reshaped)\n",
    "    \n",
    "    # revert shape\n",
    "    nX_train = nX_train.reshape(X_train.shape)\n",
    "    nX_val = nX_val.reshape(X_val.shape)\n",
    "    nX_test = nX_test.reshape(X_test.shape)\n",
    "    \n",
    "    return nX_train, nX_val, nX_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 23, 20])\n",
      "torch.Size([4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, weights, num_classes = preprocess_data(X,y)\n",
    "\n",
    "for a,b in train_loader:\n",
    "    print(a.shape)\n",
    "    print(b.shape)\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, input_dim, changing_dim, time_len, output_dim, top_k=''):\n",
    "    model = LogisticRegressionWithSummariesAndBottleneck_Wrapper(input_dim = input_dim, \n",
    "                                                changing_dim = changing_dim, \n",
    "                                                time_len = time_len,\n",
    "                                                num_concepts = n_concepts,\n",
    "                                                opt_lr = 2e-4,\n",
    "                                                opt_weight_decay = 2e-05,\n",
    "                                                l1_lambda=0.001,\n",
    "                                                cos_sim_lambda=0.01,\n",
    "                                                output_dim = output_dim,\n",
    "                                                top_k=top_k,\n",
    "                                                )\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/vasopressor/models/tiselac/normal/\"\n",
    "model_path = experiment_folder + \"tiselac_c{}.pt\"\n",
    "random_seed = 1\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]/opt/conda/conda-bld/pytorch_1670525552843/work/aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes torch.Size([4096]) torch.Size([4096, 9])\n",
      "sample 0  tensor(4, device='cuda:0') tensor([ 0.1529,  0.3920,  1.3884,  0.5646, -0.9110,  0.4074,  0.8294,  0.1987,\n",
      "         0.7666], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "task, l1, cossim:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666f63757365645f6e6f72746863757474227d@ssh-remote%2B192.168.94.2/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(n_concepts)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666f63757365645f6e6f72746863757474227d@ssh-remote%2B192.168.94.2/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m model \u001b[39m=\u001b[39m initializeModel(n_concepts, input_dim, changing_dim, time_len, num_classes)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666f63757365645f6e6f72746863757474227d@ssh-remote%2B192.168.94.2/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_loader, val_loader, weights, model_path\u001b[39m.\u001b[39;49mformat(n_concepts), \u001b[39m10000\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666f63757365645f6e6f72746863757474227d@ssh-remote%2B192.168.94.2/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f666f63757365645f6e6f72746863757474227d@ssh-remote%2B192.168.94.2/workdir/optimal-summaries-public/vasopressor/explore_tiselac.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m/workdir/optimal-summaries-public/vasopressor/models.py:1166\u001b[0m, in \u001b[0;36mLogisticRegressionWithSummariesAndBottleneck_Wrapper.fit\u001b[0;34m(self, train_loader, val_loader, p_weight, save_model_path, max_epochs, save_every_n_epochs, patience, trial)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m   1164\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(Xb)\n\u001b[0;32m-> 1166\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_loss(yb, y_pred, p_weight)\n\u001b[1;32m   1168\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m   1170\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss \u001b[39m*\u001b[39m Xb\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/workdir/optimal-summaries-public/vasopressor/models.py:1251\u001b[0m, in \u001b[0;36mLogisticRegressionWithSummariesAndBottleneck_Wrapper.compute_loss\u001b[0;34m(self, yb, y_pred, p_weight)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     cos_sim \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mabs(cosine_similarity(weights[:, \u001b[39m0\u001b[39m], weights[:, \u001b[39m1\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\u001b[39m.\u001b[39msum()\n\u001b[1;32m   1249\u001b[0m     cos_sim_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcos_sim_lambda \u001b[39m*\u001b[39m cos_sim\n\u001b[0;32m-> 1251\u001b[0m \u001b[39mprint\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mtask, l1, cossim: \u001b[39;49m\u001b[39m\"\u001b[39;49m, task_loss, l1_loss, cos_sim_loss)\n\u001b[1;32m   1252\u001b[0m \u001b[39mreturn\u001b[39;00m task_loss \u001b[39m+\u001b[39m l1_loss \u001b[39m+\u001b[39m cos_sim_loss\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:427\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    424\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:637\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    636\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:568\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    567\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 568\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    570\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    571\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:328\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    325\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    329\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmasked_select(\n\u001b[1;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39misfinite(tensor_view) \u001b[39m&\u001b[39m tensor_view\u001b[39m.\u001b[39mne(\u001b[39m0\u001b[39m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "history_multiclass = []\n",
    "\n",
    "set_seed(random_seed)\n",
    "\n",
    "train_loader, val_loader, test_loader, weights, num_classes = preprocess_data(X,y)\n",
    "\n",
    "changing_dim = X.shape[1]\n",
    "input_dim = 2 * changing_dim\n",
    "time_len = X.shape[2]\n",
    "\n",
    "auroc_metric = MulticlassAUROC(num_classes=num_classes).to(device)\n",
    "accuracy_metric = MulticlassAccuracy(num_classes=num_classes).to(device)\n",
    "f1_metric = MulticlassF1Score(num_classes=num_classes).to(device)\n",
    "conf_matrix = MulticlassConfusionMatrix(num_classes=num_classes).to(device)\n",
    "\n",
    "for n_concepts in range(1,11):\n",
    "    print(n_concepts)\n",
    "    \n",
    "    model = initializeModel(n_concepts, input_dim, changing_dim, time_len, num_classes)\n",
    "    model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            probs = model.forward_probabilities(Xb)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [n_concepts, model.val_losses[-1], auc, acc, f1]\n",
    "    history_multiclass.append(np.array(history))\n",
    "    \n",
    "    plot_losses(model.train_losses, model.val_losses)\n",
    "    \n",
    "history_multiclass = np.array(history_multiclass)\n",
    "history_multiclass.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.plot(history_multiclass[:, 0], history_multiclass[:, 2], label='AUC')\n",
    "plt.plot(history_multiclass[:, 0], history_multiclass[:, 3], label='ACC')\n",
    "plt.plot(history_multiclass[:, 0], history_multiclass[:, 4], label='F1')\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "plt.xticks(np.arange(min(history_multiclass[:, 0]), max(history_multiclass[:, 0])+1, 1))\n",
    "\n",
    "for x,_y in zip(history_multiclass[:, 0], history_multiclass[:, 2]):\n",
    "    label = \"{:.2f}\".format(_y)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,_y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    \n",
    "for x,_y in zip(history_multiclass[:, 0], history_multiclass[:, 3]):\n",
    "    label = \"{:.2f}\".format(_y)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,_y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,-10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "    \n",
    "for x,_y in zip(history_multiclass[:, 0], history_multiclass[:, 4]):\n",
    "    label = \"{:.2f}\".format(_y)\n",
    "    plt.annotate(label, # this is the text\n",
    "                 (x,_y), # these are the coordinates to position the label\n",
    "                 textcoords=\"offset points\", # how to position the text\n",
    "                 xytext=(0,-10), # distance from text to points (x,y)\n",
    "                 ha='center') # horizontal alignment can be left, right or center\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, time_len, num_classes)\n",
    "model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = time_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/vasopressor/models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, time_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, weights, save_model_path=\"/workdir/optimal-summaries-public/vasopressor/models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
