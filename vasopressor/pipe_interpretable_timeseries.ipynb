{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "# import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_REPO = '/n/dtak/mimic-pipeline-tools/'\n",
    "\n",
    "sys.path.append(PATH_TO_REPO+'mimic-iii-v1-4/extract-scripts')\n",
    "from data_load_utils import load_labs_and_vitals,convert_1inds_to_everinds,convert_1inds_to_kinds\n",
    "\n",
    "PATH_TO_QUERY_DATA = PATH_TO_REPO+\"mimic-iii-v1-4/query-data/\"\n",
    "PATH_TO_CLEANED_DATA = \"/n/home07/carissawu/intervention-onset/model-data/\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "\n",
    "###########\n",
    "#params for dataset construction; make same as UT\n",
    "\n",
    "LOS_LOWER_THRESH = 6 #exclude if LOS is shorter than this many hours\n",
    "LOS_UPPER_THRESH = 400 #exclude if LOS is longer than this many hours\n",
    "\n",
    "CONTROL_ENDTIME_UPPERQUANT = 0.9 #quantile for upper end of when we'll choose control time per enc; -1=use all, no cut\n",
    "DISC_GRID_SIZE = 1.0 #number of hours of separation in grid\n",
    "INTERVENTION_TYPE = 'vasopressor' #for now just vasopressor, later other types, too...\n",
    "\n",
    "#NOTE: THIS PARAM IS REALLY, REALLY IMPT! DEFINITELY PLOT *WHEN* THE FIRST TIME \n",
    "# EACH INTERVENTION IS GIVEN TO DECIDE WHAT TO SET THIS!!\n",
    "INTERV_START_THRESH = 6\n",
    "\n",
    "SEED = 8675309\n",
    "np.random.seed(SEED)\n",
    "\n",
    "START_TIME = 0 #start time series here...\n",
    "\n",
    "##########\n",
    "########## load in the baseline/static data for the cohort\n",
    "##########\n",
    "\n",
    "cohort_dat = pd.read_csv(PATH_TO_QUERY_DATA+'cohort.csv')\n",
    "og_row_num = cohort_dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do any additional filtering beyond cohort construction, if desired...\n",
    "\n",
    "cohort_dat = cohort_dat.loc[cohort_dat['LOS'] >= LOS_LOWER_THRESH,:]\n",
    "cohort_dat = cohort_dat.loc[cohort_dat['LOS'] <=  LOS_UPPER_THRESH,:]\n",
    "\n",
    "cohort_dat['INTIME'] = pd.to_datetime(cohort_dat['INTIME'])\n",
    "\n",
    "print('cohort loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_row_num = cohort_dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21583"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_row_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20969"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9715516841958949"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_row_num / og_row_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10497\n",
       "1      743\n",
       "Name: HOSPITAL_EXPIRE_FLAG, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort_dat['HOSPITAL_EXPIRE_FLAG'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# does HOSPITAL_EXPIRE_FLAG equal 1 when they die, or if they die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_ind = cohort_dat.index[cohort_dat['HOSPITAL_EXPIRE_FLAG'] == 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ICUSTAY_ID           STARTTIME\n",
      "0         200024 2127-03-03 16:15:00\n",
      "1         200028 2133-10-29 17:47:00\n",
      "2         200033 2198-08-10 18:30:00\n",
      "3         200034 2186-01-21 12:38:00\n",
      "4         200063 2141-03-21 11:00:00\n",
      "5         200075 2159-09-23 01:40:00\n",
      "6         200087 2196-08-31 08:14:00\n",
      "7         200095 2113-10-30 23:30:00\n",
      "8         200116 2198-03-19 22:23:00\n",
      "9         200131 2176-10-30 13:37:00\n",
      "10        200141 2143-10-15 14:19:00\n",
      "11        200143 2191-04-03 10:02:00\n",
      "12        200172 2198-05-18 04:15:00\n",
      "13        200183 2191-06-09 07:01:00\n",
      "14        200208 2117-02-18 20:50:00\n",
      "15        200223 2159-01-18 17:55:00\n",
      "16        200231 2127-03-09 16:30:00\n",
      "17        200238 2117-04-24 05:45:00\n",
      "18        200282 2164-05-04 23:18:00\n",
      "19        200286 2192-01-03 23:03:00\n",
      "20        200290 2102-12-24 19:01:00\n",
      "21        200346 2118-12-05 18:05:00\n",
      "22        200347 2116-06-07 16:00:00\n",
      "23        200349 2139-06-01 19:05:00\n",
      "24        200392 2113-02-10 14:08:00\n",
      "25        200441 2166-08-23 18:21:00\n",
      "26        200453 2153-04-05 21:00:00\n",
      "27        200454 2138-01-09 15:33:00\n",
      "28        200455 2166-02-21 12:41:00\n",
      "29        200457 2119-11-03 17:00:00\n",
      "...          ...                 ...\n",
      "6992      299606 2160-03-07 13:12:00\n",
      "6993      299608 2181-09-08 15:48:00\n",
      "6994      299614 2192-01-04 19:04:00\n",
      "6995      299626 2124-03-29 17:45:00\n",
      "6996      299630 2141-10-14 13:53:00\n",
      "6997      299645 2162-11-18 11:49:00\n",
      "6998      299658 2151-12-28 21:10:00\n",
      "6999      299660 2130-11-29 08:22:00\n",
      "7000      299672 2124-08-09 14:35:00\n",
      "7001      299678 2153-03-13 19:59:00\n",
      "7002      299698 2157-04-29 16:25:00\n",
      "7003      299734 2103-11-14 15:00:00\n",
      "7004      299749 2195-03-07 03:00:00\n",
      "7005      299756 2117-11-12 15:30:00\n",
      "7006      299758 2200-05-30 13:07:00\n",
      "7007      299791 2112-08-17 16:27:00\n",
      "7008      299802 2154-09-09 14:00:00\n",
      "7009      299811 2123-02-20 00:45:00\n",
      "7010      299820 2178-09-12 20:00:00\n",
      "7011      299846 2111-05-06 15:40:00\n",
      "7012      299847 2200-11-12 05:00:00\n",
      "7013      299867 2186-07-17 11:21:00\n",
      "7014      299871 2170-02-02 22:35:00\n",
      "7015      299879 2174-08-15 14:50:00\n",
      "7016      299904 2187-01-21 07:10:00\n",
      "7017      299948 2119-05-26 13:55:00\n",
      "7018      299950 2122-06-20 17:45:00\n",
      "7019      299956 2177-05-29 17:19:00\n",
      "7020      299957 2132-10-13 12:00:00\n",
      "7021      299979 2127-12-05 03:28:00\n",
      "\n",
      "[7022 rows x 2 columns]\n",
      "20969\n",
      "1636 / 16706 () patients with intervention vasopressor\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "########## load in pressor data, or other intervention data\n",
    "##########     TODO: add other loaders here for other interventions of interest here...\n",
    "##########\n",
    "\n",
    "# other interventions will have different processing here, eg for fluids...\n",
    "if INTERVENTION_TYPE == 'vasopressor':\n",
    "    interven_dat = pd.read_csv(PATH_TO_QUERY_DATA+\"vasopressors_mv.csv\")\n",
    "    interven_dat['STARTTIME'] = pd.to_datetime(interven_dat['STARTTIME'])\n",
    "    # vaso_dat = vaso_dat.loc[vaso_dat['ITEMID']!=222315,:] #exclude vasopressin...?\n",
    "    interven_dat = interven_dat.loc[:,['ICUSTAY_ID','STARTTIME']]\n",
    "\n",
    "    #get the first time a vaso is given\n",
    "    interven_dat = interven_dat.groupby(['ICUSTAY_ID']).min()\n",
    "    interven_dat.reset_index(level=0, inplace=True)\n",
    "    print(interven_dat)\n",
    "    \n",
    "# other interventions will have different processing here, eg for fluids...\n",
    "if INTERVENTION_TYPE == 'fluids':\n",
    "    interven_dat = pd.read_csv(PATH_TO_QUERY_DATA+\"allfluids_and_bloodproducts_mv.csv\")\n",
    "    interven_dat['STARTTIME'] = pd.to_datetime(interven_dat['STARTTIME'])\n",
    "    # vaso_dat = vaso_dat.loc[vaso_dat['ITEMID']!=222315,:] #exclude vasopressin...?\n",
    "    interven_dat = interven_dat.loc[:,['ICUSTAY_ID','STARTTIME']]\n",
    "\n",
    "    #get the first time a vaso is given\n",
    "    interven_dat = interven_dat.groupby(['ICUSTAY_ID']).min()\n",
    "    interven_dat.reset_index(level=0, inplace=True)\n",
    "    \n",
    "if INTERVENTION_TYPE == 'death':\n",
    "    # only for ICUSTAY_IDs where the flag is 1, include the starttime.\n",
    "    # if HOSPITAL_EXPIRE_FLAG == 1, then create a new dataframe which stores the DEATHTIME.\n",
    "\n",
    "    death_dict = {}\n",
    "    death_dict['ICUSTAY_ID'] = []\n",
    "    death_dict['STARTTIME'] = []\n",
    "\n",
    "    for name, group in cohort_dat.groupby(['ICUSTAY_ID']):\n",
    "        # calculate the mean hospital expire flag of the group\n",
    "        if np.mean(group['HOSPITAL_EXPIRE_FLAG']) > 0:\n",
    "            # add to dictionary\n",
    "            death_dict['ICUSTAY_ID'].append(name)\n",
    "            death_dict['STARTTIME'].append(pd.to_datetime(group.iloc[0]['DEATHTIME']))\n",
    "\n",
    "    interven_dat = pd.DataFrame(death_dict)\n",
    "    interven_dat.reset_index(level=0, inplace=True)\n",
    "    print(interven_dat)\n",
    "\n",
    "#NOTE: after processing, interven_dat should have 2 cols: ID & Start_time for those who got it \n",
    "#interven_dat should now just have 2 cols:\n",
    "\n",
    "cohort_dat = cohort_dat.merge(interven_dat,'left','ICUSTAY_ID')\n",
    "cohort_dat['Interv_Time_After_Start'] = (cohort_dat['STARTTIME']-cohort_dat['INTIME']).dt.total_seconds()/60/60\n",
    "\n",
    "#logic for filtering out bad interventions, ie too early or too late (after LOS thresh)\n",
    "keep_inds = np.logical_or(\n",
    "    np.logical_and(cohort_dat['Interv_Time_After_Start']>=INTERV_START_THRESH,\n",
    "        cohort_dat['Interv_Time_After_Start']<=LOS_UPPER_THRESH),\n",
    "    cohort_dat['Interv_Time_After_Start'].isnull())\n",
    "print(len(keep_inds))\n",
    "\n",
    "cohort_dat = cohort_dat.loc[keep_inds,:]\n",
    "cohort_dat.reset_index(inplace=True)\n",
    "cohort_dat = cohort_dat.sort_values(by=[\"ICUSTAY_ID\"])\n",
    "\n",
    "print('%d / %d () patients with intervention %s' %(\n",
    "    cohort_dat['Interv_Time_After_Start'].notnull().sum(),cohort_dat.shape[0],INTERVENTION_TYPE))\n",
    "\n",
    "final_ICU_IDs = np.array(cohort_dat['ICUSTAY_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5         True\n",
       "6         True\n",
       "7        False\n",
       "8        False\n",
       "9        False\n",
       "10       False\n",
       "11       False\n",
       "12       False\n",
       "13       False\n",
       "14       False\n",
       "15       False\n",
       "16       False\n",
       "17        True\n",
       "18       False\n",
       "19        True\n",
       "20       False\n",
       "21       False\n",
       "22       False\n",
       "23       False\n",
       "24       False\n",
       "25       False\n",
       "26       False\n",
       "27       False\n",
       "28       False\n",
       "29       False\n",
       "         ...  \n",
       "16676    False\n",
       "16677    False\n",
       "16678    False\n",
       "16679     True\n",
       "16680    False\n",
       "16681    False\n",
       "16682    False\n",
       "16683    False\n",
       "16684    False\n",
       "16685    False\n",
       "16686    False\n",
       "16687    False\n",
       "16688    False\n",
       "16689    False\n",
       "16690    False\n",
       "16691     True\n",
       "16692    False\n",
       "16693    False\n",
       "16694    False\n",
       "16695    False\n",
       "16696    False\n",
       "16697    False\n",
       "16698    False\n",
       "16699    False\n",
       "16700    False\n",
       "16701    False\n",
       "16702     True\n",
       "16703    False\n",
       "16704    False\n",
       "16705    False\n",
       "Name: Interv_Time_After_Start, Length: 16706, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print IDs that have the intervention\n",
    "\n",
    "cohort_dat['Interv_Time_After_Start'].notnull()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16706,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ICU_IDs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbp\n",
      "fio2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCS\n",
      "hr\n",
      "map\n",
      "sbp\n",
      "spontaneousrr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spo2\n",
      "temp\n",
      "urine\n",
      "weight\n",
      "bun\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magnesium\n",
      "platelets\n",
      "sodium\n",
      "alt\n",
      "hct\n",
      "po2\n",
      "ast\n",
      "potassium\n",
      "wbc\n",
      "bicarbonate\n",
      "creatinine\n",
      "lactate\n",
      "pco2\n",
      "bilirubin_total\n",
      "glucose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inr\n",
      "hgb\n",
      "time series variables all loaded!\n",
      "time series variables clipped to plausible ranges, outliers removed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##############\n",
    "############## load in all the ts data\n",
    "############## \n",
    "\n",
    "all_ts_dats, VAR_REFERENCE_IMPUTE, all_ts_vars = load_labs_and_vitals(PATH_TO_QUERY_DATA,cohort_dat)\n",
    "\n",
    "# it is a time-series, so I may need to modify load_labs_and_vitals\n",
    "\n",
    "\n",
    "##############\n",
    "############## finally build out dataset by discretizing time\n",
    "############## \n",
    "\n",
    "#store final dataset after right alignment here...\n",
    "all_grid_data = {}\n",
    "\n",
    "#precompute\n",
    "starts_ts = {}\n",
    "ends_ts = {}\n",
    "for v in all_ts_dats.keys():\n",
    "    starts_ts[v] = all_ts_dats[v]['ICUSTAY_ID'].searchsorted(final_ICU_IDs,'left')\n",
    "    ends_ts[v] = all_ts_dats[v]['ICUSTAY_ID'].searchsorted(final_ICU_IDs,'right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 100/16706, took 3.97\n",
      "processing 200/16706, took 3.95\n",
      "processing 300/16706, took 4.00\n",
      "processing 400/16706, took 4.02\n",
      "processing 500/16706, took 3.96\n",
      "processing 600/16706, took 4.07\n",
      "processing 700/16706, took 3.97\n",
      "processing 800/16706, took 3.96\n",
      "processing 900/16706, took 4.06\n",
      "processing 1000/16706, took 3.97\n",
      "processing 1100/16706, took 3.96\n",
      "processing 1200/16706, took 4.07\n",
      "processing 1300/16706, took 4.02\n",
      "processing 1400/16706, took 3.99\n",
      "processing 1500/16706, took 3.97\n",
      "processing 1600/16706, took 4.08\n",
      "processing 1700/16706, took 3.96\n",
      "processing 1800/16706, took 3.96\n",
      "processing 1900/16706, took 4.07\n",
      "processing 2000/16706, took 4.13\n",
      "processing 2100/16706, took 3.97\n",
      "processing 2200/16706, took 3.98\n",
      "processing 2300/16706, took 4.01\n",
      "processing 2400/16706, took 3.97\n",
      "processing 2500/16706, took 4.05\n",
      "processing 2600/16706, took 4.20\n",
      "processing 2700/16706, took 3.98\n",
      "processing 2800/16706, took 3.97\n",
      "processing 2900/16706, took 3.96\n",
      "processing 3000/16706, took 3.97\n",
      "processing 3100/16706, took 4.01\n",
      "processing 3200/16706, took 4.02\n",
      "processing 3300/16706, took 4.23\n",
      "processing 3400/16706, took 3.98\n",
      "processing 3500/16706, took 3.97\n",
      "processing 3600/16706, took 3.97\n",
      "processing 3700/16706, took 3.95\n",
      "processing 3800/16706, took 4.07\n",
      "processing 3900/16706, took 3.96\n",
      "processing 4000/16706, took 3.97\n",
      "processing 4100/16706, took 3.97\n",
      "processing 4200/16706, took 4.31\n",
      "processing 4300/16706, took 4.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-772d444ce157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mends_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mID_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mthis_dat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mthis_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_dat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHARTTIME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timedelta64[m]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m#urine has no valuenum field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right, name, na_op)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_SERIES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mget_op\u001b[0;34m(cls, left, right, name, na_op)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_Op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_TimeOp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, name, na_op)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;31m# left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/n/helmod/apps/centos7/Core/Anaconda3/5.0.1-fasrc01/x/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_convert_to_array\u001b[0;34m(self, values, name, other)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;31m# datetime with tz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             elif (isinstance(ovalues, datetime.datetime) and\n\u001b[0;32m--> 475\u001b[0;31m                   hasattr(ovalues, 'tzinfo')):\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;31m# datetime array with tz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loop_t = time()\n",
    "num_excluded = 0\n",
    "for ID_ind,ID in enumerate(final_ICU_IDs):\n",
    "    if ID_ind % 100==99:\n",
    "        print(\"processing %d/%d, took %.2f\" %(ID_ind+1,len(final_ICU_IDs),time()-loop_t))\n",
    "        loop_t = time()\n",
    "\n",
    "    this_static_dat = cohort_dat.iloc[ID_ind]\n",
    "\n",
    "    #TODO: you may want to add other vars in besides just age...\n",
    "    # print(this_static_dat.keys())\n",
    "    \n",
    "    age = this_static_dat['AGE']\n",
    "    gender = this_static_dat['GENDER'] == 'F'\n",
    "    adm_type = this_static_dat['ADMISSION_TYPE']\n",
    "    \n",
    "    is_urgent = adm_type == 'URGENT'\n",
    "    is_emergency = adm_type == 'EMERGENCY'\n",
    "    \n",
    "    is_sicu = this_static_dat['FIRST_CAREUNIT'] == 'SICU'\n",
    "    is_tsicu = this_static_dat['FIRST_CAREUNIT'] == 'TSICU'\n",
    "    is_micu = this_static_dat['FIRST_CAREUNIT'] == 'MICU'\n",
    "    is_csru = this_static_dat['FIRST_CAREUNIT'] == 'CSRU'\n",
    "    \n",
    "    if age > 90: #fix ages set to 300+ for anonymity purposes\n",
    "        age = 90\n",
    "\n",
    "    assert np.logical_not(np.isnan(age))\n",
    "    start_time = this_static_dat['INTIME']\n",
    "\n",
    "    \n",
    "    if INTERVENTION_TYPE == 'death':\n",
    "        # for this task, end_time is not selected randomly; include entire trajectory\n",
    "        if pd.isnull(this_static_dat['Interv_Time_After_Start']):\n",
    "            end_time = this_static_dat['LOS']\n",
    "            has_interv = False\n",
    "        else:\n",
    "            end_time = this_static_dat['Interv_Time_After_Start']\n",
    "            has_interv = True\n",
    "    else:\n",
    "        #end time should be a random time between VASO_START_THRESH hours in and 90% quantile of LOS\n",
    "        if pd.isnull(this_static_dat['Interv_Time_After_Start']):\n",
    "            if CONTROL_ENDTIME_UPPERQUANT==-1: #just use true end time, nothing shorter\n",
    "                end_time = this_static_dat['LOS']\n",
    "            else:\n",
    "                end_time = np.random.uniform(LOS_LOWER_THRESH,CONTROL_ENDTIME_UPPERQUANT*this_static_dat['LOS'],1)[0]\n",
    "            has_interv = False\n",
    "        else:\n",
    "            end_time = this_static_dat['Interv_Time_After_Start']\n",
    "            has_interv = True\n",
    "\n",
    "    # #times at which to build out feature vectors\n",
    "    # if CONTROL_ENDTIME_UPPERQUANT==-1: #just use true end time, nothing shorter\n",
    "    #     #forwards, left align from start\n",
    "    #     grid_times = np.arange(START_TIME,end_time,DISC_GRID_SIZE)\n",
    "    # else:\n",
    "    #     #backwards, right align from end\n",
    "    #     grid_times = np.arange(end_time,0,-DISC_GRID_SIZE)[::-1]\n",
    "\n",
    "    #always right align so not starting right at 0; get a little data\n",
    "    grid_times = np.arange(end_time,START_TIME,-DISC_GRID_SIZE)[::-1]\n",
    "#     print(\"end time\")\n",
    "#     print(end_time)\n",
    "#     print(\"START_TIME\")\n",
    "#     print(START_TIME)\n",
    "#     print(\"grid times length\")\n",
    "#     print(len(grid_times))\n",
    "\n",
    "    n_t = len(grid_times)\n",
    "    #print('Original timeseries time: ' + str(n_t))\n",
    "\n",
    "    this_grid_dat = pd.DataFrame()\n",
    "    this_grid_dat['Times'] = grid_times \n",
    "    this_grid_dat['Has_Interv'] = has_interv\n",
    "    this_grid_dat['Interv_Time'] = this_static_dat['Interv_Time_After_Start']\n",
    "    this_grid_dat['Age'] = age\n",
    "    this_grid_dat['is_F'] = gender\n",
    "    this_grid_dat['is_urgent'] = is_urgent\n",
    "    this_grid_dat['is_emergency'] = is_emergency\n",
    "    this_grid_dat['is_sicu'] = is_sicu\n",
    "    this_grid_dat['is_tsicu'] = is_tsicu\n",
    "    this_grid_dat['is_micu'] = is_micu\n",
    "    this_grid_dat['is_csru'] = is_csru\n",
    "    \n",
    "    # Treat first-measured weight as static.\n",
    "    # If the patient never has their weight taken, exclude them.\n",
    "\n",
    "    #####\n",
    "    #now build out the time series\n",
    "    #also build out indicator vector at each time, noting whether var was imputed or not\n",
    "    for v in all_ts_vars:\n",
    "        dat = all_ts_dats[v]\n",
    "\n",
    "        s = starts_ts[v][ID_ind]\n",
    "        e = ends_ts[v][ID_ind]\n",
    "        this_dat = dat[s:e]\n",
    "        this_t = np.array((this_dat['CHARTTIME'] - start_time).astype('timedelta64[m]').astype(float))/60\n",
    "\n",
    "        #urine has no valuenum field\n",
    "        if v=='urine':\n",
    "            val_str = 'VALUE'\n",
    "        else:\n",
    "            val_str = 'VALUENUM'\n",
    "\n",
    "        this_vals = np.array(this_dat[val_str],\"float\")\n",
    "\n",
    "        #impute anything initially missing with pop median, then\n",
    "        #fill this in with observed values via LOCF\n",
    "        imputed_vals = VAR_REFERENCE_IMPUTE[v]*np.ones(n_t)\n",
    "\n",
    "        ### Now get LOCF for cts labs/vitals\n",
    "        tt = np.searchsorted(grid_times+1e-8,this_t)\n",
    "        \n",
    "        for i in range(len(tt)):\n",
    "            if i!=len(tt)-1:\n",
    "                imputed_vals[tt[i]:tt[i+1]] = this_vals[i] \n",
    "            else:\n",
    "                imputed_vals[tt[i]:] = this_vals[i] \n",
    "        \n",
    "        this_grid_dat[v] = imputed_vals\n",
    "\n",
    "        #get indicators for at which times the variable was actually sampled\n",
    "        inds_samples_vals = np.zeros(n_t+1) #edge case when values past endtime\n",
    "        inds_samples_vals[tt] = 1.0\n",
    "        inds_samples_vals = inds_samples_vals[:-1] #edge case when values past endtime\n",
    "        \n",
    "        if v == 'weight':\n",
    "            # Append first time the weight was measured\n",
    "            weight_meas_times = np.where(inds_samples_vals == 1)[0]\n",
    "            if len(weight_meas_times > 0):\n",
    "                first_weight_time = weight_meas_times[0]\n",
    "                \n",
    "                # if possible, add 1 to account for the case where the weight isn't recorded until after the measurement time\n",
    "                if first_weight_time < (len(imputed_vals) - 1):\n",
    "                    first_weight_time += 1\n",
    "                this_grid_dat['Weight'] = imputed_vals[first_weight_time]\n",
    "\n",
    "            else:\n",
    "                num_excluded += 1\n",
    "            \n",
    "        else:\n",
    "\n",
    "            this_grid_dat[v+'_ind'] = inds_samples_vals\n",
    "\n",
    "            # extra inds for other times...\n",
    "            if v in ['ADBP','AMBP','ASBP','Lactate']:\n",
    "                ever_inds = convert_1inds_to_everinds(inds_samples_vals)\n",
    "                this_grid_dat[v+'_ever-ind'] = ever_inds\n",
    "\n",
    "            # extra inds for other times...\n",
    "            if v in ['ALT','AST','BUN','Bilirubin','Creatinine','Glucose','Hct','Hgb','FiO2',\n",
    "                'HCO3','PCO2','PO2','K','Na','Lactate','Magnesium','Platelet','WBC','Weight']:\n",
    "                last_8_inds = convert_1inds_to_kinds(inds_samples_vals,8)\n",
    "                this_grid_dat[v+'_8-ind'] = last_8_inds\n",
    "\n",
    "\n",
    "    #finished all vars; now combine the 3 GCS vars together and drop old ones\n",
    "    this_grid_dat['GCS'] = this_grid_dat['GCS_eye']+this_grid_dat['GCS_motor']+this_grid_dat['GCS_verbal']\n",
    "\n",
    "    this_grid_dat['GCS_ind'] = this_grid_dat['GCS_eye_ind']+this_grid_dat['GCS_motor_ind']+this_grid_dat['GCS_verbal_ind']\n",
    "    this_grid_dat['GCS_ind'] = np.minimum(this_grid_dat['GCS_ind'],1)\n",
    "    \n",
    "    #print('Length of this_grid_dat: ' + str(this_grid_dat['GCS'].shape))\n",
    "    \n",
    "    if len(weight_meas_times > 0):\n",
    "        all_grid_data[ID] = this_grid_dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.83813\n",
       "1      1.83813\n",
       "2      2.83813\n",
       "3      3.83813\n",
       "4      4.83813\n",
       "5      5.83813\n",
       "6      6.83813\n",
       "7      7.83813\n",
       "8      8.83813\n",
       "9      9.83813\n",
       "10    10.83813\n",
       "11    11.83813\n",
       "12    12.83813\n",
       "13    13.83813\n",
       "14    14.83813\n",
       "15    15.83813\n",
       "16    16.83813\n",
       "17    17.83813\n",
       "18    18.83813\n",
       "19    19.83813\n",
       "20    20.83813\n",
       "21    21.83813\n",
       "22    22.83813\n",
       "23    23.83813\n",
       "24    24.83813\n",
       "25    25.83813\n",
       "26    26.83813\n",
       "27    27.83813\n",
       "28    28.83813\n",
       "29    29.83813\n",
       "30    30.83813\n",
       "31    31.83813\n",
       "32    32.83813\n",
       "Name: Times, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_excluded\n",
    "this_grid_dat['Times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/home07/carissawu/intervention-onset/model-data/11-15-21-interpretable-timeseries-vasopressor.p\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = PATH_TO_CLEANED_DATA+'11-15-21-interpretable-timeseries-vasopressor.p'\n",
    "\n",
    "print(OUTPUT_PATH)\n",
    "pickle.dump(all_grid_data,open(OUTPUT_PATH,'wb'))\n",
    "pickle.dump(all_grid_data,open('data.p', 'wb'))\n",
    "\n",
    "print('dumped')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Replicating Previous Vasopressor Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_REPO = '/n/dtak/mimic-pipeline-tools/'\n",
    "\n",
    "sys.path.append(PATH_TO_REPO+'mimic-iii-v1-4/extract-scripts')\n",
    "from data_load_utils import load_labs_and_vitals,convert_1inds_to_everinds,convert_1inds_to_kinds\n",
    "\n",
    "PATH_TO_QUERY_DATA = PATH_TO_REPO+\"mimic-iii-v1-4/query-data/\"\n",
    "PATH_TO_CLEANED_DATA = \"/n/home07/carissawu/intervention-onset/model-data/\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "\n",
    "###########\n",
    "#params for dataset construction; make same as UT\n",
    "\n",
    "LOS_LOWER_THRESH = 6 #exclude if LOS is shorter than this many hours\n",
    "LOS_UPPER_THRESH = 600 #exclude if LOS is longer than this many hours\n",
    "\n",
    "CONTROL_ENDTIME_UPPERQUANT = 0.9 #quantile for upper end of when we'll choose control time per enc; -1=use all, no cut\n",
    "DISC_GRID_SIZE = 1.0 #number of hours of separation in grid\n",
    "INTERVENTION_TYPE = 'vasopressor' #for now just vasopressor, later other types, too...\n",
    "\n",
    "#NOTE: THIS PARAM IS REALLY, REALLY IMPT! DEFINITELY PLOT *WHEN* THE FIRST TIME \n",
    "# EACH INTERVENTION IS GIVEN TO DECIDE WHAT TO SET THIS!!\n",
    "INTERV_START_THRESH = 6\n",
    "\n",
    "SEED = 8675309\n",
    "np.random.seed(SEED)\n",
    "\n",
    "START_TIME = 0 #start time series here...\n",
    "\n",
    "##########\n",
    "########## load in the baseline/static data for the cohort\n",
    "##########\n",
    "\n",
    "cohort_dat = pd.read_csv(PATH_TO_QUERY_DATA+'cohort.csv')\n",
    "og_row_num = cohort_dat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cohort loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# do any additional filtering beyond cohort construction, if desired...\n",
    "\n",
    "cohort_dat = cohort_dat.loc[cohort_dat['LOS'] >= LOS_LOWER_THRESH,:]\n",
    "cohort_dat = cohort_dat.loc[cohort_dat['LOS'] <=  LOS_UPPER_THRESH,:]\n",
    "\n",
    "cohort_dat['INTIME'] = pd.to_datetime(cohort_dat['INTIME'])\n",
    "\n",
    "print('cohort loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20510\n",
      "cohort shape\n",
      "20510\n",
      "cohort shape\n",
      "16401\n",
      "1473 / 16401 () patients with intervention vasopressor\n"
     ]
    }
   ],
   "source": [
    "interven_dat = pd.read_csv(PATH_TO_QUERY_DATA+\"vasopressors_mv.csv\")\n",
    "interven_dat['STARTTIME'] = pd.to_datetime(interven_dat['STARTTIME'])\n",
    "interven_dat = interven_dat.loc[:,['ICUSTAY_ID','STARTTIME']]\n",
    "interven_dat = interven_dat.groupby(['ICUSTAY_ID']).min()\n",
    "interven_dat.reset_index(level=0, inplace=True)\n",
    "cohort_dat = cohort_dat.merge(interven_dat,'left','ICUSTAY_ID')\n",
    "cohort_dat['Interv_Time_After_Start'] = (cohort_dat['STARTTIME']-cohort_dat['INTIME']).dt.total_seconds()/60/60\n",
    "keep_inds = np.logical_or(\n",
    "    np.logical_and(cohort_dat['Interv_Time_After_Start']>=INTERV_START_THRESH,\n",
    "        cohort_dat['Interv_Time_After_Start']<=LOS_UPPER_THRESH),\n",
    "    cohort_dat['Interv_Time_After_Start'].isnull())\n",
    "print(len(keep_inds))\n",
    "print(\"cohort shape\")\n",
    "print(cohort_dat.shape[0])\n",
    "cohort_dat = cohort_dat.loc[keep_inds,:]\n",
    "cohort_dat.reset_index(inplace=True)\n",
    "cohort_dat = cohort_dat.sort_values(by=[\"ICUSTAY_ID\"])\n",
    "print(\"cohort shape\")\n",
    "print(cohort_dat.shape[0])\n",
    "print('%d / %d () patients with intervention %s' %(\n",
    "    cohort_dat['Interv_Time_After_Start'].notnull().sum(),cohort_dat.shape[0],INTERVENTION_TYPE))\n",
    "\n",
    "# cohort_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cohort_1 = cohort_dat[cohort_dat['Interv_Time_After_Start'].notnull()]\n",
    "cohort_0 = cohort_dat[cohort_dat['Interv_Time_After_Start'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.3621503758\n",
      "64.3217021472\n"
     ]
    }
   ],
   "source": [
    "cohort_1_age = np.array(cohort_1['AGE'])\n",
    "print(np.median(cohort_1_age))\n",
    "cohort_0_age = np.array(cohort_0['AGE'])\n",
    "print(np.median(cohort_0_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
