{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:15\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29137, 6, 62)\n",
      "(29137, 2)\n",
      "(29137, 1)\n",
      "27 ['dbp', 'fio2', 'GCS', 'hr', 'map', 'sbp', 'spontaneousrr', 'spo2', 'temp', 'bun', 'magnesium', 'platelets', 'sodium', 'alt', 'hct', 'po2', 'ast', 'potassium', 'wbc', 'bicarbonate', 'creatinine', 'lactate', 'pco2', 'glucose', 'inr', 'hgb', 'bilirubin_total']\n"
     ]
    }
   ],
   "source": [
    "X, Y_logits, changing_vars, _ = myPreprocessed()\n",
    "print(X.shape)\n",
    "print(Y_logits.shape) # (logit, original)\n",
    "y = Y_logits[:, 1, None]\n",
    "print(y.shape)\n",
    "print(len(changing_vars), changing_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(_X, _Y_logits, output_dim = 2, batch_size = 512, random_state = 1):\n",
    "    \n",
    "    # ## target\n",
    "    y = _Y_logits\n",
    "    if output_dim == 1:\n",
    "        y = _Y_logits[:, 1, None]\n",
    "    \n",
    "    y_unique = np.unique(y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    # # class weights\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=y_unique, y=_Y_logits[:, 1])\n",
    "    class_weights = torch.tensor(class_weights)\n",
    "    \n",
    "    if output_dim == 1:\n",
    "        class_weights = class_weights[1]/class_weights[0] # == pos / neg   # get ONLY positive sample weights\n",
    "    \n",
    "    \n",
    "    # split 60/20/20 %\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, y, test_size = 0.40, random_state = random_state, stratify = y)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "    # tensor\n",
    "    X_train_pt = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_pt = torch.tensor(y_train)\n",
    "\n",
    "    X_val_pt = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_pt = torch.tensor(y_val)\n",
    "\n",
    "    X_test_pt = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_pt = torch.tensor(y_test)\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = TensorDataset(X_train_pt, y_train_pt)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4, pin_memory=False)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val_pt, y_val_pt)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = X_val_pt.shape[0], shuffle=False, num_workers=4, pin_memory=False)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_pt, y_test_pt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = X_test_pt.shape[0], shuffle=False, num_workers=4, pin_memory=False)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2752, dtype=torch.float64) 2\n",
      "torch.Size([512, 6, 62]) cpu\n",
      "torch.Size([512, 1]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits, 1)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for a,b in train_loader:\n",
    "    print(a.shape, a.device)\n",
    "    print(b.shape, b.device)\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim, noise_std, top_k=''):\n",
    "    model = original_models.CBM(input_dim = input_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = True,\n",
    "                                use_fixes = False,\n",
    "                                use_only_last_timestep = False,\n",
    "                                use_grad_norm = False,\n",
    "                                noise_std = noise_std,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=1e-3,\n",
    "                                cos_sim_lambda=1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, output_dim, use_summaries_for_atomics, noise_std, top_k=''):\n",
    "    model = new_models.CBM(input_dim = input_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = True,\n",
    "                            use_fixes = False,\n",
    "                            use_grad_norm = False,\n",
    "                            noise_std = noise_std,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=1e-3,\n",
    "                            cos_sim_lambda=1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 62 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auroc_metric = AUROC(task=\"binary\").to(device)\n",
    "accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
    "f1_metric = F1Score(task=\"binary\").to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"binary\").to(device)\n",
    "\n",
    "seq_len = X.shape[1]\n",
    "changing_dim = len(changing_vars)\n",
    "input_dim = X.shape[2]\n",
    "\n",
    "print(changing_dim, input_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "config_original = {\n",
    "    \"n_concepts\": [4], # 20\n",
    "    # \"use_indicators\": [True], # False\n",
    "    # \"use_fixes\": [False], # True\n",
    "    # \"use_only_last_timestep\": [False], # True\n",
    "    # \"output_dim\": [2], #1\n",
    "    # \"use_grad_norm\": [False], # \"FULL\", \"COMPONENT_WISE\"],\n",
    "    \"noise_std\": [None, .2, .5, .7, 1, 5, 10],\n",
    "}\n",
    "\n",
    "all_config_permutations_og = list(product(*config_original.values()))\n",
    "all_config_permutations_og = [dict(zip(config_original.keys(), permutation)) for permutation in all_config_permutations_og]\n",
    "print(len(all_config_permutations_og))\n",
    "# all_config_permutations_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/vasopressor/original/\"\n",
    "model_path = experiment_folder + \"vaso_c_{n_concepts}_noise_std_{noise_std}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_concepts': 4, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 339/10000 [04:40<2:13:18,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.5261745452880859, 0.9143568277359009, 0.8388535976409912, 0.8469188213348389, 0.0013957176124677062]\n",
      "1 {'n_concepts': 4, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 309/10000 [04:34<2:23:32,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.5372231006622314, 0.9251470565795898, 0.8541273474693298, 0.8594809174537659, 0.002857369603589177]\n",
      "2 {'n_concepts': 4, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 439/10000 [06:26<2:20:24,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.5387924313545227, 0.9271559715270996, 0.8582460880279541, 0.8633355498313904, 0.00822579488158226]\n",
      "3 {'n_concepts': 4, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 319/10000 [04:46<2:24:49,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.543633222579956, 0.9229189157485962, 0.8582460880279541, 0.8632676601409912, 0.007552966475486755]\n",
      "4 {'n_concepts': 4, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 349/10000 [05:10<2:22:57,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.54631507396698, 0.9203706383705139, 0.854813814163208, 0.8600959181785583, 0.006977006793022156]\n",
      "5 {'n_concepts': 4, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 239/10000 [03:33<2:25:10,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.6172335743904114, 0.8738658428192139, 0.8625364899635315, 0.8625364899635315, 0.0030987404752522707]\n",
      "6 {'n_concepts': 4, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  1%|▏         | 129/10000 [01:57<2:29:57,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.6171075105667114, 0.8872444033622742, 0.8625364899635315, 0.8625364899635315, 0.0009533893899060786]\n",
      "0 {'n_concepts': 4, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 299/10000 [04:15<2:18:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.5284395813941956, 0.9010716676712036, 0.8168010711669922, 0.8274189829826355, 0.0015584081411361694]\n",
      "1 {'n_concepts': 4, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 399/10000 [06:05<2:26:46,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.5252007842063904, 0.9214909076690674, 0.8473485708236694, 0.8541205525398254, 0.004022379405796528]\n",
      "2 {'n_concepts': 4, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 529/10000 [07:59<2:23:05,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.5420578718185425, 0.926910400390625, 0.8609919548034668, 0.8656493425369263, 0.008535111322999]\n",
      "3 {'n_concepts': 4, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 199/10000 [03:01<2:28:43,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.5503532290458679, 0.9233282804489136, 0.8603054881095886, 0.8650530576705933, 0.006694985553622246]\n",
      "4 {'n_concepts': 4, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▍         | 479/10000 [07:08<2:21:58,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.5481465458869934, 0.924123227596283, 0.8620216250419617, 0.8661784529685974, 0.0113755464553833]\n",
      "5 {'n_concepts': 4, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 169/10000 [02:35<2:30:42,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.6178917288780212, 0.8730436563491821, 0.8625364899635315, 0.8625364899635315, 0.011560725048184395]\n",
      "6 {'n_concepts': 4, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  1%|▏         | 129/10000 [01:57<2:29:27,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.6166616082191467, 0.894241988658905, 0.8625364899635315, 0.8625364899635315, 0.0013604662381112576]\n",
      "0 {'n_concepts': 4, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 289/10000 [04:05<2:17:21,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.5295514464378357, 0.9205506443977356, 0.8512098789215088, 0.8570486307144165, 0.006247116718441248]\n",
      "1 {'n_concepts': 4, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  6%|▌         | 599/10000 [09:05<2:22:40,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.5232479572296143, 0.9161176085472107, 0.8385961651802063, 0.8463360667228699, 0.004269768949598074]\n",
      "2 {'n_concepts': 4, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 399/10000 [06:00<2:24:45,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.5370433926582336, 0.9230210185050964, 0.8557576537132263, 0.860763669013977, 0.005162663292139769]\n",
      "3 {'n_concepts': 4, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 419/10000 [06:17<2:23:54,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.539925754070282, 0.924515962600708, 0.8593615889549255, 0.8650028705596924, 0.005338012240827084]\n",
      "4 {'n_concepts': 4, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 269/10000 [04:01<2:25:34,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.5488686561584473, 0.9219156503677368, 0.859704852104187, 0.864618718624115, 0.001671700505539775]\n",
      "5 {'n_concepts': 4, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 259/10000 [03:54<2:26:49,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.6165717244148254, 0.881461501121521, 0.8625364899635315, 0.8625364899635315, 0.005409506615251303]\n",
      "6 {'n_concepts': 4, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  1%|▏         | 139/10000 [02:06<2:30:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.6169849634170532, 0.8886846303939819, 0.8625364899635315, 0.8625364899635315, 0.0030241692438721657]\n",
      "0 {'n_concepts': 4, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 419/10000 [05:59<2:17:08,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.5250046849250793, 0.9031111001968384, 0.8220353722572327, 0.8308043479919434, 0.0037673963233828545]\n",
      "1 {'n_concepts': 4, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 289/10000 [04:20<2:26:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.5365214347839355, 0.9227068424224854, 0.8476917743682861, 0.8537771105766296, 0.003345776814967394]\n",
      "2 {'n_concepts': 4, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▎         | 369/10000 [05:35<2:25:58,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.5412384867668152, 0.9243477582931519, 0.8577312231063843, 0.8626346588134766, 0.011237561702728271]\n",
      "3 {'n_concepts': 4, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 209/10000 [03:08<2:26:51,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.5526758432388306, 0.9257996082305908, 0.8625364899635315, 0.8665000200271606, 0.0015856927493587136]\n",
      "4 {'n_concepts': 4, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 219/10000 [03:16<2:25:59,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.5469633936882019, 0.9239593744277954, 0.8611635565757751, 0.8655699491500854, 0.0027855816297233105]\n",
      "5 {'n_concepts': 4, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 179/10000 [02:42<2:28:58,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.6166075468063354, 0.8853434324264526, 0.8625364899635315, 0.8625364899635315, 0.0026931017637252808]\n",
      "6 {'n_concepts': 4, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 529/10000 [07:50<2:20:27,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.6167861819267273, 0.8899608850479126, 0.8625364899635315, 0.8625364899635315, 0.002256477251648903]\n",
      "0 {'n_concepts': 4, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 319/10000 [04:29<2:16:18,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 0, 0.5288946032524109, 0.920345664024353, 0.8436588048934937, 0.850090503692627, 0.005985617637634277]\n",
      "1 {'n_concepts': 4, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▎         | 359/10000 [05:25<2:25:52,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 1, 0.5312842130661011, 0.9230996966362, 0.8530118465423584, 0.8589078187942505, 0.006569331046193838]\n",
      "2 {'n_concepts': 4, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 259/10000 [03:53<2:26:13,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 2, 0.5409303903579712, 0.922773540019989, 0.85284024477005, 0.8585566878318787, 0.0025029005482792854]\n",
      "3 {'n_concepts': 4, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 429/10000 [06:25<2:23:14,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 3, 0.5451091527938843, 0.9240099787712097, 0.8560150861740112, 0.8606081008911133, 0.0031932543497532606]\n",
      "4 {'n_concepts': 4, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 339/10000 [05:02<2:23:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 4, 0.5520625710487366, 0.9218510389328003, 0.8608202934265137, 0.8656395077705383, 0.0024446099996566772]\n",
      "5 {'n_concepts': 4, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  1%|▏         | 149/10000 [02:14<2:28:42,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 5, 0.6177952885627747, 0.8804479837417603, 0.8625364899635315, 0.8625364899635315, 0.009741319343447685]\n",
      "6 {'n_concepts': 4, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  2%|▏         | 199/10000 [03:01<2:28:57,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 6, 0.6171475648880005, 0.8827455639839172, 0.8625364899635315, 0.8625364899635315, 0.0011921318946406245]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for zzz in range(5):\n",
    "    for i, config in enumerate(all_config_permutations_og):\n",
    "        print(i, config)\n",
    "        \n",
    "        train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits)\n",
    "        \n",
    "        model = initializeModel(**config, input_dim=input_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=2)\n",
    "        model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config)+f\"{zzz}\", max_epochs=10000)\n",
    "        \n",
    "        cos_sim = (model.cos_sim(model.bottleneck) / model.bottleneck.out_features).item()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                probs = model.forward_probabilities(Xb)\n",
    "                \n",
    "                auc = auroc_metric(probs, yb).item()\n",
    "                acc = accuracy_metric(probs, yb).item()\n",
    "                f1 = f1_metric(probs, yb).item()\n",
    "                # conf_matrix(probs, yb)\n",
    "            auc = auroc_metric.compute().item()\n",
    "            acc = accuracy_metric.compute().item()\n",
    "            f1 = f1_metric.compute().item()\n",
    "            # conf_matrix.plot()\n",
    "            # plt.show()\n",
    "            auroc_metric.reset()\n",
    "            accuracy_metric.reset()\n",
    "            # conf_matrix.reset()\n",
    "            f1_metric.reset()\n",
    "        \n",
    "        history = [\"original\", i, model.val_losses[-1], auc, acc, f1, cos_sim]\n",
    "        print(history)\n",
    "        histories_original.append(np.array(history))\n",
    "        \n",
    "        # plot_losses(model.train_losses, model.val_losses)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "# plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "config_atomics = {\n",
    "    \"n_atomics\": [10], # 30\n",
    "    \"n_concepts\": [4], # 20\n",
    "    # \"use_indicators\": [True], # False\n",
    "    # \"use_fixes\": [False], # True\n",
    "    # \"output_dim\": [2], #1\n",
    "    \"use_summaries_for_atomics\": [True], # False\n",
    "    # \"use_grad_norm\": [False], # \"FULL\", \"COMPONENT_WISE\"],\n",
    "    \"noise_std\": [None, .2, .5, .7, 1, 5, 10],\n",
    "}\n",
    "\n",
    "all_config_permutations_atomics = list(product(*config_atomics.values()))\n",
    "all_config_permutations_atomics = [dict(zip(config_atomics.keys(), permutation)) for permutation in all_config_permutations_atomics]\n",
    "print(len(all_config_permutations_atomics))\n",
    "# all_config_permutations_atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/vasopressor/atomics/\"\n",
    "model_path = experiment_folder + \"vaso_a_{n_atomics}_c_{n_concepts}_summaries4atomics_{use_summaries_for_atomics}_noise_std_{noise_std}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  6%|▌         | 600/10000 [09:15<2:25:04,  1.08 epoch/s, Train Loss=0.50485, Val Loss=0.53954, Best Val Loss=0.53912]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.5400149822235107, 0.9159799814224243, 0.8379955291748047, 0.8457516431808472, 0.009828764945268631]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 710/10000 [11:31<2:30:44,  1.03 epoch/s, Train Loss=0.51034, Val Loss=0.53585, Best Val Loss=0.53470]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.5404880046844482, 0.9241430759429932, 0.8552428483963013, 0.860659122467041, 0.007816251367330551]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 770/10000 [12:26<2:29:08,  1.03 epoch/s, Train Loss=0.52658, Val Loss=0.54110, Best Val Loss=0.54086]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.5466828942298889, 0.9239658117294312, 0.8651965260505676, 0.8691160678863525, 0.008661005645990372]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 440/10000 [07:10<2:35:51,  1.02 epoch/s, Train Loss=0.61691, Val Loss=0.61671, Best Val Loss=0.61661]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.6169410943984985, 0.881426990032196, 0.8625364899635315, 0.8625364899635315, 0.008527224883437157]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 520/10000 [08:19<2:31:46,  1.04 epoch/s, Train Loss=0.55098, Val Loss=0.56435, Best Val Loss=0.55195]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.560035765171051, 0.922935426235199, 0.8703449368476868, 0.8733338713645935, 0.009541865438222885]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 450/10000 [07:13<2:33:22,  1.04 epoch/s, Train Loss=0.61724, Val Loss=0.61691, Best Val Loss=0.61678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.6172764897346497, 0.8788121938705444, 0.8625364899635315, 0.8625364899635315, 0.009403018280863762]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▍         | 480/10000 [07:40<2:32:04,  1.04 epoch/s, Train Loss=0.61713, Val Loss=0.61793, Best Val Loss=0.61677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.617590069770813, 0.8469321727752686, 0.8625364899635315, 0.8625364899635315, 0.010653460398316383]\n",
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 680/10000 [10:26<2:23:13,  1.08 epoch/s, Train Loss=0.50233, Val Loss=0.53678, Best Val Loss=0.53594]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.5367680788040161, 0.9109189510345459, 0.8302728533744812, 0.8396042585372925, 0.01124761626124382]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 500/10000 [08:01<2:32:26,  1.04 epoch/s, Train Loss=0.51230, Val Loss=0.53762, Best Val Loss=0.53761]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.5400208830833435, 0.923385739326477, 0.8555002808570862, 0.8609643578529358, 0.007919329218566418]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 750/10000 [12:05<2:29:10,  1.03 epoch/s, Train Loss=0.52558, Val Loss=0.53766, Best Val Loss=0.53760]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.539885938167572, 0.9238311052322388, 0.8597906231880188, 0.8643758296966553, 0.008879667147994041]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  6%|▌         | 620/10000 [10:04<2:32:27,  1.03 epoch/s, Train Loss=0.53338, Val Loss=0.54493, Best Val Loss=0.54175]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.5448480844497681, 0.923615574836731, 0.8644242286682129, 0.8683552742004395, 0.008153199218213558]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 850/10000 [13:48<2:28:37,  1.03 epoch/s, Train Loss=0.54673, Val Loss=0.55832, Best Val Loss=0.55087]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.552155613899231, 0.9228373765945435, 0.8673416972160339, 0.871359646320343, 0.009220628067851067]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 520/10000 [08:24<2:33:21,  1.03 epoch/s, Train Loss=0.61689, Val Loss=0.61699, Best Val Loss=0.61669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.6169622540473938, 0.8939139246940613, 0.8625364899635315, 0.8625364899635315, 0.007364174816757441]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 720/10000 [11:37<2:29:54,  1.03 epoch/s, Train Loss=0.61705, Val Loss=0.61713, Best Val Loss=0.61678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.6175282001495361, 0.8630157709121704, 0.8625364899635315, 0.8625364899635315, 0.011128597892820835]\n",
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1050/10000 [15:56<2:15:54,  1.10 epoch/s, Train Loss=0.49567, Val Loss=0.52891, Best Val Loss=0.52790]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.5343548059463501, 0.9247896075248718, 0.8553286194801331, 0.8609828352928162, 0.010588686913251877]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 770/10000 [12:34<2:30:42,  1.02 epoch/s, Train Loss=0.51109, Val Loss=0.53647, Best Val Loss=0.53268]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.5348886847496033, 0.9212970733642578, 0.8551570177078247, 0.8608638048171997, 0.009252783842384815]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▍         | 470/10000 [07:40<2:35:37,  1.02 epoch/s, Train Loss=0.52909, Val Loss=0.55429, Best Val Loss=0.54805]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.554394543170929, 0.9244407415390015, 0.8664836287498474, 0.8699866533279419, 0.008905298076570034]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 820/10000 [13:16<2:28:41,  1.03 epoch/s, Train Loss=0.53630, Val Loss=0.55171, Best Val Loss=0.54735]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.5530685186386108, 0.9242842197418213, 0.8660545945167542, 0.8699924945831299, 0.008293322287499905]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 420/10000 [06:49<2:35:43,  1.03 epoch/s, Train Loss=0.61666, Val Loss=0.61692, Best Val Loss=0.61664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.616681694984436, 0.889587938785553, 0.8625364899635315, 0.8625364899635315, 0.007702442817389965]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 410/10000 [06:39<2:35:33,  1.03 epoch/s, Train Loss=0.61729, Val Loss=0.61704, Best Val Loss=0.61645]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.6169556379318237, 0.8853956460952759, 0.8625364899635315, 0.8625364899635315, 0.008446687832474709]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 440/10000 [06:50<2:28:32,  1.07 epoch/s, Train Loss=0.61699, Val Loss=0.61728, Best Val Loss=0.61685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.6170600056648254, 0.8552590608596802, 0.8625364899635315, 0.8625364899635315, 0.008111677132546902]\n",
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 530/10000 [07:46<2:18:53,  1.14 epoch/s, Train Loss=0.50223, Val Loss=0.53568, Best Val Loss=0.53500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.536011815071106, 0.9163925647735596, 0.8398833274841309, 0.8474991917610168, 0.008933399803936481]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 730/10000 [11:13<2:22:38,  1.08 epoch/s, Train Loss=0.50529, Val Loss=0.53562, Best Val Loss=0.53051]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.5366531014442444, 0.924714207649231, 0.8558434844017029, 0.861431896686554, 0.0075612422078847885]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  5%|▌         | 540/10000 [08:22<2:26:45,  1.07 epoch/s, Train Loss=0.52666, Val Loss=0.54284, Best Val Loss=0.54089]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.5485472083091736, 0.9252132177352905, 0.8643383979797363, 0.8683487176895142, 0.008909287862479687]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  6%|▌         | 550/10000 [08:32<2:26:43,  1.07 epoch/s, Train Loss=0.53506, Val Loss=0.54975, Best Val Loss=0.54678]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.5486606955528259, 0.9231762886047363, 0.8642526268959045, 0.8684297800064087, 0.007785130757838488]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 850/10000 [13:11<2:21:56,  1.07 epoch/s, Train Loss=0.54796, Val Loss=0.54153, Best Val Loss=0.54087]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.5417060852050781, 0.9207606911659241, 0.8579028844833374, 0.8633663654327393, 0.00945206917822361]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 410/10000 [06:24<2:29:57,  1.07 epoch/s, Train Loss=0.61688, Val Loss=0.61699, Best Val Loss=0.61672]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.6167888045310974, 0.8654444813728333, 0.8625364899635315, 0.8625364899635315, 0.007519808132201433]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▎         | 350/10000 [05:25<2:29:43,  1.07 epoch/s, Train Loss=0.61691, Val Loss=0.61670, Best Val Loss=0.61669]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.6170387864112854, 0.8775614500045776, 0.8625364899635315, 0.8625364899635315, 0.009553056210279465]\n",
      "0 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 12%|█▏        | 1240/10000 [18:11<2:08:32,  1.14 epoch/s, Train Loss=0.49677, Val Loss=0.53153, Best Val Loss=0.52894]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 0, 0.5294579863548279, 0.9163013100624084, 0.8391968607902527, 0.8471701145172119, 0.008670616894960403]\n",
      "1 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 11%|█         | 1070/10000 [16:21<2:16:28,  1.09 epoch/s, Train Loss=0.50382, Val Loss=0.52853, Best Val Loss=0.52841]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 1, 0.5286852121353149, 0.918914258480072, 0.8438304662704468, 0.8509418368339539, 0.010061991401016712]\n",
      "2 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  7%|▋         | 730/10000 [11:08<2:21:31,  1.09 epoch/s, Train Loss=0.52059, Val Loss=0.54578, Best Val Loss=0.53824]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 2, 0.542860746383667, 0.9256891012191772, 0.8606486916542053, 0.8649142980575562, 0.00796513631939888]\n",
      "3 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      " 10%|█         | 1000/10000 [15:23<2:18:30,  1.08 epoch/s, Train Loss=0.53725, Val Loss=0.54480, Best Val Loss=0.54221]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 3, 0.5503114461898804, 0.9241350889205933, 0.8646816611289978, 0.8681989312171936, 0.00825896393507719]\n",
      "4 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 760/10000 [11:53<2:24:37,  1.06 epoch/s, Train Loss=0.54470, Val Loss=0.55217, Best Val Loss=0.54858]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 4, 0.5535990595817566, 0.9231387972831726, 0.8686287999153137, 0.8715280890464783, 0.008682179264724255]\n",
      "5 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 260/10000 [04:02<2:31:34,  1.07 epoch/s, Train Loss=0.61758, Val Loss=0.61775, Best Val Loss=0.61753]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 5, 0.617922842502594, 0.8706942796707153, 0.8625364899635315, 0.8625364899635315, 0.012791456654667854]\n",
      "6 {'n_atomics': 10, 'n_concepts': 4, 'use_summaries_for_atomics': True, 'noise_std': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  3%|▎         | 320/10000 [04:59<2:31:03,  1.07 epoch/s, Train Loss=0.61693, Val Loss=0.61689, Best Val Loss=0.61659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['atomics', 6, 0.6167578101158142, 0.8695791959762573, 0.8625364899635315, 0.8625364899635315, 0.007970292121171951]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for zzz in range(5):\n",
    "    for i, config in enumerate(all_config_permutations_atomics):\n",
    "        print(i, config)\n",
    "        \n",
    "        train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits, config.get(\"output_dim\"))#, batch_size=8)\n",
    "        \n",
    "        model = initializeModel_with_atomics(**config, input_dim=input_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=2)\n",
    "        model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(**config)+f\"{zzz}\", max_epochs=10000)\n",
    "        \n",
    "        cos_sim = ((model.cos_sim(model.layer_to_concepts) + model.cos_sim(model.layer_time_to_atomics)) \n",
    "                / (model.layer_to_concepts.out_features + model.layer_time_to_atomics.out_features)).item()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for Xb, yb in test_loader:\n",
    "                Xb, yb = Xb.to(device), yb.to(device)\n",
    "                probs = model.forward_probabilities(Xb)\n",
    "                \n",
    "                auc = auroc_metric(probs, yb).item()\n",
    "                acc = accuracy_metric(probs, yb).item()\n",
    "                f1 = f1_metric(probs, yb).item()\n",
    "                # conf_matrix(probs, yb)\n",
    "            auc = auroc_metric.compute().item()\n",
    "            acc = accuracy_metric.compute().item()\n",
    "            f1 = f1_metric.compute().item()\n",
    "            # conf_matrix.plot()\n",
    "            # plt.show()\n",
    "            auroc_metric.reset()\n",
    "            accuracy_metric.reset()\n",
    "            # conf_matrix.reset()\n",
    "            f1_metric.reset()\n",
    "\n",
    "        history = [\"atomics\", i, model.val_losses[-1], auc, acc, f1, cos_sim]\n",
    "        print(history)\n",
    "        history_atomics.append(np.array(history))\n",
    "        \n",
    "        # plot_losses(model.train_losses, model.val_losses)\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=[\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\", \"cos_sim\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float, 'cos_sim': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = pd.concat([df_og, pd.DataFrame(all_config_permutations_og)], axis=1)\n",
    "\n",
    "df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "df_atomics = pd.concat([df_atomics, pd.DataFrame(all_config_permutations_atomics)], axis=1)\n",
    "\n",
    "result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"type\", \"config\", \"val_loss\", \"auc\", \"acc\", \"f1\", \"cos_sim\"]\n",
    "dtypes = {'type': str, 'config': int, 'val_loss': float, 'auc': float, 'acc': float, 'f1': float, 'cos_sim': float}\n",
    "\n",
    "df_og = pd.DataFrame(histories_original, columns=columns).astype(dtypes)\n",
    "df_og = df_og.join(pd.DataFrame(all_config_permutations_og), on=\"config\", how=\"left\")\n",
    "\n",
    "df_atomics = pd.DataFrame(history_atomics, columns=columns).astype(dtypes)\n",
    "df_atomics = df_atomics.join(pd.DataFrame(all_config_permutations_atomics), on=\"config\", how=\"left\")\n",
    "\n",
    "result_df = pd.concat([df_og, df_atomics], ignore_index=True)\n",
    "# result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc 0.9143568277359009\n",
      "acc 0.8388535976409912\n",
      "f1 0.8469188213348389\n"
     ]
    }
   ],
   "source": [
    "for col in result_df.columns[3:6]:\n",
    "    baseline = result_df[(result_df['type'] == 'original') & (result_df['config'] == 0)][col].values[0]\n",
    "    print(col, baseline)\n",
    "    result_df[f'{col}_abs_imp'] = result_df[col] - baseline\n",
    "    # result_df[f'{col}_rel_imp'] = result_df[f'{col}_abs_imp'] / baseline\n",
    "# result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>config</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>cos_sim</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th>noise_std</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th>auc_abs_imp</th>\n",
       "      <th>acc_abs_imp</th>\n",
       "      <th>f1_abs_imp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560036</td>\n",
       "      <td>0.922935</td>\n",
       "      <td>0.870345</td>\n",
       "      <td>0.873334</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>0.026415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.553599</td>\n",
       "      <td>0.923139</td>\n",
       "      <td>0.868629</td>\n",
       "      <td>0.871528</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008782</td>\n",
       "      <td>0.029775</td>\n",
       "      <td>0.024609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.552156</td>\n",
       "      <td>0.922837</td>\n",
       "      <td>0.867342</td>\n",
       "      <td>0.871360</td>\n",
       "      <td>0.009221</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008481</td>\n",
       "      <td>0.028488</td>\n",
       "      <td>0.024441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.554395</td>\n",
       "      <td>0.924441</td>\n",
       "      <td>0.866484</td>\n",
       "      <td>0.869987</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.027630</td>\n",
       "      <td>0.023068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553069</td>\n",
       "      <td>0.924284</td>\n",
       "      <td>0.866055</td>\n",
       "      <td>0.869992</td>\n",
       "      <td>0.008293</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.027201</td>\n",
       "      <td>0.023074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>0.923966</td>\n",
       "      <td>0.865197</td>\n",
       "      <td>0.869116</td>\n",
       "      <td>0.008661</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.026343</td>\n",
       "      <td>0.022197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.550311</td>\n",
       "      <td>0.924135</td>\n",
       "      <td>0.864682</td>\n",
       "      <td>0.868199</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.025828</td>\n",
       "      <td>0.021280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.544848</td>\n",
       "      <td>0.923616</td>\n",
       "      <td>0.864424</td>\n",
       "      <td>0.868355</td>\n",
       "      <td>0.008153</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.025571</td>\n",
       "      <td>0.021436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.548547</td>\n",
       "      <td>0.925213</td>\n",
       "      <td>0.864338</td>\n",
       "      <td>0.868349</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>0.021430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.548661</td>\n",
       "      <td>0.923176</td>\n",
       "      <td>0.864253</td>\n",
       "      <td>0.868430</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.025399</td>\n",
       "      <td>0.021511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.616758</td>\n",
       "      <td>0.869579</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.007970</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.044778</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.616662</td>\n",
       "      <td>0.894242</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.020115</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617892</td>\n",
       "      <td>0.873044</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.041313</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617060</td>\n",
       "      <td>0.855259</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.059098</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616956</td>\n",
       "      <td>0.885396</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.028961</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617923</td>\n",
       "      <td>0.870694</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.012791</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.043663</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.616682</td>\n",
       "      <td>0.889588</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.024769</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.616985</td>\n",
       "      <td>0.888685</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025672</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616572</td>\n",
       "      <td>0.881462</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032895</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617528</td>\n",
       "      <td>0.863016</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.051341</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616962</td>\n",
       "      <td>0.893914</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.020443</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>atomics</td>\n",
       "      <td>3</td>\n",
       "      <td>0.616941</td>\n",
       "      <td>0.881427</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.008527</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.032930</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617276</td>\n",
       "      <td>0.878812</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.009403</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.035545</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616608</td>\n",
       "      <td>0.885343</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.552676</td>\n",
       "      <td>0.925800</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.866500</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011443</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.019581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.616786</td>\n",
       "      <td>0.889961</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617590</td>\n",
       "      <td>0.846932</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.010653</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.067425</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617148</td>\n",
       "      <td>0.882746</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031611</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617795</td>\n",
       "      <td>0.880448</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033909</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>atomics</td>\n",
       "      <td>5</td>\n",
       "      <td>0.616789</td>\n",
       "      <td>0.865444</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.048912</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>atomics</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617039</td>\n",
       "      <td>0.877561</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.009553</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>original</td>\n",
       "      <td>5</td>\n",
       "      <td>0.617234</td>\n",
       "      <td>0.873866</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.040491</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>original</td>\n",
       "      <td>6</td>\n",
       "      <td>0.617108</td>\n",
       "      <td>0.887244</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027112</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.015618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.548147</td>\n",
       "      <td>0.924123</td>\n",
       "      <td>0.862022</td>\n",
       "      <td>0.866178</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.023168</td>\n",
       "      <td>0.019260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.546963</td>\n",
       "      <td>0.923959</td>\n",
       "      <td>0.861164</td>\n",
       "      <td>0.865570</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.022310</td>\n",
       "      <td>0.018651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.542058</td>\n",
       "      <td>0.926910</td>\n",
       "      <td>0.860992</td>\n",
       "      <td>0.865649</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.022138</td>\n",
       "      <td>0.018731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.552063</td>\n",
       "      <td>0.921851</td>\n",
       "      <td>0.860820</td>\n",
       "      <td>0.865640</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.018721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.542861</td>\n",
       "      <td>0.925689</td>\n",
       "      <td>0.860649</td>\n",
       "      <td>0.864914</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>0.021795</td>\n",
       "      <td>0.017995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.550353</td>\n",
       "      <td>0.923328</td>\n",
       "      <td>0.860305</td>\n",
       "      <td>0.865053</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.018134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>atomics</td>\n",
       "      <td>2</td>\n",
       "      <td>0.539886</td>\n",
       "      <td>0.923831</td>\n",
       "      <td>0.859791</td>\n",
       "      <td>0.864376</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>0.017457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.548869</td>\n",
       "      <td>0.921916</td>\n",
       "      <td>0.859705</td>\n",
       "      <td>0.864619</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.020851</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.539926</td>\n",
       "      <td>0.924516</td>\n",
       "      <td>0.859362</td>\n",
       "      <td>0.865003</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010159</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.018084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.538792</td>\n",
       "      <td>0.927156</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.863336</td>\n",
       "      <td>0.008226</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012799</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.016417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.543633</td>\n",
       "      <td>0.922919</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.863268</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008562</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>0.016349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>atomics</td>\n",
       "      <td>4</td>\n",
       "      <td>0.541706</td>\n",
       "      <td>0.920761</td>\n",
       "      <td>0.857903</td>\n",
       "      <td>0.863366</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>0.016448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541238</td>\n",
       "      <td>0.924348</td>\n",
       "      <td>0.857731</td>\n",
       "      <td>0.862635</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009991</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>0.015716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>original</td>\n",
       "      <td>3</td>\n",
       "      <td>0.545109</td>\n",
       "      <td>0.924010</td>\n",
       "      <td>0.856015</td>\n",
       "      <td>0.860608</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.013689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536653</td>\n",
       "      <td>0.924714</td>\n",
       "      <td>0.855843</td>\n",
       "      <td>0.861432</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.014513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.537043</td>\n",
       "      <td>0.923021</td>\n",
       "      <td>0.855758</td>\n",
       "      <td>0.860764</td>\n",
       "      <td>0.005163</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.016904</td>\n",
       "      <td>0.013845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540021</td>\n",
       "      <td>0.923386</td>\n",
       "      <td>0.855500</td>\n",
       "      <td>0.860964</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009029</td>\n",
       "      <td>0.016647</td>\n",
       "      <td>0.014046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534355</td>\n",
       "      <td>0.924790</td>\n",
       "      <td>0.855329</td>\n",
       "      <td>0.860983</td>\n",
       "      <td>0.010589</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.014064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540488</td>\n",
       "      <td>0.924143</td>\n",
       "      <td>0.855243</td>\n",
       "      <td>0.860659</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.013740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.534889</td>\n",
       "      <td>0.921297</td>\n",
       "      <td>0.855157</td>\n",
       "      <td>0.860864</td>\n",
       "      <td>0.009253</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.016303</td>\n",
       "      <td>0.013945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>original</td>\n",
       "      <td>4</td>\n",
       "      <td>0.546315</td>\n",
       "      <td>0.920371</td>\n",
       "      <td>0.854814</td>\n",
       "      <td>0.860096</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.015960</td>\n",
       "      <td>0.013177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.537223</td>\n",
       "      <td>0.925147</td>\n",
       "      <td>0.854127</td>\n",
       "      <td>0.859481</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.012562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531284</td>\n",
       "      <td>0.923100</td>\n",
       "      <td>0.853012</td>\n",
       "      <td>0.858908</td>\n",
       "      <td>0.006569</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008743</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>0.011989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>original</td>\n",
       "      <td>2</td>\n",
       "      <td>0.540930</td>\n",
       "      <td>0.922774</td>\n",
       "      <td>0.852840</td>\n",
       "      <td>0.858557</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>0.011638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529551</td>\n",
       "      <td>0.920551</td>\n",
       "      <td>0.851210</td>\n",
       "      <td>0.857049</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.012356</td>\n",
       "      <td>0.010130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536521</td>\n",
       "      <td>0.922707</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.853777</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.006858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525201</td>\n",
       "      <td>0.921491</td>\n",
       "      <td>0.847349</td>\n",
       "      <td>0.854121</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.008495</td>\n",
       "      <td>0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>atomics</td>\n",
       "      <td>1</td>\n",
       "      <td>0.528685</td>\n",
       "      <td>0.918914</td>\n",
       "      <td>0.843830</td>\n",
       "      <td>0.850942</td>\n",
       "      <td>0.010062</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.004023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528895</td>\n",
       "      <td>0.920346</td>\n",
       "      <td>0.843659</td>\n",
       "      <td>0.850091</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536012</td>\n",
       "      <td>0.916393</td>\n",
       "      <td>0.839883</td>\n",
       "      <td>0.847499</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.529458</td>\n",
       "      <td>0.916301</td>\n",
       "      <td>0.839197</td>\n",
       "      <td>0.847170</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.526175</td>\n",
       "      <td>0.914357</td>\n",
       "      <td>0.838854</td>\n",
       "      <td>0.846919</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "      <td>0.523248</td>\n",
       "      <td>0.916118</td>\n",
       "      <td>0.838596</td>\n",
       "      <td>0.846336</td>\n",
       "      <td>0.004270</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>-0.000583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.540015</td>\n",
       "      <td>0.915980</td>\n",
       "      <td>0.837996</td>\n",
       "      <td>0.845752</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>atomics</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536768</td>\n",
       "      <td>0.910919</td>\n",
       "      <td>0.830273</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.011248</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.003438</td>\n",
       "      <td>-0.008581</td>\n",
       "      <td>-0.007315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525005</td>\n",
       "      <td>0.903111</td>\n",
       "      <td>0.822035</td>\n",
       "      <td>0.830804</td>\n",
       "      <td>0.003767</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011246</td>\n",
       "      <td>-0.016818</td>\n",
       "      <td>-0.016114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>original</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528440</td>\n",
       "      <td>0.901072</td>\n",
       "      <td>0.816801</td>\n",
       "      <td>0.827419</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013285</td>\n",
       "      <td>-0.022053</td>\n",
       "      <td>-0.019500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        type  config  val_loss       auc       acc        f1   cos_sim  \\\n",
       "39   atomics       4  0.560036  0.922935  0.870345  0.873334  0.009542   \n",
       "67   atomics       4  0.553599  0.923139  0.868629  0.871528  0.008682   \n",
       "46   atomics       4  0.552156  0.922837  0.867342  0.871360  0.009221   \n",
       "51   atomics       2  0.554395  0.924441  0.866484  0.869987  0.008905   \n",
       "52   atomics       3  0.553069  0.924284  0.866055  0.869992  0.008293   \n",
       "37   atomics       2  0.546683  0.923966  0.865197  0.869116  0.008661   \n",
       "66   atomics       3  0.550311  0.924135  0.864682  0.868199  0.008259   \n",
       "45   atomics       3  0.544848  0.923616  0.864424  0.868355  0.008153   \n",
       "58   atomics       2  0.548547  0.925213  0.864338  0.868349  0.008909   \n",
       "59   atomics       3  0.548661  0.923176  0.864253  0.868430  0.007785   \n",
       "69   atomics       6  0.616758  0.869579  0.862536  0.862536  0.007970   \n",
       "13  original       6  0.616662  0.894242  0.862536  0.862536  0.001360   \n",
       "12  original       5  0.617892  0.873044  0.862536  0.862536  0.011561   \n",
       "55   atomics       6  0.617060  0.855259  0.862536  0.862536  0.008112   \n",
       "54   atomics       5  0.616956  0.885396  0.862536  0.862536  0.008447   \n",
       "68   atomics       5  0.617923  0.870694  0.862536  0.862536  0.012791   \n",
       "53   atomics       4  0.616682  0.889588  0.862536  0.862536  0.007702   \n",
       "20  original       6  0.616985  0.888685  0.862536  0.862536  0.003024   \n",
       "19  original       5  0.616572  0.881462  0.862536  0.862536  0.005410   \n",
       "48   atomics       6  0.617528  0.863016  0.862536  0.862536  0.011129   \n",
       "47   atomics       5  0.616962  0.893914  0.862536  0.862536  0.007364   \n",
       "38   atomics       3  0.616941  0.881427  0.862536  0.862536  0.008527   \n",
       "40   atomics       5  0.617276  0.878812  0.862536  0.862536  0.009403   \n",
       "26  original       5  0.616608  0.885343  0.862536  0.862536  0.002693   \n",
       "24  original       3  0.552676  0.925800  0.862536  0.866500  0.001586   \n",
       "27  original       6  0.616786  0.889961  0.862536  0.862536  0.002256   \n",
       "41   atomics       6  0.617590  0.846932  0.862536  0.862536  0.010653   \n",
       "34  original       6  0.617148  0.882746  0.862536  0.862536  0.001192   \n",
       "33  original       5  0.617795  0.880448  0.862536  0.862536  0.009741   \n",
       "61   atomics       5  0.616789  0.865444  0.862536  0.862536  0.007520   \n",
       "62   atomics       6  0.617039  0.877561  0.862536  0.862536  0.009553   \n",
       "5   original       5  0.617234  0.873866  0.862536  0.862536  0.003099   \n",
       "6   original       6  0.617108  0.887244  0.862536  0.862536  0.000953   \n",
       "11  original       4  0.548147  0.924123  0.862022  0.866178  0.011376   \n",
       "25  original       4  0.546963  0.923959  0.861164  0.865570  0.002786   \n",
       "9   original       2  0.542058  0.926910  0.860992  0.865649  0.008535   \n",
       "32  original       4  0.552063  0.921851  0.860820  0.865640  0.002445   \n",
       "65   atomics       2  0.542861  0.925689  0.860649  0.864914  0.007965   \n",
       "10  original       3  0.550353  0.923328  0.860305  0.865053  0.006695   \n",
       "44   atomics       2  0.539886  0.923831  0.859791  0.864376  0.008880   \n",
       "18  original       4  0.548869  0.921916  0.859705  0.864619  0.001672   \n",
       "17  original       3  0.539926  0.924516  0.859362  0.865003  0.005338   \n",
       "2   original       2  0.538792  0.927156  0.858246  0.863336  0.008226   \n",
       "3   original       3  0.543633  0.922919  0.858246  0.863268  0.007553   \n",
       "60   atomics       4  0.541706  0.920761  0.857903  0.863366  0.009452   \n",
       "23  original       2  0.541238  0.924348  0.857731  0.862635  0.011238   \n",
       "31  original       3  0.545109  0.924010  0.856015  0.860608  0.003193   \n",
       "57   atomics       1  0.536653  0.924714  0.855843  0.861432  0.007561   \n",
       "16  original       2  0.537043  0.923021  0.855758  0.860764  0.005163   \n",
       "43   atomics       1  0.540021  0.923386  0.855500  0.860964  0.007919   \n",
       "49   atomics       0  0.534355  0.924790  0.855329  0.860983  0.010589   \n",
       "36   atomics       1  0.540488  0.924143  0.855243  0.860659  0.007816   \n",
       "50   atomics       1  0.534889  0.921297  0.855157  0.860864  0.009253   \n",
       "4   original       4  0.546315  0.920371  0.854814  0.860096  0.006977   \n",
       "1   original       1  0.537223  0.925147  0.854127  0.859481  0.002857   \n",
       "29  original       1  0.531284  0.923100  0.853012  0.858908  0.006569   \n",
       "30  original       2  0.540930  0.922774  0.852840  0.858557  0.002503   \n",
       "14  original       0  0.529551  0.920551  0.851210  0.857049  0.006247   \n",
       "22  original       1  0.536521  0.922707  0.847692  0.853777  0.003346   \n",
       "8   original       1  0.525201  0.921491  0.847349  0.854121  0.004022   \n",
       "64   atomics       1  0.528685  0.918914  0.843830  0.850942  0.010062   \n",
       "28  original       0  0.528895  0.920346  0.843659  0.850091  0.005986   \n",
       "56   atomics       0  0.536012  0.916393  0.839883  0.847499  0.008933   \n",
       "63   atomics       0  0.529458  0.916301  0.839197  0.847170  0.008671   \n",
       "0   original       0  0.526175  0.914357  0.838854  0.846919  0.001396   \n",
       "15  original       1  0.523248  0.916118  0.838596  0.846336  0.004270   \n",
       "35   atomics       0  0.540015  0.915980  0.837996  0.845752  0.009829   \n",
       "42   atomics       0  0.536768  0.910919  0.830273  0.839604  0.011248   \n",
       "21  original       0  0.525005  0.903111  0.822035  0.830804  0.003767   \n",
       "7   original       0  0.528440  0.901072  0.816801  0.827419  0.001558   \n",
       "\n",
       "    n_concepts  noise_std  n_atomics use_summaries_for_atomics  auc_abs_imp  \\\n",
       "39           4        1.0       10.0                      True     0.008579   \n",
       "67           4        1.0       10.0                      True     0.008782   \n",
       "46           4        1.0       10.0                      True     0.008481   \n",
       "51           4        0.5       10.0                      True     0.010084   \n",
       "52           4        0.7       10.0                      True     0.009927   \n",
       "37           4        0.5       10.0                      True     0.009609   \n",
       "66           4        0.7       10.0                      True     0.009778   \n",
       "45           4        0.7       10.0                      True     0.009259   \n",
       "58           4        0.5       10.0                      True     0.010856   \n",
       "59           4        0.7       10.0                      True     0.008819   \n",
       "69           4       10.0       10.0                      True    -0.044778   \n",
       "13           4       10.0        NaN                       NaN    -0.020115   \n",
       "12           4        5.0        NaN                       NaN    -0.041313   \n",
       "55           4       10.0       10.0                      True    -0.059098   \n",
       "54           4        5.0       10.0                      True    -0.028961   \n",
       "68           4        5.0       10.0                      True    -0.043663   \n",
       "53           4        1.0       10.0                      True    -0.024769   \n",
       "20           4       10.0        NaN                       NaN    -0.025672   \n",
       "19           4        5.0        NaN                       NaN    -0.032895   \n",
       "48           4       10.0       10.0                      True    -0.051341   \n",
       "47           4        5.0       10.0                      True    -0.020443   \n",
       "38           4        0.7       10.0                      True    -0.032930   \n",
       "40           4        5.0       10.0                      True    -0.035545   \n",
       "26           4        5.0        NaN                       NaN    -0.029013   \n",
       "24           4        0.7        NaN                       NaN     0.011443   \n",
       "27           4       10.0        NaN                       NaN    -0.024396   \n",
       "41           4       10.0       10.0                      True    -0.067425   \n",
       "34           4       10.0        NaN                       NaN    -0.031611   \n",
       "33           4        5.0        NaN                       NaN    -0.033909   \n",
       "61           4        5.0       10.0                      True    -0.048912   \n",
       "62           4       10.0       10.0                      True    -0.036795   \n",
       "5            4        5.0        NaN                       NaN    -0.040491   \n",
       "6            4       10.0        NaN                       NaN    -0.027112   \n",
       "11           4        1.0        NaN                       NaN     0.009766   \n",
       "25           4        1.0        NaN                       NaN     0.009603   \n",
       "9            4        0.5        NaN                       NaN     0.012554   \n",
       "32           4        1.0        NaN                       NaN     0.007494   \n",
       "65           4        0.5       10.0                      True     0.011332   \n",
       "10           4        0.7        NaN                       NaN     0.008971   \n",
       "44           4        0.5       10.0                      True     0.009474   \n",
       "18           4        1.0        NaN                       NaN     0.007559   \n",
       "17           4        0.7        NaN                       NaN     0.010159   \n",
       "2            4        0.5        NaN                       NaN     0.012799   \n",
       "3            4        0.7        NaN                       NaN     0.008562   \n",
       "60           4        1.0       10.0                      True     0.006404   \n",
       "23           4        0.5        NaN                       NaN     0.009991   \n",
       "31           4        0.7        NaN                       NaN     0.009653   \n",
       "57           4        0.2       10.0                      True     0.010357   \n",
       "16           4        0.5        NaN                       NaN     0.008664   \n",
       "43           4        0.2       10.0                      True     0.009029   \n",
       "49           4        NaN       10.0                      True     0.010433   \n",
       "36           4        0.2       10.0                      True     0.009786   \n",
       "50           4        0.2       10.0                      True     0.006940   \n",
       "4            4        1.0        NaN                       NaN     0.006014   \n",
       "1            4        0.2        NaN                       NaN     0.010790   \n",
       "29           4        0.2        NaN                       NaN     0.008743   \n",
       "30           4        0.5        NaN                       NaN     0.008417   \n",
       "14           4        NaN        NaN                       NaN     0.006194   \n",
       "22           4        0.2        NaN                       NaN     0.008350   \n",
       "8            4        0.2        NaN                       NaN     0.007134   \n",
       "64           4        0.2       10.0                      True     0.004557   \n",
       "28           4        NaN        NaN                       NaN     0.005989   \n",
       "56           4        NaN       10.0                      True     0.002036   \n",
       "63           4        NaN       10.0                      True     0.001944   \n",
       "0            4        NaN        NaN                       NaN     0.000000   \n",
       "15           4        0.2        NaN                       NaN     0.001761   \n",
       "35           4        NaN       10.0                      True     0.001623   \n",
       "42           4        NaN       10.0                      True    -0.003438   \n",
       "21           4        NaN        NaN                       NaN    -0.011246   \n",
       "7            4        NaN        NaN                       NaN    -0.013285   \n",
       "\n",
       "    acc_abs_imp  f1_abs_imp  \n",
       "39     0.031491    0.026415  \n",
       "67     0.029775    0.024609  \n",
       "46     0.028488    0.024441  \n",
       "51     0.027630    0.023068  \n",
       "52     0.027201    0.023074  \n",
       "37     0.026343    0.022197  \n",
       "66     0.025828    0.021280  \n",
       "45     0.025571    0.021436  \n",
       "58     0.025485    0.021430  \n",
       "59     0.025399    0.021511  \n",
       "69     0.023683    0.015618  \n",
       "13     0.023683    0.015618  \n",
       "12     0.023683    0.015618  \n",
       "55     0.023683    0.015618  \n",
       "54     0.023683    0.015618  \n",
       "68     0.023683    0.015618  \n",
       "53     0.023683    0.015618  \n",
       "20     0.023683    0.015618  \n",
       "19     0.023683    0.015618  \n",
       "48     0.023683    0.015618  \n",
       "47     0.023683    0.015618  \n",
       "38     0.023683    0.015618  \n",
       "40     0.023683    0.015618  \n",
       "26     0.023683    0.015618  \n",
       "24     0.023683    0.019581  \n",
       "27     0.023683    0.015618  \n",
       "41     0.023683    0.015618  \n",
       "34     0.023683    0.015618  \n",
       "33     0.023683    0.015618  \n",
       "61     0.023683    0.015618  \n",
       "62     0.023683    0.015618  \n",
       "5      0.023683    0.015618  \n",
       "6      0.023683    0.015618  \n",
       "11     0.023168    0.019260  \n",
       "25     0.022310    0.018651  \n",
       "9      0.022138    0.018731  \n",
       "32     0.021967    0.018721  \n",
       "65     0.021795    0.017995  \n",
       "10     0.021452    0.018134  \n",
       "44     0.020937    0.017457  \n",
       "18     0.020851    0.017700  \n",
       "17     0.020508    0.018084  \n",
       "2      0.019392    0.016417  \n",
       "3      0.019392    0.016349  \n",
       "60     0.019049    0.016448  \n",
       "23     0.018878    0.015716  \n",
       "31     0.017161    0.013689  \n",
       "57     0.016990    0.014513  \n",
       "16     0.016904    0.013845  \n",
       "43     0.016647    0.014046  \n",
       "49     0.016475    0.014064  \n",
       "36     0.016389    0.013740  \n",
       "50     0.016303    0.013945  \n",
       "4      0.015960    0.013177  \n",
       "1      0.015274    0.012562  \n",
       "29     0.014158    0.011989  \n",
       "30     0.013987    0.011638  \n",
       "14     0.012356    0.010130  \n",
       "22     0.008838    0.006858  \n",
       "8      0.008495    0.007202  \n",
       "64     0.004977    0.004023  \n",
       "28     0.004805    0.003172  \n",
       "56     0.001030    0.000580  \n",
       "63     0.000343    0.000251  \n",
       "0      0.000000    0.000000  \n",
       "15    -0.000257   -0.000583  \n",
       "35    -0.000858   -0.001167  \n",
       "42    -0.008581   -0.007315  \n",
       "21    -0.016818   -0.016114  \n",
       "7     -0.022053   -0.019500  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "result_df.sort_values(by='acc', ascending=False)\n",
    "# atomics: atomics, concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics\n",
    "# original: concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <th>10.0</th>\n",
       "      <td>0.905214</td>\n",
       "      <td>0.858822</td>\n",
       "      <td>0.862218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.910344</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.858964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc       acc        f1\n",
       "type     n_atomics                              \n",
       "atomics  10.0       0.905214  0.858822  0.862218\n",
       "original NaN        0.910344  0.854836  0.858964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>n_concepts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <th>4</th>\n",
       "      <td>0.905214</td>\n",
       "      <td>0.858822</td>\n",
       "      <td>0.862218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th>4</th>\n",
       "      <td>0.910344</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.858964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          auc       acc        f1\n",
       "type     n_concepts                              \n",
       "atomics  4           0.905214  0.858822  0.862218\n",
       "original 4           0.910344  0.854836  0.858964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>noise_std</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">atomics</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.922491</td>\n",
       "      <td>0.853115</td>\n",
       "      <td>0.858972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.924628</td>\n",
       "      <td>0.863292</td>\n",
       "      <td>0.867348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.915328</td>\n",
       "      <td>0.864390</td>\n",
       "      <td>0.867503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.915852</td>\n",
       "      <td>0.865351</td>\n",
       "      <td>0.868425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.878852</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.862470</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.916876</td>\n",
       "      <td>0.840535</td>\n",
       "      <td>0.848202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">original</th>\n",
       "      <th>0.2</th>\n",
       "      <td>0.921712</td>\n",
       "      <td>0.848155</td>\n",
       "      <td>0.854524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.924842</td>\n",
       "      <td>0.857113</td>\n",
       "      <td>0.862188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.924115</td>\n",
       "      <td>0.859293</td>\n",
       "      <td>0.864086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.922444</td>\n",
       "      <td>0.859705</td>\n",
       "      <td>0.864421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.878832</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.888575</td>\n",
       "      <td>0.862536</td>\n",
       "      <td>0.862536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.911887</td>\n",
       "      <td>0.834512</td>\n",
       "      <td>0.842456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         auc       acc        f1\n",
       "type     noise_std                              \n",
       "atomics  0.2        0.922491  0.853115  0.858972\n",
       "         0.5        0.924628  0.863292  0.867348\n",
       "         0.7        0.915328  0.864390  0.867503\n",
       "         1.0        0.915852  0.865351  0.868425\n",
       "         5.0        0.878852  0.862536  0.862536\n",
       "         10.0       0.862470  0.862536  0.862536\n",
       "         NaN        0.916876  0.840535  0.848202\n",
       "original 0.2        0.921712  0.848155  0.854524\n",
       "         0.5        0.924842  0.857113  0.862188\n",
       "         0.7        0.924115  0.859293  0.864086\n",
       "         1.0        0.922444  0.859705  0.864421\n",
       "         5.0        0.878832  0.862536  0.862536\n",
       "         10.0       0.888575  0.862536  0.862536\n",
       "         NaN        0.911887  0.834512  0.842456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>use_summaries_for_atomics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <th>True</th>\n",
       "      <td>0.905214</td>\n",
       "      <td>0.858822</td>\n",
       "      <td>0.862218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <th>NaN</th>\n",
       "      <td>0.910344</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.858964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         auc       acc        f1\n",
       "type     use_summaries_for_atomics                              \n",
       "atomics  True                       0.905214  0.858822  0.862218\n",
       "original NaN                        0.910344  0.854836  0.858964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>atomics</th>\n",
       "      <td>0.905214</td>\n",
       "      <td>0.858822</td>\n",
       "      <td>0.862218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.910344</td>\n",
       "      <td>0.854836</td>\n",
       "      <td>0.858964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               auc       acc        f1\n",
       "type                                  \n",
       "atomics   0.905214  0.858822  0.862218\n",
       "original  0.910344  0.854836  0.858964"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in sorted(set(list(all_config_permutations_og[0].keys()) + list(all_config_permutations_atomics[0].keys()))):\n",
    "    display(result_df.groupby([\"type\", key], dropna=False)[[\"auc\", \"acc\", \"f1\"]].mean())\n",
    "\n",
    "display(result_df.groupby(\"type\")[[\"auc\", \"acc\", \"f1\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
