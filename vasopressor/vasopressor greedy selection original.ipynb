{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "current device cuda:8\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "import random\n",
                "import csv\n",
                "import matplotlib.pyplot as plt\n",
                "import torch\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "from torch.autograd import Variable\n",
                "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
                "import os, subprocess, gc, time, datetime\n",
                "from itertools import product\n",
                "\n",
                "import models.models_original as models_original\n",
                "import models.models_3d_atomics as models_3d_atomics\n",
                "import models.models_3d as models_3d\n",
                "from models.data import *\n",
                "from models.helper import *\n",
                "from models.param_initializations import *\n",
                "from models.optimization_strategy import *\n",
                "\n",
                "device = get_free_gpu()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([0.5797, 3.6376], dtype=torch.float64) 2 6\n",
                        "torch.Size([512, 6, 27]) cpu\n",
                        "torch.Size([512, 6, 27]) cpu\n",
                        "torch.Size([512, 8]) cpu\n",
                        "torch.Size([512, 2]) cpu\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "35"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "train_loader, val_loader, test_loader, class_weights, num_classes, changing_dim, static_dim, seq_len = get_MIMIC_dataloader(output_dim = 2, batch_size = 512, random_state = 1)\n",
                "\n",
                "print(class_weights, num_classes, seq_len)\n",
                "\n",
                "for batch in train_loader:\n",
                "    [print(t.shape, t.device) for t in batch]\n",
                "    break\n",
                "\n",
                "len(train_loader)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "auroc_metric = AUROC(task=\"binary\").to(device)\n",
                "accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
                "f1_metric = F1Score(task=\"binary\").to(device)\n",
                "conf_matrix = ConfusionMatrix(task=\"binary\").to(device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "27 8 6\n"
                    ]
                }
            ],
            "source": [
                "print(changing_dim, static_dim, seq_len)\n",
                "\n",
                "random_seed = 1\n",
                "set_seed(random_seed)\n",
                "\n",
                "experiment_folder = \"/workdir/optimal-summaries-public/_models/vasopressor/original/\"\n",
                "top_k_file = experiment_folder + \"top-k/bottleneck_topkinds_seed_{seed}.csv\"\n",
                "makedir(top_k_file)\n",
                "\n",
                "random_seeds = range(1,4)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Optimization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_1.pt\n",
                        "AUC macro 0.915\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n"
                    ]
                }
            ],
            "source": [
                "def get_model(random_seed):\n",
                "    set_seed(random_seed)\n",
                "\n",
                "    config = {\n",
                "        \"n_concepts\": 4,\n",
                "    }\n",
                "\n",
                "    makedir(experiment_folder)\n",
                "    model_path = get_filename_from_dict(experiment_folder, config)\n",
                "    model_path = model_path.format(**config, seed = random_seed)\n",
                "\n",
                "    train_loader, val_loader, test_loader, class_weights, num_classes, changing_dim, static_dim, seq_len = get_MIMIC_dataloader(random_state = random_seed)\n",
                "\n",
                "    model = models_original.CBM(**config, static_dim=static_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=2, device=device)\n",
                "    model.try_load_else_fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path, max_epochs=10000)\n",
                "\n",
                "    evaluate_classification(model, test_loader)\n",
                "    return model\n",
                "\n",
                "model = get_model(1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "visualize_top100_weights_per_channel(model.bottleneck)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "random_seed 1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_1.pt\n",
                        "AUC macro 0.915\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "Found 4 Concepts\n",
                        "90th percentile per concept [8.141751  0.8794138 4.321822  7.642881 ]\n",
                        "['Concept 0 len: 79', 'Concept 1 len: 272', 'Concept 2 len: 77', 'Concept 3 len: 71']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 40/40 [4:08:22<00:00, 372.57s/it, Score=0.91963, acc=0.858, f1=0.863, auc=0.92]   \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "random_seed 2\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_2.pt\n",
                        "AUC macro 0.921\n",
                        "ACC macro 0.844\n",
                        " F1 macro 0.852\n",
                        "Found 4 Concepts\n",
                        "90th percentile per concept [ 0.28210557 10.270896    6.4929314   2.3336902 ]\n",
                        "['Concept 0 len: 299', 'Concept 1 len: 95', 'Concept 2 len: 105', 'Concept 3 len: 150']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 40/40 [5:18:27<00:00, 477.68s/it, Score=0.92956, acc=0.842, f1=0.855, auc=0.93]   \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "random_seed 3\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_3.pt\n",
                        "AUC macro 0.914\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "Found 4 Concepts\n",
                        "90th percentile per concept [1.3721063  9.55452    0.41133872 7.4182534 ]\n",
                        "['Concept 0 len: 239', 'Concept 1 len: 81', 'Concept 2 len: 295', 'Concept 3 len: 72']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 40/40 [5:24:46<00:00, 487.17s/it, Score=0.92909, acc=0.858, f1=0.865, auc=0.929]  \n"
                    ]
                }
            ],
            "source": [
                "track_metrics={\"acc\": accuracy_metric,\n",
                "               \"f1\": f1_metric,\n",
                "               \"auc\": auroc_metric,\n",
                "               }\n",
                "\n",
                "results = []\n",
                "for random_seed in random_seeds:\n",
                "    print(\"random_seed\", random_seed)\n",
                "    model = get_model(random_seed)\n",
                "    train_loader, val_loader, test_loader, class_weights, num_classes, changing_dim, static_dim, seq_len = get_MIMIC_dataloader(random_state = random_seed)\n",
                "    top_k_inds = [get_top_features_per_concept(layer) for layer in model.regularized_layers]\n",
                "    save_path = top_k_file.format(seed=random_seed)\n",
                "    \n",
                "    greedy_results = greedy_forward_selection(model=model, layers_to_prune=model.regularized_layers, top_k_inds=top_k_inds, val_loader=val_loader, optimize_metric=auroc_metric, track_metrics=track_metrics, save_path=save_path)\n",
                "    results.append(greedy_results)\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "random_seed = 1\n",
                "model = get_model(random_seed)\n",
                "top_k_inds = get_top_features_per_concept(model.bottleneck)\n",
                "greedy_results = read_df_from_csv(top_k_file.format(seed=random_seed))\n",
                "\n",
                "pd.set_option('display.max_rows', 100)\n",
                "\n",
                "print(len(top_k_inds))\n",
                "[print(x) for x in top_k_inds]\n",
                "greedy_results\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_selected_weights(model.bottleneck.weight, top_k_inds, greedy_results, 100)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_1.pt\n",
                        "AUC macro 0.915\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "AUC macro 0.914\n",
                        "ACC macro 0.839\n",
                        " F1 macro 0.846\n",
                        "AUC macro 0.915\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "AUC macro 0.920\n",
                        "ACC macro 0.858\n",
                        " F1 macro 0.863\n",
                        "AUC macro 0.916\n",
                        "ACC macro 0.858\n",
                        " F1 macro 0.863\n",
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/finetuned/n_concepts_4_seed_1.pt\n",
                        "AUC macro 0.909\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.844\n",
                        "AUC macro 0.909\n",
                        "ACC macro 0.842\n",
                        " F1 macro 0.848\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_2.pt\n",
                        "AUC macro 0.921\n",
                        "ACC macro 0.844\n",
                        " F1 macro 0.852\n",
                        "AUC macro 0.923\n",
                        "ACC macro 0.848\n",
                        " F1 macro 0.856\n",
                        "AUC macro 0.921\n",
                        "ACC macro 0.844\n",
                        " F1 macro 0.852\n",
                        "AUC macro 0.930\n",
                        "ACC macro 0.842\n",
                        " F1 macro 0.855\n",
                        "AUC macro 0.926\n",
                        "ACC macro 0.836\n",
                        " F1 macro 0.850\n",
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/finetuned/n_concepts_4_seed_2.pt\n",
                        "AUC macro 0.922\n",
                        "ACC macro 0.852\n",
                        " F1 macro 0.859\n",
                        "AUC macro 0.917\n",
                        "ACC macro 0.848\n",
                        " F1 macro 0.855\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
                        "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/n_concepts_4_seed_3.pt\n",
                        "AUC macro 0.914\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "AUC macro 0.920\n",
                        "ACC macro 0.843\n",
                        " F1 macro 0.850\n",
                        "AUC macro 0.914\n",
                        "ACC macro 0.837\n",
                        " F1 macro 0.845\n",
                        "AUC macro 0.929\n",
                        "ACC macro 0.858\n",
                        " F1 macro 0.865\n",
                        "AUC macro 0.923\n",
                        "ACC macro 0.855\n",
                        " F1 macro 0.862\n",
                        "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/finetuned/n_concepts_4_seed_3.pt\n",
                        "AUC macro 0.924\n",
                        "ACC macro 0.852\n",
                        " F1 macro 0.859\n",
                        "AUC macro 0.915\n",
                        "ACC macro 0.846\n",
                        " F1 macro 0.853\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th>Seed</th>\n",
                            "      <th>AUC</th>\n",
                            "      <th>ACC</th>\n",
                            "      <th>F1</th>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Split</th>\n",
                            "      <th>Mask</th>\n",
                            "      <th>Finetuned</th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "      <th></th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th rowspan=\"3\" valign=\"top\">test</th>\n",
                            "      <th>Empty</th>\n",
                            "      <th>False</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.916475</td>\n",
                            "      <td>0.839654</td>\n",
                            "      <td>0.847360</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th rowspan=\"2\" valign=\"top\">Greedy</th>\n",
                            "      <th>False</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.921804</td>\n",
                            "      <td>0.849551</td>\n",
                            "      <td>0.858044</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>True</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.913676</td>\n",
                            "      <td>0.845146</td>\n",
                            "      <td>0.852178</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th rowspan=\"3\" valign=\"top\">val</th>\n",
                            "      <th>Empty</th>\n",
                            "      <th>False</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.919034</td>\n",
                            "      <td>0.843257</td>\n",
                            "      <td>0.850629</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th rowspan=\"2\" valign=\"top\">Greedy</th>\n",
                            "      <th>False</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.926095</td>\n",
                            "      <td>0.852808</td>\n",
                            "      <td>0.860713</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>True</th>\n",
                            "      <td>2.0</td>\n",
                            "      <td>0.918211</td>\n",
                            "      <td>0.847032</td>\n",
                            "      <td>0.853861</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                        Seed       AUC       ACC        F1\n",
                            "Split Mask   Finetuned                                    \n",
                            "test  Empty  False       2.0  0.916475  0.839654  0.847360\n",
                            "      Greedy False       2.0  0.921804  0.849551  0.858044\n",
                            "             True        2.0  0.913676  0.845146  0.852178\n",
                            "val   Empty  False       2.0  0.919034  0.843257  0.850629\n",
                            "      Greedy False       2.0  0.926095  0.852808  0.860713\n",
                            "             True        2.0  0.918211  0.847032  0.853861"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result_df = evaluate_greedy_selection(get_model, get_MIMIC_dataloader, top_k_file, n_experiments=3)\n",
                "result_df.groupby([\"Split\", \"Mask\", \"Finetuned\"]).mean()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def aggregate_greedy_results(top_k_file):\n",
                "    metrics = [\"AUC\", \"ACC\", \"F1\"]\n",
                "    aggregated_metrics_df = read_df_from_csv(top_k_file.format(seed=1))\n",
                "    aggregated_metrics_df = aggregated_metrics_df[[metrics]]\n",
                "\n",
                "    seeds = range(2, 4)\n",
                "\n",
                "    for random_seed in random_seeds:\n",
                "        greedy_results = read_df_from_csv(top_k_file.format(seed=seed))\n",
                "        greedy_results = greedy_results[[metrics]]\n",
                "            \n",
                "        aggregated_metrics_df += greedy_results\n",
                "\n",
                "    aggregated_metrics_df /= (len(seeds)+1)\n",
                "\n",
                "    return aggregated_metrics_df\n",
                "\n",
                "aggregate_greedy_results(top_k_file)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
