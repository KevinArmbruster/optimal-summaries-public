{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device cuda:15\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.classification import AUROC, Accuracy, ConfusionMatrix, F1Score\n",
    "import os, subprocess, gc, time, datetime\n",
    "from itertools import product\n",
    "\n",
    "import models.original_models as original_models\n",
    "import models.models_3d_atomics_on_variate_to_concepts as new_models\n",
    "from vasopressor.preprocess_helpers import *\n",
    "from models.helper import *\n",
    "from models.param_initializations import *\n",
    "from models.optimization_strategy import greedy_selection\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "gpu_id = int(subprocess.check_output('nvidia-smi --query-gpu=memory.free --format=csv,nounits,noheader | nl -v 0 | sort -nrk 2 | cut -f 1 | head -n 1 | xargs', shell=True, text=True))\n",
    "device = torch.device(f'cuda:{gpu_id}') if torch.cuda.is_available else torch.device('cpu')\n",
    "print(\"current device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29137, 6, 62)\n",
      "(29137, 2)\n",
      "(29137, 1)\n",
      "27 ['dbp', 'fio2', 'GCS', 'hr', 'map', 'sbp', 'spontaneousrr', 'spo2', 'temp', 'bun', 'magnesium', 'platelets', 'sodium', 'alt', 'hct', 'po2', 'ast', 'potassium', 'wbc', 'bicarbonate', 'creatinine', 'lactate', 'pco2', 'glucose', 'inr', 'hgb', 'bilirubin_total']\n"
     ]
    }
   ],
   "source": [
    "X, Y_logits, changing_vars, _ = myPreprocessed()\n",
    "print(X.shape)\n",
    "print(Y_logits.shape) # (logit, original)\n",
    "y = Y_logits[:, 1, None]\n",
    "print(y.shape)\n",
    "print(len(changing_vars), changing_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(y, bins=len(np.unique(y)), edgecolor='black')\n",
    "plt.xticks(np.unique(y))\n",
    "\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(_X, _Y_logits, output_dim, batch_size = 512, random_state = 1):\n",
    "    \n",
    "    # ## target\n",
    "    y = _Y_logits\n",
    "    if output_dim == 1:\n",
    "        y = _Y_logits[:, 1, None]\n",
    "    \n",
    "    y_unique = np.unique(y)\n",
    "    num_classes = len(y_unique)\n",
    "    \n",
    "    # # class weights\n",
    "    class_weights = compute_class_weight(class_weight=\"balanced\", classes=y_unique, y=_Y_logits[:, 1])\n",
    "    class_weights = torch.tensor(class_weights)\n",
    "    \n",
    "    if output_dim == 1:\n",
    "        class_weights = class_weights[1]/class_weights[0] # == pos / neg   # get ONLY positive sample weights\n",
    "    \n",
    "    \n",
    "    # split 60/20/20 %\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, y, test_size = 0.40, random_state = random_state, stratify = y)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = random_state, stratify = y_test)\n",
    "\n",
    "    # tensor\n",
    "    X_train_pt = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_pt = torch.tensor(y_train)\n",
    "\n",
    "    X_val_pt = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_pt = torch.tensor(y_val)\n",
    "\n",
    "    X_test_pt = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_pt = torch.tensor(y_test)\n",
    "    \n",
    "    # dataloader\n",
    "    train_dataset = TensorDataset(X_train_pt, y_train_pt)\n",
    "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val_pt, y_val_pt)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = X_val_pt.shape[0], shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    test_dataset = TensorDataset(X_test_pt, y_test_pt)\n",
    "    test_loader = DataLoader(test_dataset, batch_size = X_test_pt.shape[0], shuffle=False, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader, class_weights, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.2752, dtype=torch.float64) 2\n",
      "torch.Size([512, 6, 62]) cpu\n",
      "torch.Size([512, 1]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits, 1)\n",
    "\n",
    "print(class_weights, num_classes)\n",
    "\n",
    "for a,b in train_loader:\n",
    "    print(a.shape, a.device)\n",
    "    print(b.shape, b.device)\n",
    "    break\n",
    "\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.plot(train_losses, color=\"black\", label=\"Train\")\n",
    "    plt.plot(val_losses, color=\"green\", label=\"Val\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(history, n_concepts_list):\n",
    "    plt.plot(history[:, 0], history[:, 2], label=f'AUC')\n",
    "    plt.plot(history[:, 0], history[:, 3], label=f'ACC')\n",
    "    plt.plot(history[:, 0], history[:, 4], label=f'F1')\n",
    "\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title('Plot of Concepts vs Criteria')\n",
    "    plt.xticks(n_concepts_list)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_atomics_concepts_metric(history, title, dec=\"{:.3g}\"):\n",
    "        \n",
    "    df = pd.DataFrame(history, columns=[\"n_atomics\", \"n_concepts\", \"val_loss\", \"auc\", \"acc\", \"f1\"])\n",
    "    mean_atomics = df.groupby(\"n_atomics\").mean()\n",
    "    mean_concepts = df.groupby(\"n_concepts\").mean()\n",
    "\n",
    "    # display(mean_atomics)\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_atomics.index, mean_atomics[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Atomics')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over atomics\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # display(mean_concepts)\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"auc\"], label='AUC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"acc\"], label='ACC')\n",
    "    plt.plot(mean_concepts.index, mean_concepts[\"f1\"], label='F1')\n",
    "    plt.xlabel('Num Concepts')\n",
    "    plt.ylabel('Criteria')\n",
    "    plt.title(\"Metric as mean over concepts\")\n",
    "    plt.suptitle(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeModel(n_concepts, input_dim, changing_dim, seq_len, output_dim, \n",
    "                    use_indicators, use_fixes, use_only_last_timestep, top_k=''):\n",
    "    model = original_models.CBM(input_dim = input_dim, \n",
    "                                changing_dim = changing_dim, \n",
    "                                seq_len = seq_len,\n",
    "                                num_concepts = n_concepts,\n",
    "                                use_indicators = use_indicators,\n",
    "                                use_fixes = use_fixes,\n",
    "                                use_only_last_timestep = use_only_last_timestep,\n",
    "                                opt_lr = 1e-3,\n",
    "                                opt_weight_decay = 1e-5,\n",
    "                                l1_lambda=1e-3,\n",
    "                                cos_sim_lambda=1e-2,\n",
    "                                output_dim = output_dim,\n",
    "                                top_k=top_k,\n",
    "                                device = device\n",
    "                                )\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def initializeModel_with_atomics(n_atomics, n_concepts, input_dim, changing_dim, seq_len, output_dim, \n",
    "                                 use_summaries_for_atomics, use_indicators, use_fixes, top_k=''):\n",
    "    model = new_models.CBM(input_dim = input_dim, \n",
    "                            changing_dim = changing_dim, \n",
    "                            seq_len = seq_len,\n",
    "                            num_concepts = n_concepts,\n",
    "                            num_atomics= n_atomics,\n",
    "                            use_summaries_for_atomics = use_summaries_for_atomics,\n",
    "                            use_indicators = use_indicators,\n",
    "                            use_fixes = use_fixes,\n",
    "                            opt_lr = 1e-3,\n",
    "                            opt_weight_decay = 1e-5,\n",
    "                            l1_lambda=1e-3,\n",
    "                            cos_sim_lambda=1e-2,\n",
    "                            output_dim = output_dim,\n",
    "                            top_k=top_k,\n",
    "                            device = device\n",
    "                            )\n",
    "    model = model.to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 62 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "auroc_metric = AUROC(task=\"binary\").to(device)\n",
    "accuracy_metric = Accuracy(task=\"binary\").to(device)\n",
    "f1_metric = F1Score(task=\"binary\").to(device)\n",
    "conf_matrix = ConfusionMatrix(task=\"binary\").to(device)\n",
    "\n",
    "seq_len = X.shape[1]\n",
    "changing_dim = len(changing_vars)\n",
    "input_dim = X.shape[2]\n",
    "\n",
    "print(changing_dim, input_dim, seq_len)\n",
    "\n",
    "random_seed = 1\n",
    "set_seed(random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[4, True, False, 2, True],\n",
       " [4, False, False, 2, True],\n",
       " [4, True, True, 2, True],\n",
       " [4, True, False, 1, True],\n",
       " [4, True, False, 2, False],\n",
       " [4, False, True, 1, False]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_concepts, (use_indicators, use_fixes, output_dim, use_only_last_timestep)\n",
    "config = [\n",
    "    [True, False, 2, True], # old\n",
    "    \n",
    "    [False, False, 2, True], # ablaitions\n",
    "    [True, True, 2, True],\n",
    "    [True, False, 1, True],\n",
    "    [True, False, 2, False],\n",
    "    \n",
    "    [False, True, 1, False], # new\n",
    "]\n",
    "\n",
    "n_concepts_list = list(range(4, 5, 1))\n",
    "\n",
    "all_config_permutations = [[concept] + list(combination) for combination, concept in product(config, n_concepts_list)]\n",
    "\n",
    "# all_config_permutations = list(product(*config.values()))\n",
    "print(len(all_config_permutations))\n",
    "all_config_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/vasopressor/original/\"\n",
    "model_path = experiment_folder + \"vaso_c{}_ind{}_fixes{}_onlylasttimestep{}_output_dim{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 True False 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesFalse_onlylasttimestepTrue_output_dim2.pt\n",
      "['original', 0, 0.5197964310646057, 0.91069096326828, 0.8326754570007324, 0.8411534428596497]\n",
      "1 4 True False 2 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesFalse_onlylasttimestepFalse_output_dim2.pt\n",
      "['original', 1, 0.5231447815895081, 0.9181749820709229, 0.843058168888092, 0.8501924872398376]\n",
      "2 4 True False 1 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesFalse_onlylasttimestepTrue_output_dim1.pt\n",
      "['original', 2, 0.9712875485420227, 0.7908577919006348, 0.7237000465393066, 0.41283735632896423]\n",
      "3 4 True False 1 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesFalse_onlylasttimestepFalse_output_dim1.pt\n",
      "['original', 3, 0.9729517102241516, 0.7939590811729431, 0.7187231779098511, 0.4119124412536621]\n",
      "4 4 True True 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesTrue_onlylasttimestepTrue_output_dim2.pt\n",
      "['original', 4, 0.5176288485527039, 0.912331223487854, 0.8375664949417114, 0.8448233604431152]\n",
      "5 4 True True 2 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesTrue_onlylasttimestepFalse_output_dim2.pt\n",
      "['original', 5, 0.5236897468566895, 0.9159983992576599, 0.838424563407898, 0.845920979976654]\n",
      "6 4 True True 1 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesTrue_onlylasttimestepTrue_output_dim1.pt\n",
      "['original', 6, 0.9659886956214905, 0.787341296672821, 0.7274755239486694, 0.41054195165634155]\n",
      "7 4 True True 1 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indTrue_fixesTrue_onlylasttimestepFalse_output_dim1.pt\n",
      "['original', 7, 0.9704265594482422, 0.7915175557136536, 0.7432641386985779, 0.42015504837036133]\n",
      "8 4 False False 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indFalse_fixesFalse_onlylasttimestepTrue_output_dim2.pt\n",
      "['original', 8, 0.5202323198318481, 0.9149949550628662, 0.8411704301834106, 0.849033534526825]\n",
      "9 4 False False 2 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/original/vaso_c4_indFalse_fixesFalse_onlylasttimestepFalse_output_dim2.pt\n",
      "['original', 9, 0.526611864566803, 0.9185498952865601, 0.8415994644165039, 0.8493061065673828]\n",
      "10 4 False False 1 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▎         | 359/10000 [05:05<2:16:38,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 10, 0.9740108847618103, 0.7829480171203613, 0.7317659258842468, 0.4112994372844696]\n",
      "11 4 False False 1 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 399/10000 [05:32<2:13:25,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 11, 1.004642128944397, 0.7848280072212219, 0.7424060702323914, 0.42023947834968567]\n",
      "12 4 False True 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  8%|▊         | 759/10000 [10:51<2:12:18,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 12, 0.5248509049415588, 0.9172795414924622, 0.8434014320373535, 0.8504220843315125]\n",
      "13 4 False True 2 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  6%|▋         | 639/10000 [09:14<2:15:17,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 13, 0.5267669558525085, 0.9143927097320557, 0.8400549292564392, 0.8473882675170898]\n",
      "14 4 False True 1 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 379/10000 [05:27<2:18:37,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 14, 0.9712535738945007, 0.7873522043228149, 0.7425776720046997, 0.4177018702030182]\n",
      "15 4 False True 1 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  4%|▍         | 379/10000 [05:30<2:19:57,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['original', 15, 0.9873917102813721, 0.7849068641662598, 0.7515016198158264, 0.4203362762928009]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histories_original = []\n",
    "\n",
    "for i, (n_concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep) in enumerate(all_config_permutations):\n",
    "    print(i, n_concepts, use_indicators, use_fixes, output_dim, use_only_last_timestep)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits, output_dim)\n",
    "    \n",
    "    model = initializeModel(n_concepts=n_concepts, input_dim=input_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=output_dim, \n",
    "                            use_indicators=use_indicators, use_fixes=use_fixes, use_only_last_timestep=use_only_last_timestep)\n",
    "    \n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(n_concepts, use_indicators, use_fixes, use_only_last_timestep, output_dim), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            probs = model.forward_probabilities(Xb)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "    \n",
    "    history = [\"original\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    histories_original.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "    \n",
    "histories_original = np.array(histories_original)\n",
    "histories_original.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plot_metrics(histories_original, n_concepts_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10, 4, True, False, 2, True],\n",
       " [30, 4, True, False, 2, True],\n",
       " [100, 4, True, False, 2, True],\n",
       " [10, 4, True, False, 2, False],\n",
       " [30, 4, True, False, 2, False],\n",
       " [100, 4, True, False, 2, False],\n",
       " [10, 4, False, False, 2, True],\n",
       " [30, 4, False, False, 2, True],\n",
       " [100, 4, False, False, 2, True],\n",
       " [10, 4, True, True, 2, True],\n",
       " [30, 4, True, True, 2, True],\n",
       " [100, 4, True, True, 2, True],\n",
       " [10, 4, True, False, 1, True],\n",
       " [30, 4, True, False, 1, True],\n",
       " [100, 4, True, False, 1, True],\n",
       " [10, 4, False, False, 2, False],\n",
       " [30, 4, False, False, 2, False],\n",
       " [100, 4, False, False, 2, False],\n",
       " [10, 4, True, True, 2, False],\n",
       " [30, 4, True, True, 2, False],\n",
       " [100, 4, True, True, 2, False],\n",
       " [10, 4, True, False, 1, False],\n",
       " [30, 4, True, False, 1, False],\n",
       " [100, 4, True, False, 1, False],\n",
       " [10, 4, False, True, 1, True],\n",
       " [30, 4, False, True, 1, True],\n",
       " [100, 4, False, True, 1, True],\n",
       " [10, 4, False, True, 1, False],\n",
       " [30, 4, False, True, 1, False],\n",
       " [100, 4, False, True, 1, False]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_concepts, (use_indicators, use_fixes, output_dim, use_summaries_for_atomics)\n",
    "config = [\n",
    "     # old\n",
    "    [True, False, 2, True],\n",
    "    [True, False, 2, False],\n",
    "    \n",
    "    # ablaitions\n",
    "    [False, False, 2, True],\n",
    "    [True, True, 2, True],\n",
    "    [True, False, 1, True],\n",
    "    \n",
    "    [False, False, 2, False],\n",
    "    [True, True, 2, False],\n",
    "    [True, False, 1, False],\n",
    "    \n",
    "    # new\n",
    "    [False, True, 1, True],\n",
    "    [False, True, 1, False],\n",
    "]\n",
    "\n",
    "n_concepts_list = list(range(4, 5, 1))\n",
    "n_atomics_list = [10, 30, 100]\n",
    "\n",
    "all_config_permutations = [[atomic, concept] + list(combination) for combination, concept, atomic in product(config, n_concepts_list, n_atomics_list)]\n",
    "\n",
    "# all_config_permutations = list(product(*config.values()))\n",
    "print(len(all_config_permutations))\n",
    "all_config_permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = \"/workdir/optimal-summaries-public/_models/vasopressor/atomics/\"\n",
    "model_path = experiment_folder + \"vaso_a{}_c{}_ind{}_fixes{}_output_dim{}_summaries{}.pt\"\n",
    "\n",
    "if not os.path.exists(experiment_folder):\n",
    "    os.makedirs(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 4 True False 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/atomics/vaso_a10_c4_indTrue_fixesFalse_output_dim2_summariesTrue.pt\n",
      "['CBM atomics', 0, 0.5313735008239746, 0.9138913750648499, 0.8373948931694031, 0.8451417684555054]\n",
      "1 30 4 True False 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/atomics/vaso_a30_c4_indTrue_fixesFalse_output_dim2_summariesTrue.pt\n",
      "['CBM atomics', 1, 0.5467365980148315, 0.9132466316223145, 0.8349064588546753, 0.8434499502182007]\n",
      "2 100 4 True False 2 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /workdir/optimal-summaries-public/_models/vasopressor/atomics/vaso_a100_c4_indTrue_fixesFalse_output_dim2_summariesTrue.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/9279 [00:32<2:02:25,  1.26 epoch/s, Train Loss=1.73838, Val Loss=1.77607, Best Val Loss=1.77607]"
     ]
    }
   ],
   "source": [
    "history_atomics = []\n",
    "\n",
    "for i, (n_atomics, n_concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics) in enumerate(all_config_permutations):\n",
    "    print(i, n_atomics, n_concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics)\n",
    "    \n",
    "    train_loader, val_loader, test_loader, class_weights, num_classes = preprocess_data(X, Y_logits, output_dim)\n",
    "    \n",
    "    model = initializeModel_with_atomics(n_atomics=n_atomics, n_concepts=n_concepts, input_dim=input_dim, changing_dim=changing_dim, seq_len=seq_len, output_dim=output_dim, \n",
    "                                         use_summaries_for_atomics=use_summaries_for_atomics, use_indicators=use_indicators, use_fixes=use_fixes)\n",
    "    \n",
    "    model.fit(train_loader, val_loader, p_weight=class_weights.to(device), save_model_path=model_path.format(n_atomics, n_concepts, use_indicators, use_fixes, output_dim, use_summaries_for_atomics), max_epochs=10000)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for Xb, yb in test_loader:\n",
    "            Xb, yb = Xb.to(device), yb.to(device)\n",
    "            probs = model.forward_probabilities(Xb)\n",
    "            \n",
    "            auc = auroc_metric(probs, yb).item()\n",
    "            acc = accuracy_metric(probs, yb).item()\n",
    "            f1 = f1_metric(probs, yb).item()\n",
    "            # conf_matrix(probs, yb)\n",
    "        auc = auroc_metric.compute().item()\n",
    "        acc = accuracy_metric.compute().item()\n",
    "        f1 = f1_metric.compute().item()\n",
    "        # conf_matrix.plot()\n",
    "        # plt.show()\n",
    "        auroc_metric.reset()\n",
    "        accuracy_metric.reset()\n",
    "        # conf_matrix.reset()\n",
    "        f1_metric.reset()\n",
    "\n",
    "    history = [\"CBM atomics\", i, model.val_losses[-1], auc, acc, f1]\n",
    "    print(history)\n",
    "    history_atomics.append(np.array(history))\n",
    "    \n",
    "    # plot_losses(model.train_losses, model.val_losses)\n",
    "\n",
    "    \n",
    "history_atomics = np.array(history_atomics)\n",
    "history_atomics.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_atomics_concepts_metric(history_atomics, \"title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature weights\n",
    "n_concepts = 4\n",
    "\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes)\n",
    "model.fit(train_loader, val_loader, class_weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "    Xb, yb = Xb.to(device), yb.to(device)\n",
    "    probs = model.forward_probabilities(Xb)\n",
    "    \n",
    "    auc = auroc_metric(probs, yb).item()\n",
    "    acc = accuracy_metric(probs, yb).item()\n",
    "    conf_matrix(probs, yb)\n",
    "auc = auroc_metric.compute().item()\n",
    "acc = accuracy_metric.compute().item()\n",
    "conf_matrix.plot()\n",
    "auroc_metric.reset()\n",
    "accuracy_metric.reset()\n",
    "conf_matrix.reset()\n",
    "\n",
    "print(\"AUC\", auc)\n",
    "print(\"ACC\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if \"bottleneck.weight\" in name:\n",
    "        bottleneck_weights = param\n",
    "feature_weights = bottleneck_weights.cpu().detach().numpy()\n",
    "\n",
    "feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize weight magnitudes\n",
    "for c in range(n_concepts):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    inds = np.argsort(-np.abs(feature_weights[c]))[:100]\n",
    "    ax.bar(np.arange(1,101),np.abs(feature_weights[c])[inds])\n",
    "    ax.set_xlabel(\"Top 100 features\")\n",
    "    ax.set_ylabel(\"abs value of feature coefficient\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 90th percentile of feature weights\n",
    "sum90p = np.sum(np.abs(feature_weights), axis=-1)*0.90\n",
    "sum90p.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top K indizes\n",
    "top_k_inds = []\n",
    "for c in range(n_concepts):\n",
    "    topkinds_conc = []\n",
    "    curr_sum = 0\n",
    "    inds = np.argsort(-np.abs(feature_weights[c])) #desc\n",
    "    sorted_weights = feature_weights[c][inds]\n",
    "    \n",
    "    for ind, weight in zip(inds, sorted_weights):\n",
    "        curr_sum += abs(weight)\n",
    "        if curr_sum <= sum90p[c]:\n",
    "            topkinds_conc.append(ind)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # if selects less than 10, choose 10 best\n",
    "    if len(topkinds_conc) < 10:\n",
    "        topkinds_conc = np.argsort(-np.abs(feature_weights[c]))[:10].tolist()\n",
    "    \n",
    "    top_k_inds.append(topkinds_conc)\n",
    "\n",
    "top_k_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write top k inds to csv\n",
    "filename = experiment_folder + \"top-k/top_k_inds_c{}.csv\".format(n_concepts)\n",
    "\n",
    "directory = os.path.dirname(filename)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(top_k_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 13 + 1\n",
    "T = seq_len + 1\n",
    "print(T)\n",
    "vars_ = [i for i in range(1,V)] + [str(i) + \"_ind\" for i in range(1,V)]\n",
    "print(len(vars_))\n",
    "data_cols = [[\"feat_{}_time_{}\".format(v, t) for v in vars_] for t in range(1, T)]\n",
    "flattened_data_cols = [col for sublist in data_cols for col in sublist]\n",
    "print(len(flattened_data_cols))\n",
    "flattened_data_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for c, _list in enumerate(top_k_inds):\n",
    "    for ind in _list:\n",
    "        name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, int(ind))\n",
    "        print(f\"Concept {c}: ID {ind}, Feature {name}, Summary {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_results = greedy_selection(auroc_metric, test_loader, top_k_inds, model, track_metrics={\"acc\": accuracy_metric})\n",
    "greedy_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = experiment_folder + \"top-k/bottleneck_r{}_c{}_topkinds.csv\".format(random_seed, n_concepts)\n",
    "\n",
    "# writing to csv file\n",
    "with open(top_k_csv_file, 'w') as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(greedy_results.columns)\n",
    "    # writing the data rows \n",
    "    for row in greedy_results.itertuples(index=False):\n",
    "        csvwriter.writerow(list(row))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = greedy_results.sort_values([\"Concept\", \"ID\"])\n",
    "\n",
    "for row in sorted_.itertuples(index=False):\n",
    "    name, summary = getConcept(flattened_data_cols, input_dim, changing_dim, row[1])\n",
    "    print(f\"Concept {row[2]}: ID {row[1]}, Feature {name}, Summary {summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(greedy_results[\"Score\"], label = f\"AUC {greedy_results['Score'].values[-1]:.3f}\")\n",
    "plt.plot(greedy_results[\"acc\"], label = f\"ACC {greedy_results['acc'].values[-1]:.3f}\")\n",
    "\n",
    "plt.xlabel('Num Concepts')\n",
    "plt.ylabel('Criteria')\n",
    "plt.title('Plot of Concepts vs Criteria')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_csv_file = \"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/bottleneck_r1_c6_topkinds.csv\"\n",
    "n_concepts = 6\n",
    "model = initializeModel(n_concepts, input_dim, changing_dim, seq_len, num_classes, top_k=top_k_csv_file)\n",
    "# model.fit(train_loader, val_loader, weights, model_path.format(n_concepts), 1000)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb).item()\n",
    "        acc = accuracy_metric(probs, yb).item()\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "\n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, val_loader, class_weights, save_model_path=\"/workdir/optimal-summaries-public/_models/arabic/multiclass/top-k/arabic_c6_finetuned.pt\", max_epochs=3000, patience=100)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (Xb, yb) in enumerate(test_loader):\n",
    "        Xb, yb = Xb.to(device), yb.to(device)\n",
    "        probs = model.forward_probabilities(Xb)\n",
    "        \n",
    "        auc = auroc_metric(probs, yb)\n",
    "        acc = accuracy_metric(probs, yb)\n",
    "    auc = auroc_metric.compute().item()\n",
    "    acc = accuracy_metric.compute().item()\n",
    "    auroc_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "print(auc)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(model.val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
